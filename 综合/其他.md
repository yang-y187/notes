# 消息队列

## 你为什么要用消息队列？

从优点上来说

- 异步处理（异步处理提高了并发性）
  - 将一些比较耗时的操作，放在其他系统，将消息队列需要处理的消息进行存储，其他系统可以消费消息队列中的数据
  - 那为什么不直接异步调用呢？干嘛要用消息队列？
    1. 可以提高系统的稳定性，若是多线程异步调用，程序宕机，请求丢失，若是消息队列，仍在保存在队列中等待消费
    2. 解耦更充分，架构更合理    A通过消息中间件 到B，更合理
    3. 
- 系统解耦
  - 若是微服务之间的相互调用，耦合过于严重，但凡有接口变化，则可能导致整个系统不可用。可以使用统一的中间件，都遵从这个格式，降低耦合
- 流量削峰
  - 若是流量很大，服务器无法立即处理所有请求，可以将请求缓存在消息队列中，由服务器慢慢处理。缓解服务器运行压力
  - 低延迟，高可靠，高吞吐，可以应对大量并发

## 消息队列有什么缺点吗

- 对于实时性要求很高的情况，不适用。或者请求很低，可以满足要求，若是请求量很大，则消息队列进行削峰处理，降低速度，不满足实时性要求
- 消息队列要引入中间件，则需要考虑消息中间件的可靠性，速率，以及性能。这些问题。而且出现问题如何解决，都需要一定的策略。
- 需要考虑分布式事务，（即更复杂的考虑）

## kafka是如何保证消息不丢失的

分为两个阶段：

- 生产端

  - 生产者生产消息，提交时，可以设置应答策略，会进行应答。若提交失败，可以重试。

- 消费端

  - broker会将生产者的消息进行持久化，一般不会删除，等待消息过期后自动删除。broker持久化应用 了分片和索引的方式。一个主题将多条数据分片。每一片建立索引进行存储。这个索引就使用的offset。

  - 由于消费者可能是多个，kafka维持了一个offset的队列，保存map数据，每个消费者，会定时更新该消费者已经消费消息的offset。

    - 此时，仍会出现重复消费和漏消费的情况，**需要使用消费者事务**

      - 重复消费
        - 自动提交offset情况下，在消费者提交offset之后，消费者继续消费，还没等到下一次提交，消费者宕机，重启后，继续从上次提交的offset处消费。造成了重复
      - 漏消费
        - 在手动提交offset情况下，offset方提交，消费者抓取的消息还在内存中，未持久化。消费者宕机，消息丢失

      **需要使用消费者事务**

## RabbitMQ是如何保证消息不丢失

消息丢失的原因：生产者丢失消息、消息列表丢失消息、消费者丢失消息；

- 生产者丢失消息：
  - transaction机制就是说：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。然而，这种方式有个缺点：吞吐量下降；
  - confirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。
- **消息队列丢数据**：消息持久化。
  - 持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。
  - 步骤
    - 将queue的持久化标识durable设置为true,则代表是一个持久的队列
    - 发送消息的时候将deliveryMode=2
- **消费者丢失消息**：消费者丢数据一般是因为采用了自动确认消息模式，改为手动确认消息即可！



## 如何避免消息重复

Kafka

- 生产者端
  - 生产消息是幂等的，设置幂等开关 `enable.idempotence=true`，生产者可以保证每条消息只写入一次。消息附带key 
  - 生产者应答机制：确认消息被所有副本确认后再应答
- broker 端
  - 设置适当的分区数和副本数，确保机器的高可用和一致性
- 消费者端
  - 确保消费者消费逻辑是幂等的，即多次消息也无影响
  - Kafka消费应答，确认消费成功后应答
  - 消费者消费完消息后，提交offset偏移量。改为手动提交，并在消费成功后提交偏移量。确保消息消费成功后才更新偏移量



# RPC

### RPC协议和HTTP协议的区别？

RPC（Remote Procedure Call）协议和HTTP（Hypertext Transfer Protocol）协议是两种用于网络通信的协议，它们在设计目标、使用场景和技术实现上有一些显著的区别：

- ### 1. 设计目标

  - **RPC协议**：
    - 旨在使远程服务调用看起来像本地调用。开发者可以通过调用函数或方法的方式来与远程服务进行交互。
    - 通常用于分布式系统中，以实现服务之间的通信和协调。


    - **HTTP协议**：
      - 是一种应用层协议，主要用于在客户端和服务器之间传输超文本信息。
      - 设计用于Web浏览器与Web服务器之间的通信，但也广泛用于RESTful API、微服务等。


- ### 2. 通信模式

  - **RPC协议**：
    - 使用二进制协议


    - **HTTP协议**：
      - 使用文本协议


- ### 3. 数据格式

  - **RPC协议**：
    - 可以使用二进制格式（如Protobuf、Thrift）进行数据序列化，具有较高的性能和效率。
    - RPC接口使用函数参数传递参数


    - **HTTP协议**：
      - 数据通常以文本格式传输，如JSON、XML，易于阅读和调试，但可能在性能上不如二进制格式。


- ### 4. 使用场景

  - **RPC协议**：
    - 常用于需要高性能、低延迟的分布式系统。
    - 适合内部服务之间的通信，尤其是在微服务架构中。


    - **HTTP协议**：
      - 广泛用于Web应用程序和开放的RESTful API。
      - 适合需要与外部系统集成的场景。

- ### 5. 标准化和互操作性

  - **RPC协议**：
    - 通常与特定的框架绑定（如gRPC、Apache Thrift），可能需要特定的库支持。


    - **HTTP协议**：
      - 是一种标准化的协议，具有广泛的互操作性和支持，几乎所有的编程语言和平台都能处理HTTP。


综上所述，RPC和HTTP协议各有优缺点，选择使用哪种协议通常取决于具体的应用场景和需求。







# 项目

## 项目中遇到了什么问题吗？

- 论坛项目
  - 我在退出登录后，有时候还是会显示我登录的头像等信息？而且我已经在redis中移除了登录用户的信息，或者说改变了登录状态。
    - 后来是发现，我设置了拦截器，每次请求都会进行拦截器校验，判断是否登录，若是登录，则保存在threadLocal中。退出登录后，确实没有获取到该用户信息。但是在后续的方法中，threadLocal中有用户数据。这个threadLocal是线程隔离的，线程内共享，方便操作。但tomcat线程是有限的，即线程是会复用的，所以后续的请求，使用到了之前线程保存的用户信息。造成了退出登录，但仍有可能显示的问题。后续解决是：使用拦截器，在方式执行结束后，移除用户信息
- 你简历项目中都是用到了redis，说说你把什么数据放在redis中呢？
  - 将即时性，数据一致性要求不高的数据放在redis中。比如说验证码，已登录用户信息，物流信息
  - 访问量大且更新频率不高的 数据（读多，写少）

## 谈谈你对高并发的理解

高并发：意味着大流量，使用技术手段抵抗流量的冲击，使流量更平稳地被系统所处理，带给用户更好的体验。

并发量和QPS只是参考指标，还得具体情况具体分析

- 高性能：性能体现了系统的并行处理能力
- 高可用：服务不出现故障，不宕机
- 高拓展：系统的拓展能力，流量高时，能否在流量高峰时短时间内完成扩容。
- **高性能的实践方案**
  - 使用Redis多级缓存
  - 分库分表和索引优化
  - 使用多线程异步处理
  - 限流，熔断
  - 进行流量削峰
  - 缓存预热
  - 减少锁的使用
  - 优化代码逻辑

## 程序如果挂了/抛异常/结果有问题，该如何排查？

如果是在idea这种运行的错误，因为有错的话，会报错。看到是哪有错。如果是结果有问题，可以debug。

如果是在服务器上，如果是有异常，肯定是先查日志，我们项目使用的Tomcat，文件夹下，有一个文件logs。可以查看日志。自己在idea中进行测试查看问题来源。我们在项目中使用了@restControllerAdvice，来处理所有的异常，首先就会记录日志。





## 什么叫强一致性，弱一致性？还有一个最终一致性？

- 强一致性：系统中的某个数据被成功更新后，后续任何对该数据的读取操作都将得到更新后的值；

- 弱一致性：系统中的某个数据被更新后，后续对该数据的读取操作可能得到更新后的值，也可能是更改前的值。但经过“不一致时间窗口”这段时间后，后续对该数据的读取都是更新后的值；

- 最终一致性：是弱一致性的特殊形式，存储系统保证在没有新的更新的条件下，最终所有的访问都是最后更新的值。





## 遇没遇到过内存突然飙升的问题

遇到过，是CPU和内存同时飙升

-XX:+UseAdaptiveSizePolicy



# 简历

你实习最大的收货是什么？

- 首先来说，开拓了眼界，体验了一下生产环境，开发一个东西要写，技术方案，每天要有wiki产出。

- 了解了很多新的技术知识，

- 在遇到一个需求时，不是直接上手写代码，而是先写技术方案，写各种涉及到的东西和解决办法。而且还是思考plan B。若是线上出现问题后，可以及时补救。（在lion中配置开关）

- 我实习的时候，写的一个需求是切换orgId。将原本使用自己系统的orgId，切换为基础侧的orgId。所有的系统都要切换orgId。这就涉及一个点是，你不清楚自己

  - 需要先写技术方案，开会讨论。

  - 重点是：三个步骤

    1. 双写，将新旧orgId进行写入。添加新字段
       1. 双写不仅是在数据库写入，需要在接口处都要处理。
       2. 流量入口：分为其他服务的调用和前端的调用
          1. 将orgId统一切换新orgId（我们并不清楚其他系统使用的新的还是旧的orgId）BO，PO都要添加新字段（我们系统内部使用新orgId）
       3. 流量出口：我们并不清楚其他系统微服务使用的新旧接口，所以返回值涉及到orgId的，全部使用旧的。
    2. 数据刷新，将原本没有使用新orgId的数据添加新 的orgId

    前端请求调用





## TPS/QPS的区别：

一、QPS/TPS
QPS：Queries Per Second意思是“每秒查询率”，是一台服务器每秒能够相应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。
TPS：是TransactionsPerSecond的缩写，也就是事务数/秒。它是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。
Tps即每秒处理事务数，包括了
1）用户请求服务器
2）服务器自己的内部处理
3）服务器返回给用户
这三个过程，每秒能够完成N个这三个过程，Tps也就是3；
Qps基本类似于Tps，但是不同的是，对于一个页面的一次访问，形成一个Tps；但一次页面请求，可能产生多次对服务器的请求，服务器对这些请求，就可计入“Qps”之中。
例如：访问一个页面会请求服务器3次，一次放，产生一个“T”，产生3个“Q” 

## TP99 和TP999

TP99:处理99%的请求所消耗的时间

TP999:处理99.9%的请求所消耗的时间。





# MQ

## MQ如何保证消息不会丢失？

- 生产者
  - producer重试机制 
  - producer的ack机制
- broker
  - 副本故障处理。follower备份：leader和follow故障后的机制
  - 持久化（分片和稀疏索引）
- 消费者
  - 手动提交offset

## rabbitMq如何保证消息不丢失

- 生产者：RabbitMQ提供transaction和confirm模式来确保生产者不丢消息；

  - transaction机制就是说：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。然而，这种方式有个缺点：吞吐量下降；
  - confirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；
  - 发送失败后，触发重试机制

- 消息队列：消息持久化

  - 这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。

    这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。

    那么如何持久化呢？

    这里顺便说一下吧，其实也很容易，就下面两步

    1. 将queue的持久化标识durable设置为true,则代表是一个持久的队列
    2. 发送消息的时候将deliveryMode=2

- 消费者

  - 消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ 才能安全地把消息从队列中删除。





## kafka与rabbitMq的区别

![image-20220727094142076](其他.assets/image-20220727094142076.png)

Kafka是LinkedIn开源的分布式发布-订阅消息系统，目前归属于Apache顶级项目。Kafka主要特点是基于Pull的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输。0.8版本开始支持复制，不支持事务，对消息的重复、丢失、错误没有严格要求，适合产生大量数据的互联网服务的数据收集业务。**侧重点是高性能高吞吐量，对消息的重复，丢失，错误没有严格要求**





**RabbitMQ**

![image-20220727094209587](其他.assets/image-20220727094209587.png)

RabbitMQ是使用Erlang语言开发的开源消息队列系统，基于AMQP协议来实现。AMQP的主要特征是面向消息、队列、路由(包括点对点和发布/订阅)、可靠性、安全。AMQP协议更多用在企业系统内，对数据一致性、稳定性和可靠性要求很高的场景，对性能和吞吐量的要求还在其次。

**rabbitMq自身是基于erlang语言开发的，所以导致较为难以分析里面的源码，也较难进行深层次的源码定制和改造，毕竟需要较为扎实的erlang语言功底才可以。**



区别：

![37e338810e9472766761ef58e9059936.png](其他.assets/37e338810e9472766761ef58e9059936.jpeg)

![4fbeb7d46e61ce56665078aa723dea72.png](其他.assets/4fbeb7d46e61ce56665078aa723dea72.jpeg)



## 消息队列的有序性问题

https://xie.infoq.cn/article/c84491a814f99c7b9965732b1

**RabbitMQ**：

对于 RabbitMQ 来说，导致上面顺序错乱的原因通常是消费者是集群部署，不同的消费者消费到了同一订单的不同的消息，如消费者 A 执行了增加，消费者 B 执行了修改，消费者 C 执行了删除，但是消费者 C 执行比消费者 B 快，消费者 B 又比消费者 A 快，就会导致消费 binlog 执行到数据库的时候顺序错乱，本该顺序是增加、修改、删除，变成了删除、修改、增加。


![image-20220819105654665](其他.assets/image-20220819105654665-16608778163231.png)

**解决方案：**

RabbitMQ 的问题是由于不同的消息都发送到了同一个 queue 中，多个消费者都消费同一个 queue 的消息。解决这个问题，我们可以给 RabbitMQ 创建多个 queue，每个消费者固定消费一个 queue 的消息，生产者发送消息的时候，同一个订单号的消息发送到同一个 queue 中，由于同一个 queue 的消息是一定会保证有序的，那么同一个订单号的消息就只会被一个消费者顺序消费，从而保证了消息的顺序性。

**梳理：**所有消息都发给同一个消息队列，最后由多个消费者竞争消费，所以导致乱序。指定多个消息队列，队列与消费者一一对应。一个订单的消息只发给一个队列即可



**Kafka**

对于 Kafka 来说，一个 topic 下同一个 partition 中的消息肯定是有序的，生产者在写的时候可以指定一个 key，通过我们会用订单号作为 key，这个 key 对应的消息都会发送到同一个 partition 中，所以消费者消费到的消息也一定是有序的。
那么为什么 Kafka 还会存在消息错乱的问题呢？问题就出在消费者身上。通常我们消费到同一个 key 的多条消息后，会使用多线程技术去并发处理来提高消息处理速度，否则一条消息的处理需要耗时几十 ms，1 秒也就只能处理几十条消息，吞吐量就太低了。而多线程并发处理的话，binlog 执行到数据库的时候就不一定还是原来的顺序了。

![img](其他.assets/bd26bbe4fd32fbc6b1417fea30e63b9f.png)

**解决方案：**

Kafka 从生产者到消费者消费消息这一整个过程其实都是可以保证有序的，导致最终乱序是由于消费者端需要使用多线程并发处理消息来提高吞吐量，比如消费者消费到了消息以后，开启 32 个线程处理消息，每个线程线程处理消息的快慢是不一致的，所以才会导致最终消息有可能不一致。
所以对于 Kafka 的消息顺序性保证，其实我们只需要保证同一个订单号的消息只被同一个线程处理的就可以了。由此我们可以在线程处理前增加个内存队列，每个线程只负责处理其中一个内存队列的消息，同一个订单号的消息发送到同一个内存队列中即可。



**梳理：**kafka从生产者到消费者是能够保证消息的有序性的，开启幂等性和事务，生产者发送消息时，指定分区，就可以将同一类事务放在指定分区，消息者顺序消费。但是消费者为提高吞吐量，可能会使用多线程处理消费的消息，可能会出现【消费者开始执行消息的顺序有序的，但是异步执行过程中，有的消息执行慢，有的消息执行快，导致最终乱序了】，可以使用一个内存队列，即执行线程消费，一个订单号或者一个用户都使用这一个异步线程处理。就可以解决。

如下图是 Kafka 保证消息顺序性的方案：

![img](其他.assets/558885f83fac1c0dacf4c4c60df3941b.png)







# 场景题

## 10000数据找出最大的1000个数字

快速排序：时间复杂度为nlog（n），可以选择 partition只求取最大1000的排序，若是取出的值==1000，不再进行排序。

最小堆: 时间复杂度为 nlog（k）

## 给你一个 多边形，如何判断一个点在多边形内部

对该点做一条射线，若是基数，则在内部，偶数，则外部。单独考虑是否与边重合，或者与多边形角重合的情况



## 用户访问不了一个网站，你怎么解决？

- 首先检查服务器：
  - **确定服务器部署的项目运行成功**
    1. 查看后台运行进程信息，像idea控制台一样
    2. 查看日志，可以在日志中查看运行信息【项目都用tomcat启动，所有服务器都在tomcat的日志记录中】
  - **确定访问地址地址是否正确**
    - IP地址，端口号是不是一直
  - **确定服务器安全规则是否添加了要访问的端口**
    - 即查看服务器是不是开放了该端口，防火墙问题。

- 追问：**服务器里面高内存，高CPU的情况怎么解决？**
  - CPU，内存，看上面 JVM部分
- 如果排查下来，都正常，还有一小部分用户不能方法，你怎么解决？
  - 可能是有限流
- 如果没有限流呢，而且那几个用户还着急要用，你怎么解决？
  - 上线小demo，实现对应功能，先解决用户着急使用数据 的问题，然后再排查。可以在开一台服务器



实际上是想问：Linux无法通过url获得服务器主页数据如何排查？

- **关防火墙、看host文件里边是否ip和域名绑定了**



## TOP K问题

通常最好的方案是使用分治 + 小顶堆。即先将数据集用Hash方法拆解成多个小数据集进行分治，然后用小顶堆在每个数据集中找到最大的前K个数，最后在所有小数据集的Top K数中通过系统排序找到最终的Top K个数。

**是否有足够内存：**如果机器内存足够可以直接在内存中使用Hash对数据进行切分，如果机器内存不足可以将原始文件切分成多个小文件

**如果含较多重复值**：先用hash / 依图法去重，可大大节省运算量

## 有几台机器存储着几亿淘宝搜索日志，你只有一台 2g 的电脑，怎么选出搜索热度最高的十个？

针对top k类文本问题，通常比较好的方案是【分治+trie树/hash+小顶堆】，即先将数据集按照hash方法分解成多个小数据集，然后使用trie树或者hash统计每个小数据集中的query词频，之后用小顶堆求出每个数据集中出频率最高的前K个数，最后在所有top K中求出最终的top K。

拆分成n多个文件：以首字母区分，不同首字母放在不同文件，长度仍过长的继续按照次首字母进行拆分。这样一来，每个文件的每个数据长度相同且首字母尾字母也相同，就能保证数据被独立的分为了n个文件，且各个文件中不存在关键词的交集。

分别词频统计：对于每个文件，使用hash或者Trie树进行进行词频统计

小顶堆排序：依次处理每个文件，并逐渐更新最大的十个词



## 双十一大家都挤在0点抢，怎么处理高并发的？

- 一个域名，多个IP地址，映射多个机房
- Nginx实现负载均衡
- 分布式的系统，当每个微服务只执行单一化职能，并设置使用分布式中的限流，熔断，降级等功能。
  - 熔断：某个服务发生故障，导致不可用。下次调用该服务，则直接返回不可用结果。
  - 降级：高并发时，由于系统运行高并发，手动关闭一些非核心业务。来使得核心业务顺利执行
  - 限流：限制流速，限制请求数量
- SQL数据库使用集群，redis使用分布式缓存，使用搜索引擎ES
- 以云平台映射承载系统，若请求量过高，可以临时申请多台机器运行。【使用docker,和K8S，通过docker将服务打包成镜像，K8S来动态分发和部署镜像】



# 实习

- 比较难的点，成体系的描述问题以及回答
- 锻炼了解决线上问题的能力
- 回答问题的时候，往进公司的目的靠拢，比如说喜欢技术等等，拿出例子来，而不是侃侃而谈。
- 面试的时候，并不一定所有的问题都能回答上来，可以有一两个问题答不上来。但是有的问题，回答的要有亮点，而不是普普通通
- 有可能一些面试是压力面试，不要慌，考的就是临场应变能力。
  - 比如说批量查询，
- 而且不要过度从自身上找原因，有可能不是你的问题。
- 从梳理项目的东西，为什么会存在这个作战平台，它的作用是什么
- 面试遇到不会的问题，可以直接说【这个问题，我还不了解，回头我先学习一下这块内容】



## SQL慢查询优化

==SQL慢查询优化，查询请求由176ms，优化到33ms，性能提升81.25%，已上线；==

### SQL问题

先描述这个SQL语句,索引是index_status_time (order_status,create_time)，

```
select `所有字段`
from
  yx_order
where
  order_status = 50
  and update_time <= '2022-06-02 00:00:00'
  and valid = 1
order by
  create_time desc
limit
  20
```

- 查询类型也表明：simple简单的select查询。不涉及子查询或者联合查询

- 查询困难程度：ref。

- 涉及到的索引：index_status_time (order_status,create_time)
- rows：物理查询的行数。6.9w，将近7w
- key_len=4，命中索引的长度为4
- extra： using where  【使用where字段过滤】

**查询过程是，命中联合索引字段order_status，粒度很低，order by create_time可以快速查找出需要的字段，由于非聚簇索引，回表查询将近7w行，再where 过滤。执行时间变为170ms；**

explain SQL语句

<img src="../../../../../杂七杂八.assets/image-20220729153143070.png" alt="image-20220729153143070" style="zoom:200%;" />

### 分析问题

- 由于只有两个字段的索引，而且为等值查询，索引没失效，
  order_status 为int类型，不涉及类型转换
  符合最佳左前缀原则，不涉及！=或者大于小于，范围查询，函数计算的情况。
- 起初是，原本的两个字段的联合索引，替换为4个。在原有的status，create_time  的字段顺序不变，在后面添加字段，valid，update_time。【一定不能改变原来索引字段的顺序，因为改变顺序，可能会导致其他SQL查询变慢】
- 其实没有效果。因为order by已经是进行了排序，后续的索引就不会再使用。所以直接添加两个字段是不能解决问题的。

### 解决办法

- 所以使用了索引覆盖，和join连接

  ```
  select '所有字段'
  from
    yx_order a join (select id from yx_order 
    WHERE order_status = 50
  	AND update_time <= '2022-06-03 00:00:00'
  	AND valid = 1
  ORDER BY create_time DESC
  LIMIT 20) b on a.id=b.id
  ORDER BY a.create_time DESC
  ```

- <img src="其他.assets/image-20220729155551662.png" alt="image-20220729155551662" style="zoom:200%;" />

- 先查询2表，由于使用了索引覆盖，并且limit offset，count ，只返回查询到的id，所以，在查询1表时，只返回20行数据，在20行数据有可能是无序的，所以在order by一次。此时未命中索引。explain中extra中出现了using filesort，但是只有20行数据，并未产生临时文件，而且在查询时间降到了30ms

### 最大收获

- 由于mysql的性能优化，导致我们使用mysql查询时，是个黑箱操作，并不清楚内部如何查询的。也就是说，所有的索引优化的知识，只是书本上的知识，只有实际测试过后，真的速度变快了，才是有效的优化；
- 原本索引覆盖，只是作为一个知识点了解，我期初并未遇到过这种情况。然而这个SQL语句实际用到了，才明白，原来索引能这样用，不仅仅是简单的增加，删除索引字段
- 其实还有一点收获，这是我第一次请求虽然已经进行了验证，但仍然需要考虑线上出现问题的Plan B。所以在配置中心，添加一个Boolean变量，表明开关，来使用新SQL查询或者旧SQL查询。

## ~~任务文件导出~~

### ~~问题描述~~

- ~~使用人员反馈，在任务文件导出请求，超出一定阈值后【id阈值，或者说任务文件列表页的id】，请求失败，无法导出~~

### ~~问题分析~~

~~在发现这个问题时，首先发现，有些文件是可以导出，有些文件不能导出。那说明，请求能请求到，是生效的。是服务器内部错误~~

~~该请求过程是：~~

- ~~请求Nginx，再转发到相应的微服务~~
- ~~执行目标方法~~
  - ~~用户权限验证（没问题，因为有的文件能导出）~~
  - ~~从数据库获取数据~~
  - ~~上传至文件中心，并返回对应的url地址~~
- ~~返回对应的url地址~~

~~请求参数，是taskId=3313,不涉及请求参数溢出的情况。而且有的文件可以导出，说明有权限。所以问题出现在service层处理方法的过程。~~

~~**我查询了mttrace，链路追踪。**~~

~~方法内：~~

- ~~首先是查询一张表，根据参数能查询到1.5w的数据~~
- ~~在根据表中的参数id，查找到另外一张表中的状态。~~
  - ~~将第一张表中的数据进行遍历，查询每一条记录orderId的status状态。~~
  - ~~每次查询耗时2ms不到，1.5w次，差不多是30s。~~
- ~~将两个表的信息保存到Vo中。~~

~~整个请求的处理时间是30s。而Nginx设定的请求时间最长是20s。已经超时。所以无法返回给客户。但后台服务器已经执行，并保存到文件中兴，生成url地址。~~

### ~~解决办法~~

- ~~由于是线上问题，首先与管理Nginx的同事沟通，将Nginx的请求时间把原来的20s的请求时间改为60s。~~
- ~~然后从代码层面来改：将1.5w的请求改为批量查询，将多个orderId封装到一个list集合中。一次查询100次的请求。后续我们测试请求批次大小与响应时间的关系，分别测试了100,150，200,250,300...500.**发现随着请求批次大小增加，响应时间大体是一个减少的趋势。但考虑到mysql数据库处理的压力，以及查询数据量太大，网络传输问题，我们选择了批次=150**~~
  - ~~查询时，SQL语句使用了in和foreach。但仍出现了错误，未考虑请求为null的请求，若传入的list集合为~~
- ~~注意，即使传入list集合为null，也应该返回一个list空集合~~

## ~~OrgId切换~~

~~看技术文档~~

- ~~东西不难，但是复杂。~~

### ~~痛点（将近十几个微服务）~~

- ~~销售侧所有的平台都要切换orgId，但每个微服务切换时间不固定，所以，调用其他微服务和被其他微服务调用，所携带的orgId使用新OrgId还是旧orgId~~
- ~~应该需求完成上线后，统一orgId切换时间后，我们所有服务，能立刻切换新OrgId。要有plan B。上线后，若是其中一个微服务使用新orgId出现了问题，能够立即切换会旧orgId，来挽回损失。~~



### ~~解决办法~~

~~配置了四个Lion开关，上线流程分为多阶段~~

#### ~~lion开关~~

- ~~双写开关，人员侧orgId和基础侧orgId都写入数据库~~
- ~~流量入口开关，将request输入请求全部切换为基础侧OrgId还是人员侧orgId【入口表示的是，作战平台内部service处理使用新旧OrgId】~~
- ~~流量出口：http请求（前端请求）和thrift请求（thrift其他微服务调用）返回的数据中，避免字段的改变，否则改动太大。~~
  - ~~流量出口分为两个，是因为，前端获取orgId数据后，该orgId数据只会请求我们作战平台微服务。请求微服务时会重新获取。所以返回给前端的orgId新旧不影响其他操作~~
  - ~~但是被其他微服务调用，为避免请求的混乱，只能设置开关来决定使用新OrgId还是旧OrgId~~

#### ~~上线流程~~

- ~~上线后，开启双写开关，将新旧OrgId写入数据库，此时平台内部仍使用旧orgId~~
- ~~上线前，mysql，es添加新字段，采用定时任务的方式进行数据刷新；【先开启双写，再进行数据刷新，避免刷新后，再新增数据，新orgId没写入】~~
- ~~开启流量入口开关，将request请求携带的orgId转换成新OrgId，而且作战平台内部使用新orgId进行逻辑处理~~
- ~~没有问题后，开启前端请求的流量出口开关，前端请求的orgId转换成新OrgId，其他微服务请求作战平台时，仍使用旧orgId~~
- ~~等所有的平台都切换新OrgId后，开启其他微服务请求的流量出口开关，替换完成。最后将双写改为只写入新orgid~~

### ~~细节~~

- ~~我们的orgId的新旧映射需要请求其他微服务，若处理每一次orgid切换的请求都调用其他微服务，过慢。我们将请求保存在本地缓存中。~~
- ~~我们需要构建一个组织树，每天定时更新，每个节点保存orgId，parentOrgId和子节点集合的set集合。所以我们需要重新构建一个组织树，并不能将原组织树的orgId值替换。~~
  - ~~因为，每次只刷新一次组织树，若是替换，则可能导致刷新时使用旧OrgId构建组织树，后面我们开启流量入口开关，无法获取新orgId组织树节点。【所以此时需要构建两颗组织树】~~
- ~~存在前端与其他微服务都请求一个方法，而且无法没有携带orgId。我们可以根据请求参数来区分，是前端还是其他微服务~~
- ~~即使切换完成， 仍需要后续删除所有的冗余代码，涉及到orgId的部分都需要进行判断。将逻辑判断删除。工作量大~~
- ~~开启双写，在数据库（mysql，es）中添加新字段，还需要在BO，PO添加新字段。而且es部分不能只是开启开关能够进行数据替换的，而是与调用该数据的同事沟通，将orgId旧字段替换为新字段。~~
  - ~~作战平台是，从一个es索引中插入数据，从另一个es索引中获取数据。【维护数据但不获取，和获取数据但不维护，两个索引】所以需要分别与使用该es数据库的同事沟通替换新字段~~



**CAP定理：**分布式架构的基本理论。

指的是：一个分布式系统中，一致性（Consistency），可用性（Availability），分区容错性（Partition tolerance）。

![image-20220828145739974](其他.assets/image-20220828145739974-16616698616541.png)

只能保证CAP定理的两两组合，CAP不能同时满足：以电商为例：购买商品，需要订单系统创建订单，库存系统扣减库存。

- CP（一致性，分区容错性）：用户购买商品后，一直在页面等待，创建订单后，请求库存系统扣减库存。此期间用户一直等待，直到请求完成
- AP（可用性，分区容错性）：订单创建后，直接返回，不等待库存减少，扣减库存的工作交由异步线程处理
- AC（可用性，分区容错性）：不拆分系统，在一个数据库的一个事务完成该操作，即不使用微服务，而在一个服务中完成所有的操作



# ES 

## ES默认能查询到10000条数据

原因：ES一般是集群存在，那么查询10000条数据，每个节点都需要查询1000条数据，然后协调节点再重新组合数据，返回给用户，性能消耗太大，因而，不允许查询过多数据。分页查询 10000-10010，必然也是不允许的。分页查询也是查询0-10010的所有数据，协调节点再组合的。

## ES 全量查询

- **深度分页:**  即分页查询时，后面页数的数据。比如说总共10034页，查看第1000页。避免该方式，因为无论是ES还是MySQL，都是先查到前所有的数据，再舍弃x-1页的数据，返回第x页的数据。

### from size

分页查询，最简单的方式。需要查询 from+size条的数据，向每个分片都发配该请求，每个分片查询到自己的from+size的数据，返给协调者，协调者进行汇总、排序。抽取from后的第size条记录。

若是遇到深度分页，则无法使用该方法，因为过于危险，容易出现 ooo （out of Memory）

### Search After

Search After跟Scroll原理一致。

**使用**

- 使用必须指定排序（根据排序指定坐标）

- 必须从第一页开始搜起（若是随便一条记录开始搜，不知道它是属于全量数据的何处）

- 指定查询size为固定值，查询条件为 新增需要排序的字段。下次查询时，取此次查询的最后一条数据的时间作为查询条件。

  ```java
  将  order by time offset 0 limit 100，
  改写成 order by time where time>0 limit 100
  ```

也就是说全量查询是指定顺序的多次查询，每次查询是选择上次查询的结构最后一条数据将需要排序的字段作为此次查询的条件。

优点：**每次查询都是查第一页**，避免了舍弃前from条数据的性能损耗，几乎没有风险

缺点：同一个查询请求可能请求成百或者上千次，仍存在性能低的情况。

![img](其他.assets/webp)

### Scroll

与Search After查询类似，需要多次查询。

scroll 是将一次的查询结果快照缓存一段时间（可指定），返回值response 会返回scroll_id，下次请求时携带该scroll_id ，ES查询时从快照时查询，避免了从各个分片上查询数据。

**使用**

- 客户端向ES发起请求，指定快照生存时间，并查询数据。类似 `/{index}/_search?scroll=1m`
- ES 查询数据，并将所有数据聚合在协调者，过滤得到最后的数据
- 客户端再查询数据时，发起类似`/_search?scroll`的查询操作，每次查询返回上次查询返回的scroll_id，循环查询直到无结果返回
- 客户端向ES发起一个Delete的请求，向服务器表明查询已结束，清除快照缓存

**原理**

若是scroll 滚动查询，传的from字段会被ignore。ES内部设置了lastEmittedDoc 字段作为游标（与scroll_id相关联），以此确定游标位置。不需要像Search After，手动维护查询字段。但是需要每次修改scroll_id，也差不多了。与Search After 结果类似。









## ES修改映射

**ES中，映射不可被修改**。若非修改映射，则

1. 创建一个中间索引，包含自己需要的所有映射
2. 将数据，从旧索引中迁移到新索引中
3. 将旧索引删除，并把新索引更改名称叫旧索引名



**有实际用途吗？**

==**有，若是新增映射错误，或者原索引副本分片数量需要修改，则此时需要此操作**==

数据迁移

```es
POST _reindex
{
  "source": {
    "index": "old_index"
  },
  "dest": {
    "index": "new_index"
  }
}
```



# 需求设计



## 二维码扫码登录

使用场景：二维码通常是手机端应用扫描PC段或者web端的二维码，例如，微信登录，qq登录等 

### 二维码的本质

- 二维码登录本质商业之一种登录认证方式。最后肯定是获取cookie，请求我们的系统。
  - 告诉系统，是当前账号要登录
  - 向系统证明，当前账号可以安全登录
- 二维码，本质和一维码类似，都是“码”，即，都是一种字符串的表达方式。一维码只能表示数字，而二维码则是字符串，即任何字符了。



## 登录认证机制

为了安全起见，**手机端是不会存储账号的密码的**，只会保存登录的凭证token，毕竟，输入密码最终的目的也是获取该token。这也是为什么很多软件是不需要每次打开软件都登录的问题。一般只有重置软件，或者切换账号时，才需要重新登录，获取token。



### 账号登录认证机制

登录认证机制都是基于一个token的认证。

![图片](其他.assets/640wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1&random=0.8540285653208817&random=0.jpeg)

1. 客户端登录时会携带，账号、密码、设备信息传递给服务端
2. 服务器校验通过后，会返回一个唯一token，内部含有：账号信息，设备信息（设备ID，设备类型如IOS，Android，pc...）
3. 客户端会保存该token，软件启动时，会读取该token，这个token是长期有效地。【客户端完全没有保存你密码的必要】
4. 客户端在后续的请求服务时，会携带该token，进行身份校验，除了密码，还包括设备信息

### 二维码认证机制

PC端显示登录二维码，等待手机端扫描，手机端扫描后，手机端点击确认，PC端登录成功

![图片](其他.assets/640wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1&random=0.jpeg)

1. PC端向服务端发起请求，携带设备ID，设备类型等信息，服务器返回唯一性ID。【PC设备信息都包含在该ID中，但是没有账号信息，此时账号不确定】
2. 客户端收到的这个唯一性ID，展示成二维码，服务器会不断轮询访问服务器，请求服务端告诉当前二维码的状态及相关信息。【这也是为什么手机确认登录后，PC端需要等待下才能登录】
3. 手机端扫描该二维码，获取其中的唯一性ID信息，点击确认登录后，请求服务器，请求携带账号信息、唯一性ID
4. 服务器收到手机端的请求信息后，在PC端下次访问服务器，确认是否登录时，会返给PC端一个临时token
5. PC端根据该token，可以访问服务器资源



## ID生成器

首先谈到ID生成器，不能直接就是雪花算法，这是狭隘的视角。ID生成器生成的ID要求**唯一性**、**可排序**、**高性能**的ID。



- UUID
  - UUID虽然保证了唯一性，且高性能，但是无法排序。
- 数据库自增ID
  - 适合单机机器。保证了唯一性和可排序。若分库，则不是有个好的选择
- Redis incr 自增
  - 与数据库类似，但性能更高一些。但仍需每次都访问数据库或者Redis。

**目前适用于分布式主流的方式有两种**

- 通过方法预分配一段ID，来减少频繁的数据库或Redis操作
  - **方式**
  - 库中有张表信息，保存了各个表的id信息，获取ID时，首先冲数据库取对应表的ID信息，并保存在Map中，方便后续的取用
  - 每次获取ID，则从该Map中获取ID信息
    - 若存在该值，则自增Id
    - 若没有，则从数据库中查询，并保存在Map中；
    - 若ID超出 起始值+区间block，则从数据库重新取值，并将新起始值+区间block保存在在数据库，该处使用乐观锁，避免同时更新MaxId，并保存在Map中

- 雪花算法，根据时间生成唯一的ID。具体见「数据结构-雪花算法」



强推美团ID生成器 **Leaf，树叶**（世界上没有两片完全一样的树叶）。

- ### Segment模式 预分配ID段生成唯一ID

  - **优点**
    - 高吞吐量：通过预分配ID段，较少数据库的访问频率，适合并发场景。ID段用尽后，通过乐观锁，更新表中的Max ID信息，避免了并发问题
    - 数据库管理：ID段的最大值MaxId存在数据库中，方便更换ID格式、位数等信息，即方便管理
    - 时钟独立：该方式避免了雪花算法中时间回拨的问题
  - **缺点**
    - 存在对数据库的依赖，可能成为系统的瓶颈
    - 延迟问题：如果数据库出现问题，可能影响ID的分配
    - 复杂性：增加了单独管理各表ID的库表结构，以及实现ID段的管理逻辑。
    - 有序性：该方式生成的ID大体上是有序的，但仍存在机器A生成了ID 102，机器B生成了ID112（此时已经有ID112的记录），创建请求到了机器A，则仍创建103的记录。**即短时间内并不是有序的记录。**

  

- ### Snowflake 模式 雪花算法，根据时间、机房等信息生成唯一ID

  - **优点**
    - 无数据库依赖：雪花算法完全内存计算，不依赖数据库，性能高，延迟低
    - 全局唯一性：通过时间戳、机器ID和序列号的组合，确保了全局唯一性ID
    - 趋势递增：生成的Id是递增的，适合排序的场景
  - **缺点**
    - 时钟依赖：生成Id依赖时钟，若时间回拨，可能导致Id冲突
    - 机器Id配置：需要为每台机器配置唯一的机器ID，管理和配置复杂，如果是大规模集群中
    - 单点故障风险：若某个节点的时钟出现了问题，则可能影响整个系统的ID生成



**所有的ID就直接利用工具生成都可以适用吗？**

不是，如果仅仅作为唯一性ID标记，上述是可以的。如果有其他含义，比如美团的订单ID。很多人在用。涉及到分库分表。订单ID= 时间戳 + 用户ID后四位 + 随机数。美团的订单存在32个库，每个库有32张表。

- 用户ID后四位%32 找到对应的库
- 用户ID后四位/32 %32 找到该库下的对应的表

这样设计的原因是，订单的查询场景都是用户查看自己的订单，所以需要将当前用户的订单放在一张表里。PS：商家有商家的订单，并不是查这个用户订单库。



## 10亿数据如何快速插入MySQL？

首先确认10亿数据以什么形式存储。每条数据多大，是否有序导入，是否不能重复，数据库是否是MySQL。

假设和面试官明确后，有如下约束

-  10亿条数据，每条数据1Kb；
-  数据内容是非结构化的用户访问日志，需要解析后写入到数据库；

 **2、** 数据内容是非结构化的用户访问日志，需要解析后写入到数据库； **3、** 数据存放在`Hdfs`或`S3`分布式[文件存储](https://cloud.tencent.com/product/cfs?from_column=20065&from=20065)里； **4、** 10亿条数据并不是1个大文件，而是被近似切分为100个文件，后缀标记顺序； **5、** 要求有序导入，尽量不重复； **6、** 数据库是`MySQL`；



# 设计模式



## 策略模式

**查看审批流详情，使用的是策略模式。**

将核心算法抽取出来，针对不同的情景，执行不同的策略算法。使得某一种算法变化，而 不影响其他算法的使用



## 模版模式

**业务监控使用的就是模版模式**。泡茶与泡咖啡的流程相似。

- 泡茶的流程是：烧水，拿茶壶，放入茶叶，冲泡；

- 泡咖啡的流程：烧水，拿咖啡壶，放入可可，冲泡。

模版模式中模版流程是固定的，流程是相似的，只是有些步骤不同。将某些相近的步骤被写成抽象方法，放在具体的子类中实现



**定义了一个算法流程的框架，把一些可变节点交到具体的子类中去执行。**



- #### 策略模式与模版模式的区别：

  - 执行流程：模版模式按照一定的执行顺序执行，任何节点的重载不会影响顺序。策略模式，只提供了针对某个场景下的执行策略。即模版模式的一个执行步骤的具体实现
  - 可变节点：策略模式只有一个节点；模版模式有多个节点
  - 重载侧重点：模版模式要求算法流程中的某几个节点都可替换，但执行顺序不变；策略模式是整个算法均可替换



## 责任链模式

资质治理使用的就是责任链模式

走流程，需要走到各个部门处理，注意该处理是请求链路的每个节点，知道有对象处理它。手动的构建一个单向链。



## 工厂模式



## 适配器模式
