# 硬件结构

## 2.1 CPU 是如何执行程序的？（CPU）

![image-20221115212717013](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221115212717013-16685188548511.png)

冯诺依曼模型：运算器、控制器、存储器、输入设备、输出设备

运算器、控制器在CPU中，存储器==内存

- **内存：**
  - 数据和程序都在内存中存储，存储的区域是连续的，线性的。
  - 存储数据基本单位是字节（byte），每个字节对应一个内存地址，内存地址从0开始编号。与数组相似，读取内存中任何一个数据速度一样
- **中央处理器**：CPU
  - 位宽：32位、64位CPU为位宽，代表一次能计算多少bit的数据。 32位CPU一次可以计算4字节。
  - 控制单元（控制CPU工作）
  - 逻辑运算单元（负责计算）
  - 寄存器（内存的读取与写入速度与CPU相比仍太慢，所有CPU内部有寄存器方便读取，提高计算速度）
    - 通用寄存器：用来存放需要进行运算的数据，比如需要进行加和运算的两个数据。
    - 程序计数器：用来存储 CPU 要执行下一条指令「所在的内存地址」，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令的地址。
    - 指令寄存器：用来存放程序计数器指向的指令，也就是指令本身，指令被执行完成之前，指令都存储在这里。
- **总线**：CPU与内存和其他设备之间的通信需要通过总线
  - 地址总线：用于指定 CPU 将要操作的内存地址；
  - 数据总线：用于读写内存的数据；
  - 控制总线：用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线；
    - 当 CPU 要读写内存数据的时候，一般需要通过下面这三个总线：
      - 首先要通过「地址总线」来指定内存的地址；
      - 然后通过「控制总线」控制是读或写命令；
      - 最后通过「数据总线」来传输数据；
  - 总线：也有位宽，尽量与CPU位宽对应。32 位 CPU 最大操作内存为4GB

 **CPU 执行程序的过程**

1. CPU 读取「程序计数器」的值，这个值是指令的内存地址，然后 CPU 的「控制单元」操作「地址总线」指定需要访问的内存地址，接着通知内存设备准备数据，数据准备好后通过「数据总线」将指令数据传给 CPU，CPU 收到内存传来的数据后，将这个指令数据存入到「指令寄存器」。
2. 第二步，CPU 分析「指令寄存器」中的指令，确定指令的类型和参数，如果是计算类型的指令，就把指令交给「逻辑运算单元」运算；如果是存储类型的指令，则交由「控制单元」执行；
3. 第三步，CPU 执行完指令后，「程序计数器」的值自增，表示指向下一条指令。这个自增的大小，由 CPU 的位宽决定，比如 32 位的 CPU，指令是 4 个字节，需要 4 个内存地址存放，因此「程序计数器」的值会自增 4；
   - （为什么是4？ 因为32位CPU操作32位的bit信息，所以读取32bit的命令，即4字节。这个自增值是固定的）

**CPU执行指令分为四个阶段：**循环执行

1. CPU 通过程序计数器读取对应内存地址的指令，这个部分称为 **Fetch（取得指令）**；
2. CPU 对指令进行解码，这个部分称为 **Decode（指令译码）**；
3. CPU 执行指令，这个部分称为 **Execution（执行指令）**；
4. CPU 将计算结果存回寄存器或者将寄存器的值存入内存，这个部分称为 **Store（数据回写）**；



## 2.2 磁盘比内存慢几万倍？（存储器）

存储器有：硬盘（机械硬盘，固态硬盘）、内存、**CPU（寄存器、CPU L1/L2/L3 Cache(CPU高速缓冲)）**

速度： CPU高速缓冲>内存>硬盘

- **CPU内的寄存器**
  - 32位CPU中寄存器存储4字节，64位CPU中寄存器存储8字节。CPU中有多个寄存器，半个CPU时钟周期内完成读写操作
- **CPU高速缓冲**
  - CPU高速缓冲通过SRAM，静态随机存储器实现，速度快，1bit保存在6个晶闸管中，静态存储即通电则数据一直存在，断电则丢失。
  - ![image-20221118142233411](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221118142233411.png)
  - 一级缓存（数据缓存和指令缓存，分开存放）
    - 每个CPU核都有，距离CPU最近，读写速度比L2、L3更快，读写速度为2-4个时钟周期，与寄存器相近，大小为**几十Kb~几百Kb**
  - 二级缓存
    - 每个CPU核都有，访问速度相较于一级缓存较慢，读写速度在10~20个时钟周期，大小为**几百Kb~几Mb**
  - 三级缓存
    - 所有CPU核共享，访问速度最慢，为20~60时钟周期，通常大小在**几 MB 到几十 MB** 不等

- **内存**
  - 使用DRAM（动态随机存储器）实现。保存1bit数据仅需一个晶体管和一个电容即可。因为电容会漏电，所以需要定时刷新电容，保证数据不丢失，所以叫动态
  - 访问和刷新复杂，所以，内存速度在200~300个时钟周期之间。访问速度比CPU缓存慢很多
- 硬盘
  - 断电后，硬盘数据还在。内存，CPU寄存器，CPU高速缓存数据都丢失。
  - 内存读写速度是固态硬盘的10~1000倍，是机械硬盘的10w倍左右

![image-20221118184500806](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221118184500806.png)**每个存储器只和相邻的一层存储器设备打交道，并且存储设备为了追求更快的速度，所需的材料成本必然也是更高，也正因为成本太高，所以 CPU 内部的寄存器、L1\L2\L3 Cache 只好用较小的容量，相反内存、硬盘则可用更大的容量，这就我们今天所说的存储器层次结构**。



 **CPU L1 Cache 比内存快 `100` 倍左右**。



## 2.3 如何写出让 CPU 跑得更快的代码？（读取CPU缓存）

为什么有CPU缓存？

一次内存访问需要200~300个时钟周期，CPU与内存的访问速度相差过大，引入CPU高速缓存 



![image-20221118205324796](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221118205324796.png)

越靠近CPU核，速度越快

![image-20221118192826849](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221118192826849.png)

**程序执行时，首先将内存中的数据加载到共享的3级缓存，再加载到每个CPU核独有的2级缓存，最后进入1级缓存，最后被CPU读取操作。**

- **CPU缓存数据结构**
  - CPU缓存由多个缓存行（基本单位）构成。缓存行包括标志（Tag）+ 数据块（Data Block）。读取和写入数据以 Cache Line 缓存行为单位。缓存行一般为64byte数据，可以顺序加载数据到缓存行中。
  - **读取过程：**
  - ![image-20221118210915087](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221118210915087.png)
  - CPU如何判断内存中的数据是否在CPU中，以及该CPU缓存行的位置？**建立直接映射**
    - 将内存根据CPU缓存行的大小分割为多个内存块，将内存块的地址通过「取模运算」的方式映射到CPU缓存行中。
    - 多个内存块与一个CPU缓存行对应。
    - 该内存块地址包含CPU缓存行索引，组标记，偏移量信息
      - **CPU缓存行组成**
        - 组标记：区分不同内存块
        - 数据：实际加载的数据
        - 有效位：该CPU缓存行的有效位数
        - 索引：与内存块的映射关系
    - 映射方式有多种：全连接，组连接
  - **CPU访问内存地址步骤**
    1. 根据要读取的内存地址，计算CPU缓存行的索引，找到对应的CPU缓存行位置
    2. 找到位置后，读取CPU缓存行的有效位，确认是否有效，如果无效则直接访问内存。有效则继续执行
    3. 对比内存地址中的组标记是否与CPU缓存行的组标记相对应，确认该缓存行是与之对应的。否则，直接访问内存
    4. 根据内存地址的偏移量信息，从CPU缓存行中读取对应的字

- **如何写出让 CPU 跑得更快的代码？**即尽可能多的数据在CPU缓存中
  - CPU缓存分为：指令缓存和数据缓存，两个方面提高缓存命中率
    - 数据缓存：
      - CPU缓存行为顺序存储，在操作数据时也顺序操作访问
    - 指令缓存：
      - CPU自身有动态分支预测。有规律的条件分支语句能够让 CPU 的分支预测器发挥作用，进一步提高执行的效率；
  - 提高多核CPU的缓存命中率
    - 因为一个线程可能在不同的CPU核上执行，那CPU一二级缓存则失效，降低缓存命中率
    - 因此，**可以将线程绑定在一个CPU核上，只交由该核执行**



## 2.4 CPU 缓存一致性（写入CPU缓存）

- **CPU缓存和内存的一致性问题**解决办法（1，写直达   2，写回）
  - 写直达（同时写入内存和缓存）
    - 写入数据，首先判断CPU缓存中是否有该数据，如果有先更新缓存；再更新内存。
    - 优缺点：简单直观，但每次写操作都要写回内存，性能慢
  - 写回（当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中）
    - 写入缓存操作时，只有缓存不命中，需要将数据对应位置的缓存块保存到内存（多个内存块对应一个缓存块），从内存中读取要操作的数据到该缓存块。保存到内存时，只有为脏标记时，才更新到内存，否则不更新。
    - 如缓存命中，或者缓存不命中但原本缓存块数据不为脏，则直接写入缓存块，并标记为脏
    - **总的来说，只有将缓存中的数据进行替换时，且缓存数据为脏，才写入内存，一般情况下不写入，只是将缓存块中的数据标记为脏**，提高了性能
- **多核情况的缓存一致性问题**
  - CPU核的一二级缓存是独立不共享的。CPU对共享变量的操作由于采用写回方法，未及时更新到内存，所有数据不一致
  - 解决办法：（一种机制需要满足以下两点）
    - **写传播机制**：某一CPU核更新缓存后，传播到其他核的缓存中。常见实现方式：**总线嗅探**
    - **事务的串行化**：CPU核对数据的操作顺序，在其他核看来是顺序执行的，即对收到其他写传播的消息后，是按顺序不变的，避免多个核同时对一个数据操作，顺序发生变化。**「锁」实现**
- **总线嗅探**
  - 写传播的原则就是当某个 CPU 核心更新了 Cache 中的数据，要把该事件通过广播通知到其他核心。其他CPU核发现自己的缓存中有该数据，则也更新到自己的缓存。所有核监听总线的活动
- **MESI协议**
  - （已修改，独占，共享，已失效四个单词的首字母缩写，**表示缓存行的不同状态**）
    - 已修改：表示缓存块数据与内存数据不一致
    - 独占：缓存块中的数据是干净的，数据只保存在一个CPU核的缓存中，写入数据不用通知其他CPU核
    - 共享：缓存块中的数据是干净的，数据保存在多个CPU核中，
      - 「共享」状态代表着相同的数据在多个 CPU 核心的 Cache 里都有，所以当我们要更新 Cache 里面的数据的时候，不能直接修改，而是要先向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后再更新当前 Cache 里面的数据。
    - 已失效：缓存行中的数据是无效的



## 2.5 CPU 是如何执行任务的？

一个CPU有多个CPU核心，CPU读取数据到缓存中时，不是一个字节一个字节的读取的，而是以缓存行为单位读取的。CPU会将连续的数据加载到缓存行中，所以顺序操作访问元素，缓存行命中率高，提高性能。

![image-20221119162633807](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221119162633807.png)

- ### 缓存伪共享问题

  - 问题：假设，A,B两个变量在物理内存连续，且对应同一缓存行中，两个线程，一个操作变量A，另一个线程操作变量B。则该A,B数据保存到两个CPU核各自的缓存中。两个线程分别操作两个变量，该缓存行属于MESI 协议中的共享状态
    - ![image-20221119173415997](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221119173415997.png)
  - 线程1操作变量A，发现缓存行的状态为共享状态，则先通过总线发送消息给CPU核2，将CPU核相同缓存行的状态改为已失效，再修改本CPU核缓存行的数据毛病将状态改为已修改
    - ![image-20221119173554227](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221119173554227.png)
  - 线程2操作变量B，则该CPU核缓存行状态为已失效状态，并且CPU核1缓存行有相同数据，数据为已修改状态，则需要CPU核1缓存行数据保存到内存中，CPU核2再从内存中读取数据到缓存中。最后，CPU核2修改数据，先将CPU核1中的缓存行改为失效状态，再将本CPU核缓存行的数据修改，状态改为已修改状态
  - ![image-20221119173932468](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221119173932468.png)
  - 如果线程1,2交替修改A,B变量，则重复执行修改缓存行状态，并写入内存，另外一个CPU核从内存中读取数据再修改的过程。**缓存行未起到应有效果**
  - 这种因为多个线程同时读写同一个 Cache Line 的不同变量时，而导致 CPU Cache 失效的现象称为**伪共享**

- ### 避免伪共享的方法

  - 采用宏定`__cacheline_aligned`使得变量在缓存行中是对齐的，即原本A，B两个在一个缓存行中，现在在两个缓存行中。java实现方式是：「字节填充 + 继承」
  - 避免 Cache 伪共享实际上是用空间换时间的思想，浪费一部分 Cache 空间，从而换来性能的提升

- 系统中需要运行的多线程数一般都会大于 CPU 核心，这样就会导致线程排队等待 CPU，这可能会产生一定的延时，如果我们的任务对延时容忍度很低，则可以通过一些人为手段干预 Linux 的默认调度策略和优先级。

- 修改优先级： 线程优先级 = 旧的优先级+修改值。所以修改值可以为负值

  - 启动任务时指定优先级  nice -n 修改值
  - 修改已经运行的任务优先级： renice 修改值 -p <进程PID>    

## 2.6 什么是软中断？

中断：响应硬件的中断请求，打断正在执行的进程，并调用内核中的中断程序来响应请求。**中断处理程序时可能会关闭中断，即未执行完中断处理程序前，会丢失中断请求**

- 为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」。

  - 硬中断：快速处理硬件的中断（主要是负责耗时短的工作，特点是快速执行）
  - 软中断：延迟处理未完成的工作，由内核触发（主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行）
  - 软硬中断的另一个区别：硬中断会打断CPU正在执行的任务，立马执行中断程序。软中断是以内核线程的方式执行

- 软中断：

  - 类型：网络接收中断，网络发送中断，定时中断，RCU锁中断，内核调度中断

- 每一个 CPU 都有各自的软中断内核线程，我们还可以用 ps 命令来查看内核线程，一般名字在中括号里面到，都认为是内核线程。

  如果在 top 命令发现，CPU 在软中断上的使用率比较高，而且 CPU 使用率最高的进程也是软中断 ksoftirqd 的时候，这种一般可以认为系统的开销被软中断占据了。

  这时我们就可以分析是哪种软中断类型导致的，一般来说都是因为网络接收软中断导致的，如果是的话，可以用 sar 命令查看是哪个网卡的有大量的网络包接收，再用 tcpdump 抓网络包，做进一步分析该网络包的源头是不是非法地址，如果是就需要考虑防火墙增加规则，如果不是，则考虑硬件升级等。



## 2.7 为什么 0.1 + 0.2 不等于 0.3 ？

- 为什么负数要用补码表示？

  - int类型数字，最高位为符号标志位，剩下的31位表示二级制数字。负数用补码表示？
  - 问：明明有符号位为什么还要用补码嘞，符号位不就可以区分正负了吗？
    - 答：符号位可以区分正负，但在正负数加减时，负数不能作为加法，而是减法。因此，需要多进行一步判断，是否为负数，否则加减法转换。为了性能考虑，应简化此过程。
    - 而选择补码后，**对于负数的加减法操作，实际上是和正数加减法操作一样的**

- 十进制小数怎么转成二进制？

  - 小数怎么求二进制？ 乘二取整法
  - **由于计算机的资源是有限的，所以是没办法用二进制精确的表示 0.1，只能用「近似值」来表示，就是在有限的精度情况下，最大化接近 0.1 的二进制数，于是就会造成精度缺失的情况**。

- 计算机是怎么存小数的？

  - 计算机存储小数采用浮点数，即小数点是可以移动位置的， 1000.101 B = 1.000101 x 2^3 B  

  - 浮点数表示方法：

    - 二进制格式：   `1.000101 x 2^3 `    
    - `000101` 称为**尾数**，即小数点后面的数字；
    - `3` 称为**指数**，指定了小数点在数据中的位置；

  - 格式：![image-20221120114355665](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221120114355665.png)

    - 符号位：表示正负

    - 指数位：指定了小数点在数据中的位置，指数位越长，则数值表达的范围就越大。可以为正负值，所以有符号位，可以视为无符号位存在偏移量

    - 尾数位：数字规范化后的数值，表示为1.0010 B,通过指数位移动小数点位置

    - ![image-20221120115319249](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221120115319249.png)

    - ### float与double的区别：

    - **float用32位表示，double用64位表示。尾数位分别为24和53位**。存在固定隐含位（尾数位中，均为1.xxx,可以将整数1去掉，提高表示精度）

    - 所以它们的精度在十进制中分别是 `log10(2^53)` 约等于 `15.95` 和 `log10(2^24)` 约等于 `7.22` 位，**因此 double 的有效数字是 `15~16` 位，float 的有效数字是 `7~8` 位，这些有效位是包含整数部分和小数部分；**

    - ![image-20221120114703767](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221120114703767.png)

    - 

- 0.1 + 0.2 == 0.3 吗？

  - 不是所有的小数都能完整由二进制表示。所以计算机对于一些数值只能用近似值表示。0.1和0.2均是近似值，则两个近似值相加，必然也得到了一个近似数  而不是0.3





# 操作系统结构

操作系统核心为内核，内核是连接硬件设备的桥梁。应用程序只关心与内核的交互，不必关心硬件细节。

- 内核的功能：
  - 管理进程的能力
  - 管理内存的能力
  - 管理硬件设备的能力
  - 提供系统调用
- 操作系统：内核具有很高权限，可以控制CPU，内存和硬件；应用程序权限很小
  - 内核空间：只有内核程序可以访问
  - 用户空间：应用程序使用

- 用户态与内核态的转换过程：
  - 系统调用时，触发中断，由用户态到内核态的转换，

![image-20221120171133332](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221120171133332.png)

- 宏内核，包含多个模块，整个内核像一个完整的程序；
- 微内核，有一个最小版本的内核，一些模块和服务则由用户态管理；
- 混合内核，是宏内核和微内核的结合体，内核中抽象出了微内核的概念，也就是内核中会有一个小型的内核，其他模块就在这个基础上搭建，整个内核是个完整的程序；

Linux 的内核设计是采用了宏内核，Window 的内核设计则是采用了混合内核。

这两个操作系统的可执行文件格式也不一样， Linux 可执行文件格式叫作 ELF，Windows 可执行文件格式叫作 PE

# 内存管理

##  4.1 为什么要有虚拟内存？

**单片机的 CPU 是直接操作内存的「物理地址」**。

- 逻辑地址：程序使用的地址
-  物理地址：实际硬件中的空间地址



- ### 操作系统是如何管理虚拟地址与物理地址之间的关系？

  - 两种方式：内存分段和内存分页

- #### 内存分段

  - 将程序分为代码分段，数据分段，栈段，堆段。虚拟地址通过**段表**与物理地址进行映射
  - 缺点：
    - **内存碎片**
      - 内存是分段，但内存段没有固定大小。段内没有内存碎片，但有外部内存碎片（由于每个端的长度不固定，则多个段未必能恰好使用所有的内存空间，会产生多个不连续的小内存段，使得总空闲内存是有的，但不连续导致无法加载新程序的问题）。
    - 内存交换效率低
      - 虚拟内存中，将内存与硬盘的空间交换。需要将连续的内存数据写入到磁盘，硬盘读写效率低

- #### 内存分页

  - **分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。linux下，为4Kb
  - 虚拟地址与物理地址之间通过**页表**来映射
  - 当进程访问的虚拟地址在页表中查不到时，系统会产生一个**缺页异常**，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。
  - 分页是怎么解决分段的「外部内存碎片和内存交换效率低」的问题？
    - 页是紧密连接的，所以没有外部内存碎片，**但有内部碎片**，因为页为内存分配的单位，若不足一页时，也分配一页。但页占用比较小，所以内存浪费小
    - 内存交换率低的问题：操作系统会把其他正在运行的进程中的「最近没被使用」的内存页暂时写在硬盘上，称为**换出**。一旦需要的时候，再加载进来，称为**换入**。所以一次写入磁盘只有少数的几页，效率较高
  - 缺点：**页表占用空间过大**
    - 页表需要虚拟地址与物理地址的映射。每个进程都要一个页表映射（因为虚拟地址相同，而物理地址不同）。页表都是MB单位大小。则多个进程，则占用内存更多。
    - 解决办法：
      - **多级页表**：（64位系统是4级目录）降低页表的空间占用
        - 一级页表是虚拟地址和二级页表的映射。二级页表是二级页号与物理页号的映射。
        - **多级页表，由于一些一级页表项没有使用到，所以并不会创建对应的二级页表，所以节省了空间**
        -  64 位的系统,4级目录
          - 全局页目录项 PGD（*Page Global Directory*）
          - 上层页目录项 PUD（*Page Upper Directory*）
          - 中间页目录项 PMD（*Page Middle Directory*）
          - 页表项 PTE（*Page Table Entry*）
      - TLB   快表(高速寄存器) 提高虚拟地址与物理地址的转换
        -  有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。

- ### 段页式内存管理

  - 将内存分段与内存分页结合在一起。将程序分为多个有逻辑意义的段，每个段再分为多个页

- ### Linux的内存管理方式

  - **Linux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理**。
  - 32 位操作系统和 64 位操作系统的虚拟地址空间大小是不同的，在 Linux 操作系统中，虚拟地址空间的内部又被分为**内核空间和用户空间**两部分，如下所示：
    - `32` 位系统的内核空间占用 `1G`，位于最高处，剩下的 `3G` 是用户空间；
    - `64` 位系统的内核空间和用户空间都是 `128T`，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。
  - ![image-20221122091832669](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221122091832669.png)
  - **应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。只有在CPU访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存和物理内存之间的映射关系**

  - Linux 系统中虚拟空间分布可分为**用户态**和**内核态**两部分，其中用户态的分布：代码段、全局变量、BSS、函数栈、堆内存、映射区。
  - 用户空间内存，从**低到高**分别是 6 种不同的内存段：入图所示：
    - 程序文件段，包括二进制可执行代码；
    - 已初始化数据段，包括静态常量；
    - 未初始化数据段，包括未初始化的静态变量；
    - 堆段，包括动态分配的内存，从低地址开始向上增长；
    - 文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关 ）；
    - 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 `8 MB`。当然系统也提供了参数，以便我们自定义大小；
  - **栈，文件映射，堆，由于运行程序，可以在是这三段内存中申请空间**
  - ![image-20221121153700644](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221121153700644.png)



## 4.2 malloc 是如何分配内存的？

- `32` 位系统的内核空间占用 `1G`，位于最高处，剩下的 `3G` 是用户空间；
- `64` 位系统的内核空间和用户空间都是 `128T`，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。

每个进程都各自有独立的虚拟内存，但是**每个虚拟内存中的内核地址，其实关联的都是相同的物理内存**。

![image-20221121151829677](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221121151829677.png)

`malloc()` 或者 `mmap()` ，就可以分别在堆和文件映射段动态分配内存

**发音问题：**

malloc()   // 买哦辣可 函数

mmap   // m买破  

brk  // break的发音

- ### malloc()是如何分配内存的？

  - malloc()不是系统调用，是C语言里一个函数，用于动态分配内存
  - malloc 申请内存的时候，会有两种方式向操作系统申请堆内存。
    - 方式一：通过 **brk()** 系统调用从堆分配内存
    - 方式二：通过 **mmap()** 系统调用在文件映射区域分配内存；
    - **分配内存小于128Kb时，用brk()函数，大于128Kb时，用mmap()函数**
  - **brk() 函数**将「堆顶」指针向高地址移动，获得新的内存空间
    - ![image-20221121153610842](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221121153610842.png)
  -  **mmap()** 通过系统调用中「私有匿名映射」的方式，在文件映射区内部分配一块内存，也就是从文件映射区“偷”了一块内存。如下图：
    - ![image-20221121154054437](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221121154054437.png)

- ### malloc() 分配的是物理内存吗？

  - 不是，**malloc() 分配的是虚拟内存**。
  - 分配虚拟内存如果没有被访问，则不会映射到物理地址上，也不会占用物理内存空间
  - **只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存和物理内存之间的映射关系**

- ### malloc(1) 会分配多大的虚拟内存？

  - 会申请与用户预申请的字节数更多的空间

- ### free 释放内存，会归还给操作系统吗？

  - malloc 通过 **brk()** 方式申请的内存，free 释放内存的时候，**并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用**；
  - malloc 通过 **mmap()** 方式申请的内存，free 释放内存的时候，**会把内存归还给操作系统，内存得到真正的释放**。

- ### 为什么不全部使用 mmap 来分配内存？

  - **频繁通过 mmap 分配的内存话，不仅每次都会发生系统态和用户态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大**。
  - 所以使用brk()函数时，可以直接从内存池中取出对应的内存块即可。减少了系统调用次数

- ### 既然 brk 那么牛逼，为什么不全部使用 brk 来分配？

  - brk()函数的缺点：
  - 如果连续申请了 10k，20k，30k 这三片内存，如果 10k 和 20k 这两片释放了，变为了空闲内存空间，如果下次申请的内存小于 30k，那么就可以重用这个空闲内存空间。但小于30k，**就存在内存碎片**
    - ![image-20221121164820362](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221121164820362.png)

- ### free() 函数只传入一个内存地址，为什么能知道要释放多大的内存？

  - malloc 返回给用户态的内存起始地址比进程的堆空间起始地址多了 16 字节，该16 字节就是保存了该内存块的描述信息，比如有该内存块的大小。

## 4.3 内存满了，会发生什么？（内存分配过程）

### 内存分配的过程是怎样的？

1. 应用程序通过malloc()函数申请内存，实际申请的是虚拟内存，并没有分配物理内存
2. 在应用程序读写该块虚拟内存时，CPU访问该虚拟内存在，则发现没有该物理内存，则触发缺页中断，则中断处理时：**首先判断是否有空闲的物理内存**
   1. 有，直接分配物理内存，并建立虚拟内存与物理内存的映射
   2. 没有，内核进行回收内存的工作，两种回收方式: 直接内存回收和后台内存回收
      1. **后台内存回收**（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程**异步**的，不会阻塞进程的执行。
      2. **直接内存回收**（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是**同步**的，会阻塞进程的执行。
3. 回收后，仍空间不足，会触发**OOM （Out of Memory）机制**。会选择占用物理内存较高的进程 ，将其杀死，释放内存资源，如果还不足，会继续杀死进程。

<img src="%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221121171337055.png" alt="image-20221121171337055" style="zoom:80%;" />

### 哪些内存可以被回收？

可以回收的内存类型分为文件页和匿名页。

- 文件页：内核缓存的磁盘数据和 内核缓存的文件数据，可以直接释放内存，如果有需要再从磁盘读取即可。**回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存**。
- 匿名页：回收方式是通过linux的交换机制，保存到磁盘中，需要再次访问时，重新从磁盘中读入

回收选择算法是：LRU 最久未访问算法。

回收内存操作基本都会发生磁盘IO操作。势必影响操作系统性能。

### 尽早触发 kswapd 内核线程异步回收内存

- **尽早触发kswapd 内核线程异步回收内存**，来避免应用程序直接内存回收
- 内核选择三个指标，来判断是否执行kswapd 内核线程
  - 页最小阈值（pages_min）
  - 页低阈值（pages_low）
  - 页高阈值（pages_high）
  - ![image-20221122095006866](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221122095006866.png)
- 如果剩余内存（pages_free）在页低阈值（pages_low）和页最小阈值（pages_min）之间，说明内存压力比较大，剩余内存不多了。**这时 kswapd0 会执行内存回收，直到剩余内存大于高阈值（pages_high）为止**。异步执行
- 如果剩余内存（pages_free）小于页最小阈值（pages_min），说明用户可用内存都耗尽了，此时就会**触发直接内存回收**，这时应用程序就会被阻塞，因为两者关系是同步的。



- ### 针对回收内存导致的性能影响，常见的解决方式。

  - 设置 /proc/sys/vm/swappiness，调整文件页和匿名页的回收倾向，尽量倾向于回收文件页；
  - 设置 /proc/sys/vm/min_free_kbytes，调整 kswapd 内核线程异步回收内存的时机；
  - 设置 /proc/sys/vm/zone_reclaim_mode，调整 NUMA 架构下内存回收策略，建议设置为 0，这样在回收本地内存之前，会在其他 Node 寻找空闲内存，从而避免在系统还有很多空闲内存的情况下，因本地 Node 的本地内存不足，发生频繁直接内存回收导致性能下降的问题；
  - 

  

### 如何保护一个进程不被 OOM 杀掉呢？

内存不足时，触发OOM机制后，会根据算法选择一个进程杀掉。

```c
// points 代表打分的结果
// process_pages 代表进程已经使用的物理内存页面数
// oom_score_adj 代表 OOM 校准值
// totalpages 代表系统总的可用页面数
points = process_pages + oom_score_adj*totalpages/1000
```

**用「系统总的可用页面数」乘以 「OOM 校准值 oom_score_adj」再除以 1000，最后再加上进程已经使用的物理页面数，计算出来的值越大，那么这个进程被 OOM Kill 的几率也就越大**。



每个进程的 oom_score_adj 默认值都为 0，**我们可以通过调整 oom_score_adj 的数值，来改成进程的得分结果**：可以将校准值设为负数，降低被杀掉的概率



## 4.4 在 4GB 物理内存的机器上，申请 8G 内存会怎么样？

- **在 32 位操作系统、4GB 物理内存的机器上，申请 8GB 内存，会怎么样？**
  - 申请不到，进程只能申请3GB大小的虚拟内存空间，会申请虚拟内存失败。
- **在 64 位操作系统、4GB 物理内存的机器上，申请 8G 内存，会怎么样？**
  - 申请内存是申请虚拟内存，只要不访问该虚拟内存，则不会分配物理内存。可以申请成功。如果访问该虚拟内存后，才会进行物理内存分配。如果申请的物理内存超过了实际空闲内存，则看是否开启swap机制：
  - 没有开启swap机制，则程序直接OOM
  - 开启了swap，程序正常运行。
- **swap机制**：将内存数据换入到磁盘，又从磁盘中恢复数据到内存的过程
  - 场景： 
    - **物理内存不足**时，选择**LRU算法**选择最不常用的内存页回收，是强制的直接内存回收（Direct Page Reclaim）。直接内存回收是同步的过程，会**阻塞**当前申请内存的进程。
    - **物理内存闲置**时，程序启动时，大量内存在启动后不会使用，则通过kSwapd 守护线程将内存保存到磁盘。在空闲内存低于一定比例后，回收内存页，保证其他进程可以申请到内存。kSwapd 是后台进程，所以回收内存的过程是异步的，不会阻塞当前申请内存的进程。
  - swap分区为硬盘的独立区域，只用于交换内存。大小是可以动态变化的。



## 4.5 如何避免预读失效和缓存污染的问题？



- **「预读失效」导致缓存命中率下降**
- **「缓存污染」导致缓存命中率下降**

LRU算法：**最久未使用淘汰算法**

- **预读机制**

  - 定义：会一次性多读取后续的数据，减少IO次数，提高性能

    - 应用程序只想读取磁盘上文件 A 的 offset 为 0-3KB 范围内的数据，由于磁盘的基本读写单位为 block（4KB），于是操作系统至少会读 0-4KB 的内容，这恰好可以在一个 page 中装下。
    - 但是操作系统出于空间局部性原理（靠近当前被访问数据的数据，在未来很大概率会被访问到），会选择将磁盘块 offset [4KB,8KB)、[8KB,12KB) 以及 [12KB,16KB) 都加载到内存，于是额外在内存中申请了 3 个 page；

  - **预读失效问题**

    - 如果预读的页没有被访问，则预读失效。但由于LRU算法，会添加到链表的前排位置，而淘汰末尾的页。如果该页时热点数据，则降低了缓存命中率

  - 解决办法：

    - **将预读页停留在内存中的时间尽可能短，让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在内存里的时间尽可能长**。linux和mysql都有优化，方法不同

    - linux：
      - 实现了两个LRU链表：**活跃 LRU 链表和非活跃 LRU 链表**，活跃LRU链表：存放最近被访问过（活跃）的内存页；非活跃LRU链表：存放很少被访问的内存页
      - 预读页添加到非活跃LRU列表头部，当页真的被访问后，才添加到活跃LRU链表。如果一直没访问，则从非活跃LRU列表中删除，且不影响活跃LRU列表数据。【活跃LRU链表删除末尾数据后，添加到非活跃LRU列表】
    - MySQL：
      - **将LRU链表分为young区域和old区域**，young 区域在 LRU 链表的前半部分，old 区域则是在后半部分，这两个区域都有各自的头和尾节点，如下图：
      - 预读的页只需要加入到old区域的头部。当页被真正访问
      - ![image-20221122111959326](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221122111959326.png)

- **缓存污染**

  - 定义：

    - 在批量读取数据时，大量的页添加到LRU列表头部，可能这些数据值访问一次，之前存储的热点数据全部被淘汰，则整个LRU表就被污染了。

  - 问题解决：

    - 出现问题的原因在于，进入活跃LRU列表的门槛太低了，

    - **Linux 操作系统**：

      - 在内存页被访问**第二次**的时候，才将页从 inactive list 升级到 active list 里。

    - MySQL Innodb：

      - 在内存页被访问第二次的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行停留在 old 区域的时间判断：

        - 如果第二次的访问时间与第一次访问的时间**在 1 秒内**（默认值），那么该页就**不会**被从 old 区域升级到 young 区域；

        - 如果第二次的访问时间与第一次访问的时间**超过 1 秒**，那么该页就**会**从 old 区域升级到 young 区域；



## 4.7 深入理解 Linux 虚拟内存管理

###  1. 到底什么是虚拟内存地址

64位虚拟地址的格式为：全局页目录项（9位）+ 上层页目录项（9位）+ 中间页目录项（9位）+ 页表项（9位）+ 页内偏移（12位）。共 48 位组成的虚拟内存地址。

32 位虚拟地址的格式为：页目录项（10位）+ 页表项（10位） + 页内偏移（12位）。共 32 位组成的虚拟内存地址。

### 2. 为什么要使用虚拟地址访问内存

### 3. 进程虚拟内存空间



# 进程管理 

## 5.1 进程、线程基础知识

**并行与并发**

![image-20221122203557223](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221122203557223.png)

- ### 进程

  - 编写的代码存储在硬盘的静态文件中，通过编译，会生成二进制可执行文件。当运行该文件时，它被装载到内存中，CPU会执行程序的每一条指令，该运行的程序为进程
  - **进程控制模块**：PCB描述进程信息，是进程存在的唯一标识
    - 进程标识符，用户标识符
    - 进程当前状态，进程优先级
    - 有关内存地址空间信息，打开的文件列表，IO设备信息
    - **CPU中各个寄存器的值也保存在PCB中，以便重新执行时，能从断点处继续执行**
  - **相同状态的进程通过PCB链在一起，组成各种队列，就绪队列，阻塞队列**
  - **进程上下文切换的内容**
    - 先进行CPU的上下文切换，将当前进程的CPU寄存器和程序计数器保存起来，再加载新任务的CPU上下文的寄存器和程序计数器，最后跳到程序计数器所指的位置，运行新任务
    - 进程的切换，将堆栈，全局变量等用户空间的资源，还包括内核堆栈，寄存器等内核资源
  - 进程切换场景
    - 进程调度
    - 资源不足时，进行堵塞
    - sleep方法自己主动挂起
    - 优先级更高的进程开始执行
    - 发生中断

- ### 线程

  - 优点
    - 一个进程有多个线程
    - 线程可以并行执行
    - 各线程之间共享地址空间和文件资源
  - 线程的实现：用户线程，内核线程，轻量级线程

- ### 调度

  - 



## 5.2 进程间有哪些通信方式？

##  5.3 多线程冲突了怎么办？

## 5.6 一个进程最多可以创建多少个线程？

- 32 位系统，用户态的虚拟空间只有 3G，如果创建线程时分配的栈空间是 10M，那么一个进程最多只能创建 300 个左右的线程。
- 64 位系统，用户态的虚拟空间大到有 128T，理论上不会受虚拟内存大小的限制，而会受系统的参数或性能限制。



##  5.7 线程崩溃了，进程也会崩溃吗？

线程非法访问内存引起崩溃，则进程会崩溃。各个线程的地址空间是共享的。某个线程对共享的地址的非法访问会导致内存的不确定性，进而影响其他线程。所以进程也会崩溃

杀死一个进程采用，`kill -9 pid`，向指定pid进程发送终止信号，信号为9.



- 进程停止机制
  1. CPU执行正常的进程指令
  2. 通过kill系统调用向进程发送信号
  3. 进程收到操作系统发的信号，CPU暂停当前程序运行，并将控制权交给操作系统
  4. 调用kill 系统调用向进程发送信号
  5. 操作系统根据情况执行相应的信号处理程序（函数），一般执行完信号处理程序逻辑后让进程退出
     1. **如果进程没有注册自己的信号处理函数，则操作执行执行默认的程序，如果有注册编写的，则执行自己的信号处理函数**



JVM中自定义了信号处理函数，这样当发送 kill pid 命令（默认会传 15 也就是 SIGTERM）后，JVM 就可以在信号处理函数中执行一些资源清理之后再调用 exit 退出。



如果发生 stackoverflow 还有空指针错误，确实都发送了 SIGSEGV，只是虚拟机不选择退出，而是自己内部作了额外的处理，即**恢复了线程的执行，并抛出stackoverflow 还有空指针错误**。主要原因是这个错误实在太普遍了，如果因为常见的错误而导致进程崩溃，则JVM宕机多次。

