# 1，java

## 容易遗忘

- static修饰的成员变量，在[类加载](https://so.csdn.net/so/search?q=类加载&spm=1001.2101.3001.7020)时会被分配到数据区的方法区。没被status修饰，保存在堆内存中，局部变量保存在栈内存中

- 重载和重写
  - 重载：在一个类中，方法名相同，参数列表不同，返回值和访问权限可以不同
  - 重写：子类重写父类的方法，
    - 方法名和参数列表必须相同，返回值相同，可以是返回值的子类
    - 抛出异常小于等于分类，访问权限大于等于父类
    - 如果父类方法访问修饰符为 `private/final/static` 则子类就不能重写该方法，但是被 `static` 修饰的方法能够被再次声明。

- 多态：父类类型 变量名=new 子类类型();

## 接⼝和抽象类的区别是什么？

- 相同点：
  - 接口和抽象类都不能实例化，只能被继承/实现
  - 都可以包含抽象方法，等待继承类重写该方法
- 不同点：
  - 抽象类可以有普通方法的实现，接口不是实现
  - 抽象类成员变量可以是多种，接口的成员变量必须是 **public static final** ，必须赋值，没有默认值
  - 抽象类可以有构造器，接口没有。而且可以有初始化代码块，接口没有
  - 接口可以实现多个，类只能继承一个



## a=a+b与a+=b有什么区别吗?

- **+= 操作符将加操作的结果类型强制转换为持有结果的类型**
- a=a+b则不会自动进行类型转换

![image-20220428090051260](%E5%A4%8D%E4%B9%A0.assets/image-20220428090051260.png)

**为什么两个short类型相加会自动提升为int？**

与jvm指令集有关，较小的数据类型基本只用于数组，为较小的类型引入专门的计算逻辑不值得，所以全部转换为int



##  1.2 一个Java文件里可以有多个类吗（不含内部类）？

一个java文件中可以定义多个类，但是最多只有一个类被public修饰，并且这个类的类名与文件名必须相同，



#### 单例设计模式

饿汉式单例设计模式:

先创建出对象，什么时候调用方法，则返回该对象，但会出现一直占用内存的问题。因为类加载则创建对象。一直在内存中，等待调用

```java 
class Bank{
    //私有化构造器
    private Bank(){}
    //内部创建私有化类对象
    private static Bank instance = new Bank();
    //静态方法只能调用静态属性，单例设计模式只能获取一个对象
    //即使多次调用该静态方法，返回一个对象
    public static Bank getBank(){
        return instance;
    }
}
```

懒汉式设计模式：

什么时候调用，则再加载，但会出现线程安全问题（可能同时调用getBank，则可能会出现创建两个Bank对象，不满足单例设计模式的要求）。

不止是考虑线程安全的问题，还要考虑jvm中的指令重排

```Java
public final class Singleton {
  private Singleton() { }
  private volatile static Singleton INSTANCE = null;
  public static Singleton getInstance() {
    // 实例没创建，才会进入内部的 synchronized代码块
    if (INSTANCE == null) {      
      synchronized (Singleton.class) {
        // 也许有其它线程已经创建实例，所以再判断一次
        if (INSTANCE == null) {
          INSTANCE = new Singleton();
       }
     }
   }
    return INSTANCE;
}
}
```

## Java创建对象的几种方式：

1. new 对象
2. 通过反射创建对象
3. clone()方法创建对象
4. 反序列化创建对象
   1. 将创建一个新的对象，并将序列化流中的信息保存在新对象中



### PriorityQueue是否真正有序

```Java
public class A {
    public static void main(String[] args) {
        //设置队列的初始长度为10
        PriorityQueue<Integer> queue = new PriorityQueue<>(10);
        //入队
        for(int i=10;i>=5;i--)
            queue.offer(i);
        //遍历元素
        for(Integer i:queue)
            System.out.print(i+" ");
    }
}
//输出结果：5 7 6 10 8 9

```

PriorityQueue的底层是object数组通过最小堆实现有序输出。数组并不是有序的。所以最小堆，只能实现根节点为最小值，并不能保证它的左右节点谁大谁小。也就是说PriorityQueue内部的数据是无序的。**每次从队列中取出的是具有最高优先权的元素而已。**

最大堆：根结点的键值是所有堆结点键值中最大者。

最小堆：根结点的键值是所有堆结点键值中最小者。

![image-20220322074629817](%E5%A4%8D%E4%B9%A0.assets/image-20220322074629817.png)

## **三种权限修饰符**

- public，表示所有其他类都可以访问。
- protected，当前类或子类可以访问，同时相同包内的其他类也可以访问protected成员；
- default，默认（没有修饰符）：表示本包内可以使用
- private，表示的是在本类内可以使用；

## final、finally、finalize区别

- **final**
  - final修饰类，方法，变量，final关键字提高性能。
  - 修饰类：不能被继承，类中的所有方法不能重写（不能继承当然不能重写），但可以重载，不能abstract和final同时修饰类。（abstract类就是为了被继承，final不能被继承，两个作用相反）
  - 修饰方法：不能被重写，但子类可以调用该方法
  - 修饰变量：该变量不可变，而且不能使用默认值，需要赋值。若是基本数据类型则是值不变，若是引用数据类型，则地址不变，对象属性可变.若是基本数据类型，在编译时就赋值
- **Finally**
  - try-catch中使用。一般用于释放连接，关闭IO流，释放锁
    - （return在jvm中赋值一个变量值，所以try和finally中的return会进行覆盖）
  - **finally与return的关系：**不建议在finally中写入return
    - **try中有return，finally中没有return**
      - 先执行try中return之前的语句->finally中的语句->return 
      - 若finally修改了return中的变量，若基本数据类型，则不会改变，若引用类型，则改变
    - **try和finally中均有return**
      - try代码块中的return会保存到一个变量中，finally中的return会进行覆盖。
      - try代码块->finally代码块。finally中的return会覆盖try中的return
  - Finalize：
    -  Object 类的一个方法，GC准备释放时，可以调用一次Finalize（）方法进行自救。存活过这次GC。
    - Finalize（）方法一般用于释放非Java资源（文件资源，数据库连接），或是释放调用native方法时分配的内存。

## 深拷贝和浅拷贝区别了解吗

拷贝都需要实现Cloneable接口，重写clone方法。

- 都会创建一个新的对象，区别在于该对象中的引用对象，与原对象是相同的地址值还是也 拷贝了

![image-20220503101546936](%E5%A4%8D%E4%B9%A0.assets/image-20220503101546936.png)

# 容器

## ArrayList

- `ArrayList` 的底层是数组队列，相当于动态数组
- 支持**快速随机访问**的。在 `ArrayList` 中，我们即可以通过元素的序号快速获取元素对象，这就是快速随机访问。
- **内存空间占用：** `ArrayList` 的空 间浪费主要体现在在 list 列表的结尾会预留一定的容量空间
- 线程不安全
- 扩容方面
  - jdk1.6以后改的，（1.6还没有改）**以无参数构造方法创建 `ArrayList` 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为 10。**
  - **ArrayList 每次扩容之后容量都会变为原来的 1.5 倍左右**
  - 没有扩容因子，只有在插入数据发现没有空间时会进行扩容

## PriorityQueue

- `PriorityQueue` 是在 JDK1.5 中被引入的, 其与 `Queue` 的区别在于元素出队顺序是与优先级相关的，即总是优先级最高的元素先出队。
- **PriorityQueue底层是数组，而且不是有序的，PriorityQueue仅仅是维护了一个最小堆，使优先级最高的元素出队，并没有对数据进行sort操作**

# 操作系统

## Linux：怎么查IO的流量？



## Linux的5种IO模型梳理

IO操作是：网络IO还是磁盘IO，分为两阶段：1，从磁盘中把数据读取到内核空间的缓冲区，2，从内核空间拷贝到用户空间的缓冲区

- 同步阻塞IO**（BIO）**
  - 同步阻塞 IO 模型中，应用程序发起 read 调用后，两阶段都会阻塞
  - ![image-20220513150852947](%E5%A4%8D%E4%B9%A0.assets/image-20220513150852947.png)
- 同步非阻塞IO
  - 用户进程发起一个IO请求后可以返回做其它事情，但是用户进程不停的询问第一阶段是否完成（消耗资源），若完成，则用户线程进入阻塞，将数据拷贝到进程的缓存区。
  - 轮询过程消耗CPU资源
- 多路复用IO**（NIO）**
  
  - **文件描述符**（FD），关联一个Linux中的一个文件。可以监听它为是否是可读状态
  - **IO多路复用**：第一阶段：单独一个线程监听多个FD，若某个FD可读可写时，通知对应的用户线程执行第二阶段。（可能有多个用户进程提交IO请求，都交给该监听线程，用户进程两阶段均阻塞，本质为阻塞IO）
  - 本质类似于餐厅点餐，
    - 原本的IO模型是，前面的人先点餐，后面的人等着前面的点完后面的再点。若是前面的人点餐很拖沓，即使后面的人能很快点餐，仍会无效等待
    - IO多路复用：专门一个人不断询问排队的人，谁想好点什么餐了，就提交给前台。避免了一个线程阻塞，后续所有线程都阻塞的情况。
  
  - ![image-20220513153657107](%E5%A4%8D%E4%B9%A0.assets/image-20220513153657107.png)
  
  - ### IO多路复用方案
  
  - 调用 select，poll，epoll来提交到单线程
  
  - **select**
  
    - rfds  一个整数（FD集合）每个bit位代表一个fd，0代表未就绪，1代表就绪：
    - 监听的FD个数最大不超过1024
    - 每次select都是将要监听的FD拷贝到内核空间，
    - 有数据就绪后，返回就绪的FD集合，用户线程需要遍历集合来判断是哪些FD就绪（消耗时间）
  
  - **poll**
  
    - 使用链表表示FD集合，解决了select监听FD上限问题，仍需要遍历所有FD。（性能提升不明显）
  
  - **epoll**
  
    - 使用红黑树保存要监听的FD，且查找效率高
    - 只需要将要监听的FD拷贝到内核空间一次，因为地址相同，用户态可以直接操作
    - 有数据就绪后，返回的是就绪的FD，无序再次遍历
  
  - 
  
  
  
  
  
  
  
  - 多路：指的是多个网络连接客户端（Socket），复用：复用同一个线程(单进程)，即**一个线程内处理多个IO请求**
  - 与同步非阻塞IO不同，所有的IO请求到同一个线程（内核中的），该线程轮询查询所有IO读取状态，读取完成后，通知对应线程进行拷贝工作。
  - **注意：用户调用select进行IO请求，该进程会进入阻塞。**本质是同步阻塞IO。
  - IO 多路复用的系统调用，有 select，poll，epoll。 epoll是select的优化版本
  - **避免了将每一个IO请求分配给一个线程来单独处理，多路复用将IO请求统一交给一个线程处理，轮询查询状态**
- 信号驱动式IO（signal-driven IO）
  - Linux 用socket进行信号驱动 IO，用户线程发起一个IO请求操作会给对应的socket安装一个信号处理函数，进程继续运行并不阻塞，当IO事件就绪，进程收到SIGIO 信号，然后处理 IO 事件。（用户进程提交一个IO请求，建立一个信号处理函数。用户执行自己的程序，不阻塞，内核将数据准备完成，会主动的通知用户进程，用户进程阻塞，进行数据拷贝）
- **异步IO（A IO）**
  - 异步 IO 是基于事件和回调机制实现的，提交IO请求后会直接返回，不会堵塞在那里，在内核态将一二阶段都完成，通知相应的线程进行后续的操作。**（AIO）**
  - 唯一的异步方式：在第二阶段是异步，才是异步操作

## 二、进程和线程的区别

一个进程可以有多个线程

地址空间：

线程共享本进程的地址空间，而进程之间是独立的地址空间。

资源：

线程共享本进程的资源如内存、I/O、cpu等，不利于资源的管理和保护，而进程之间的资源是独立的，能很好的进行资源管理和保护。

健壮性：

多进程要比多线程健壮，一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。

执行过程：

每个独立的进程有一个程序运行的入口、顺序执行序列和程序入口，执行开销大。

但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，执行开销小。

可并发性：

两者均可并发执行。

切换时：

进程切换时，消耗的资源大，线程切换消耗资源少。所以涉及到频繁的切换时，使用线程要好于进程。同样如果要求同时进行并且又要共享某些变量的并发操作，只能用线程不能用进程。

其他：

线程是处理器调度的基本单位，但是进程是系统运行程序的基本单位。

## 多级反馈队列调度算法

多级反馈队列调度算法是一种根据先来先服务原则给就绪队列排序，为就绪队列赋予不同的优先级数，不同的时间片，按照优先级抢占CPU的调度算法。

## 

## 僵尸进程与孤儿进程

- 多进程程序，⽗进程⼀般需要跟踪⼦进程的退出状态，当⼦进程退出，⽗进程在运⾏，⼦进程必须等到⽗进程捕获到了⼦进程的退出状态才真正结束。在⼦进程结束后，⽗进程读取状态前，此时⼦进程为**僵⼫进程**。
- 若父进程先于子进程结束，则此时子进程是**孤儿进程**。孤儿进程将被 init 进程（进程号为1）领养，并由 init 进程对孤儿进程完成状态收集工作。**孤儿进程不会成为僵尸进程**
- 设置僵⼫进程的⽬的是维护⼦进程的信息，以便⽗进程在以后某个时候获取。这些信息⾄少包括进程ID，进程的终⽌状态，以及该进程使⽤的CPU时间。所以当终⽌⼦进程的⽗进程调⽤wait或waitpid时就可以得到这些信息。
- 但是⼦进程停⽌在僵⼫态会占据内核资源，所以需要避免僵⼫进程的产⽣或⽴即结束⼦进程的僵⼫态。（缩短僵尸进程的时间）
  - **僵尸进程不能使用kill指令杀死**。因为子进程已经执行结束。仅仅处于等待状态
  - 杀死父进程，则僵尸进程会被回收

![image-20220415081744090](%E5%A4%8D%E4%B9%A0.assets/image-20220415081744090.png)

- **预防僵尸进程**
  - **父进程调用waitpid**，若此时没有子进程是僵尸状态，会进入阻塞。
  - **通过signal(SIGCHLD, SIG_IGN)通知内核对⼦进程的结束不关⼼，由内核回收**。
    - 如果不想让⽗进程挂起，可以在⽗进程中加⼊⼀条语句：signal(SIGCHLD,SIG_IGN);表示⽗进程忽略SIGCHLD信号，该信号是⼦进程退出的时候向⽗进程发送的。

# 并发篇

## 1.线程状态

**要求**

* 掌握 Java 线程六种状态
* 掌握 Java 线程状态转换
* 能理解五种状态与六种状态两种说法的区别

**六种状态及转换**

![image-20220313175549225](%E5%A4%8D%E4%B9%A0.assets/image-20220313175549225-16473155695371.png)

分别是

- 新建
  - 当一个线程对象被创建，但还未代用start方法运行时处理**新建**状态
  - 此时未与操作系统底层线程相关
- 可运行
  - 调用了start方法，就会由**新建**状态进入**可运行**
  - 此时与底层线程关联，由操作系统调度执行
- 终结
  - 线程内代码执行完毕，由**可运行**进入终结
  - 此时会取消与底层线程关联
- 阻塞
  - 当获取锁失败后，由**可运行**进入Monitor的阻塞队列**阻塞**，此时不占用CPU
  - 当持锁线程放锁时，会按照一定规则唤醒阻塞队列中的**阻塞**线程，唤醒后的各线程进行竞争，最终一个线程进入**可运行状态**
- 等待
  - 当获取锁成功后，但由于条件不满足，调用了wait()方法，此时从可运行状态释放锁进入Monitor等待集合**等待**，同样不占用CPU时间
  - 当其它持锁线程调用 **notify() 或 notifyAll() 方法**，会按照一定规则唤醒等待集合中的**等待**线程，恢复为**可运行**状态
- 有时限等待
  - 当获取锁成功后，但由于条件不满足，调用了 wait(long) 方法，此时从**可运行**状态释放锁进入 Monitor 等待集合进行**有时限等待**，同样不占用 cpu 时间
  - 当其它持锁线程调用 notify() 或 notifyAll() 方法，会按照一定规则唤醒等待集合中的**有时限等待**线程，恢复为**可运行**状态，并重新去竞争锁
  - 当等待超时，也会从**有时限等待**状态恢复为**可运行**状态，并重新去竞争锁
  - 还有一种情况是调用sleep（long）方法也会从可运行状态进入**有时限**等待状态，但与 Monitor 无关，不需要主动唤醒，超时时间到自然恢复为**可运行**状态

**五种状态**

五种状态的说法来自于操作系统层面的划分

![image-20220313182630476-16471671925531](%E5%A4%8D%E4%B9%A0.assets/image-20220313182630476-16471671925531-16473156139412.png)

- 新建态
- 运行态：分到CPU时间，能真正执行线程内代码
- 就绪态：有资格分配到CPU时间，但还未轮到它
- 阻塞态：
  - 涵盖了 java 状态中提到的**阻塞**、**等待**、**有时限等待**
  - 多出了阻塞I/O，指线程在调用阻塞I/O时，实际活动由I/O设备完成，此时线程无事可做，只能等待
- 终结态



## 2. 线程池核心参数

- 掌握线程池的 7 大核心参数

**七大参数**

- corePoolSize 核心线程数目=池中会保留的最少线程数：
  - **在队列未满的情况下，只使用核心线程。若队列容量满了，则核心线程和救急线程共同工作**
  - 线程池创建好，就准备就绪的线程数量，等待异步执行。**与线程池一直存在，除非设置参数allowCoreThreadTimeOut,允许线程池过期**

- maximumPoolSize 最大线程数目=核心线程+救急线程的最大数目
- keepAliveTime 生存时间：救急线程的生存时间，生存时间内没有新任务，则此线程等待设置时间后，资源释放
- unit 时间单位 - 救急线程的生存时间单位，如秒、毫秒等
- workQueue ：**当没有空闲核心线程时，新来的任务会加入到此队列排队，队列满会创建救急线程执行任务**
- threadFactory 线程工厂 - 可以定制线程对象的创建，例如设置线程名字、是否是守护线程等
- handler 拒绝策略(饱和策略) - 当所有线程都在繁忙，workQueue 也放满时，会触发拒绝策略
  - jdk的拒绝策略
    - 抛异常
    - 由调用者执行任务 
    - 丢弃任务 
    - 丢弃最早排队任务，本任务取而代之 
  
  - ActiveMQ
    - 带超时等待（60s）尝试放入队列
  

**线程池重用线程时，会对ThreadLocal的值进行清空吗？**

**不会清空，要你自己去清空。**

如果你能够在使用ThreadLocal的时候管理它的创建、销毁，那么就可以用，否则会出问题。原因是ThreadLocal是和Thread绑定的，如果Thread是从Thread Pool中拿出来的，那么意味着Thread可能会被复用，如果被复用，你就一定得保证这个Thread上一次结束的时候，其关联的ThreadLocal被清空掉，否则就会串到下一次使用。





**工作流程**：

- 线程池创建，线程池中会创建core数量的核心线程，准备接收任务
- 核心线程满了，将再进来的任务放入阻塞队列，空闲的线程会在阻塞线程中获取任务
- **若阻塞也满了，则创建救急线程执行任务，此时救急线程新创建执行的任务是刚进来的任务而不是阻塞队列中的任务，执行完该任务后，从阻塞队列中获取任务**，线程总量只能是maximumPoolSize 数目
- 若已经达到最大线程数目，且阻塞队列也满了，则执行拒绝策略
- 线程执行完毕
- 若任务执行完，等待一定的存活时间，救急线程注销









## 3. wait vs sleep

**要求**

* 能够说出二者区别

**一个共同点，三个不同点**

共同点

* wait() ，wait(long) 和 sleep(long) 的效果都是让当前线程暂时放弃 CPU 的使用权，进入阻塞状态

不同点

* 方法归属不同
  * sleep(long) 是 Thread 的静态方法
  * 而 **wait()，wait(long) 都是 Object 的成员方法**，每个对象都有

* 醒来时机不同
  * 执行 sleep(long) 和 wait(long) 的线程都会在等待相应毫秒后醒来
  * wait(long) 和 wait() 还可以被 notify 唤醒，wait() 如果不唤醒就一直等下去
  * 它们都可以被打断唤醒

* 锁特性不同（重点）
  * wait 方法的调用必须先获取 wait 对象的锁，而 sleep 则无此限制
  * wait 方法执行后会释放对象锁，允许其它线程获得该对象锁（我放弃 cpu，但你们还可以用）
  * 而 sleep 如果在 synchronized 代码块中执行，并不会释放对象锁（我放弃 cpu，你们也用不了）

## 4. lock vs synchronized

**三个层面**

不同点

* 语法层面
  * synchronized 是关键字，源码在 jvm 中，用 c++ 语言实现
  * Lock 是接口，源码由 jdk 提供，用 java 语言实现
  * 使用 synchronized 时，退出同步代码块锁会自动释放，而使用 Lock 时，需要手动调用 unlock 方法释放锁。
  * **synchronized 不可被打断**
* 功能层面
  * 二者均属于悲观锁、都具备基本的互斥、同步、锁重入功能
  * Lock 提供了许多 synchronized 不具备的功能，例如获取等待状态、公平锁、可打断、可超时、多条件变量
  * Lock 有适合不同场景的实现，如 ReentrantLock， ReentrantReadWriteLock
* 性能层面
  * 在没有竞争时，synchronized 做了很多优化，如偏向锁、轻量级锁，性能不赖  （jdk1.6以后）
  * 在竞争激烈时，Lock 的实现通常会提供更好的性能

**公平锁**

* 公平锁的公平体现
  * **已经处在阻塞队列**中的线程（不考虑超时）始终都是公平的，先进先出
  * 公平锁是指**未处于阻塞队列**中的线程来争抢锁，如果队列不为空，则老实到队尾等待
  * 非公平锁是指**未处于阻塞队列**中的线程来争抢锁，与队列头唤醒的线程去竞争，谁抢到算谁的
* 公平锁会降低吞吐量，一般不用

**条件变量**

- ReentrantLock中的条件变量功能类似于普通synchronized的wait，notify，用在当前线程获得锁后，发现条件不满足时，进入临时等待的链表结构
- 与 synchronized 的等待集合不同之处在于，ReentrantLock 中的条件变量可以有多个，可以实现更精细的等待、唤醒控制

## 5. volatile



**原子性**

- 起因：多线程下，不同线程的**指令发生了交错**导致的共享变量的读写混乱
- 解决：用悲观锁或乐观锁解决，**volatile 并不能解决原子性**

**可见性**

* 起因：由于**编译器优化、或缓存优化、或 CPU 指令重排序优化**导致的对共享变量所做的修改另外的线程看不到
* 起因应该是：线程对公共变量操作时，首先从公共内存加载到线程本地内存，再进行操作，导致各个线程的操作是不可见的。
* 解决：**用 volatile 修饰共享变量，能够防止JIT编译器等优化发生，让一个线程对共享变量的修改对另一个线程可见**

**有序性**

- 起因：由于**编译器优化、或缓存优化、或 CPU 指令重排序优化**导致指令的实际执行顺序与编写顺序不一致

- 解决：**用volatile修饰共享变量会在读，写共享变量时加入不同的屏障，阻止其他读写操作越过屏障，从而达到阻止重排的效果**

- 注意：

  对volatile变量的写指令**后会加入写屏障**

  对volatile变量的读指令**前会加入读屏障**

  - **volatile 变量写屏障**阻止的是阻止前面其他写操作越过屏障排到**volatile 变量写后面**（这句话和上面的写指令后会加入写屏障并不冲突，因为写屏障使得写屏障前的代码不能越过屏障到后面，**但不能阻止后面的屏障到面前来，读屏障类似**）
  - **volatile 变量读屏障**阻止的是阻止后面的其他读操作越过屏障排到 **volatile 变量读前面**
  - volatile 读写加入的屏障只能防止同一线程内的指令重排

  （**所以读写屏障的插入应该是在所有写操作之后，所有读操作之前**）

内存屏障：

是CPU或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作。**简单说就是加入内存屏障，则之前的读写操作全部执行后再执行内存屏障后的代码。内存屏障为一个同步点，点之前的代码执行完，再执行点之后的代码**

## 6. 悲观锁 vs 乐观锁

**要求**

* 掌握悲观锁和乐观锁的区别

**对比悲观锁与乐观锁**

* 悲观锁的代表是 synchronized 和 Lock 锁
  * 其核心思想是【线程只有占有了锁，才能去操作共享变量，每次只有一个线程占锁成功，获取锁失败的线程，都得停下来等待】
  * 线程从运行到阻塞、再从阻塞到唤醒，涉及线程上下文切换，如果频繁发生，影响性能
  * 实际上，线程在获取 synchronized 和 Lock 锁时，如果锁已被占用，都会做几次重试操作，减少阻塞的机会

* 乐观锁的代表是 AtomicInteger |e toa mi ke  Integer|，使用 cas 来保证原子性
  * 其核心思想是【无需加锁，每次只有一个线程能成功修改共享变量，其它失败的线程不需要停止，不断重试直至成功】
  * 由于线程一直运行，不需要阻塞，因此不涉及线程上下文切换
  * 它需要多核 cpu 支持，且线程数不应超过 cpu 核数

AtomicInteger 的底层实现使用的是Unsafe，保证操作的原子性



## 7. Hashtable vs ConcurrentHashMap

**要求**

* 掌握 Hashtable 与 ConcurrentHashMap 的区别
* 掌握 ConcurrentHashMap 在不同版本的实现区别

**Hashtable 对比 ConcurrentHashMap**

* Hashtable 与 ConcurrentHashMap 都是线程安全的 Map 集合
* Hashtable 的底层是数组+链表，ConcurrentHashMap 底层是`Node 数组 + 链表或红黑树`
* Hashtable 并发度低，整个 Hashtable 对应一把锁，同一时刻，只能有一个线程操作它
* ConcurrentHashMap 并发度高，整个 ConcurrentHashMap 对应多把锁，只要线程访问的是不同锁，那么不会冲突

**ConcurrentHashMap 1.7**

* 数据结构：`Segment数组 + HashEntry数组 + 链表`，每个 Segment 对应一把锁，如果多个线程访问不同的 Segment，则不会冲突。（Segment数组中包含HashEntry数组，其内部有链表），**Segment继承了ReentrantLock**
* 并发度：Segment 数组大小即并发度，决定了同一时刻最多能有多少个线程并发访问。Segment 数组不能扩容，意味着并发度在 ConcurrentHashMap 创建时就固定了
* 索引计算
  * 假设大数组长度是 $2^m$​，key 在大数组内的索引是 key 的二次 hash 值的高 m 位（二进制hash值的高M位）
  * 假设小数组长度是 $2^n$​，key 在小数组内的索引是 key 的二次 hash 值的低 n 位（二进制hash值的低n位）
* **put新节点时会进行扩容。而且若是超出阈值，则会先进行扩容，再添加新节点**
* **并发GET操作**
  * **get操作没有加锁**
  * 使用Unsafe类保证可见性，因为数组某个位置的值改变，volatile只能保证整个数组的可见性，而数组中某个值的需要改变通过Unsafe类保证。Unsafe.getObjectVolatile(数组，下标)。获取指定位置的volatile值
  * 扩容时，若get先进行，则从旧表中取。get后发生则从新表中取

* **并发put操作**
  * 对map的操作，找到对应的segment
  * **对segment进行操作，由于继承了ReentrantLock，进行加锁。**
  * 判断是新增还是更新
    * 若新增，则总量+1，
    * 进行扩容判断，需要扩容，则**先扩容后添加新元素**

* size操作
  * 计算元素个数前，先不加锁计算两次，如果前后两次结果如一样，认为个数正确返回
  * 如果不一样，进行重试，重试次数超过 3，将所有 segment 锁住，重新计算个数返回




* 扩容：每个小数组的扩容相对独立，小数组在超过扩容因子时会触发扩容，每次扩容翻倍（扩容时，一般情况下是头插法，遍历链表。若链表中，在某个节点以及后续节点与扩容后仍在一个链表，则之间将剩余链表迁移，不必挨个遍历头插法）
* Segment[0] 原型：首次创建其它小数组时，会以此原型为依据，数组长度，扩容因子都会以原型为准

**ConcurrentHashMap 1.8**

* 数据结构：`Node 数组 + 链表或红黑树`，数组的每个头节点作为锁，如果多个线程访问的头节点不同，则不会冲突。**首次生成头节点时如果发生竞争，利用 cas 而非 syncronized**，进一步提升性能

* 并发度：Node 数组有多大，并发度就有多大，与 1.7 不同，Node 数组可以扩容

* 扩容条件：Node 数组满 3/4 时就会扩容

* 扩容单位：以链表为单位从后向前迁移链表，迁移完成的将旧数组头节点替换为 ForwardingNode。**七上八下**

* **扩容时并发 get**
  
  * 根据是否为 ForwardingNode**（一种标记，是 ForwardingNode代表该数组位置已经迁移结束）**来决定是在新数组查找还是在旧数组查找，不会阻塞
  * 如果链表长度超过 1，则需要对节点进行复制（创建新节点），怕的是节点迁移后 next 指针改变
  * 如果链表最后几个元素扩容后相对位置不变，则节点无需复制
  
* **扩容时并发 put**
  
  * 首先判断map是否为空。**空表示没有进行初始化，初始化Map，因为是懒惰初始化，省内存**
  * 如果 put 的线程与扩容线程正在迁移的链表为同一个，put 线程会阻塞
  * 如果 put 的线程操作的链表还未迁移，即该链表还未迁移（还没轮到该链表迁移），则可以并发执行
  * 如果 put 的线程操作的链表（在旧map中）已经迁移完成，则协助扩容，等扩容完成后，再从扩容后的map中put
  
* 与 1.7 相比是懒惰初始化**（只有在储存元素时才会创建对象）**

* **并发初始化table，原子操作**

  * 设置一个变量sc
  * 进入循环，条件table=null。
    * if判断若sc<0,则yield，让出CPU时间片
    * else if：CAS操作，将sc赋值-1，加锁操作，其他线程进来，会进入第一个if判断。内部创建table。sc=正值。
    * 释放锁，退出循环

* put操作时，增加数值。统计size

  * 与LongAddr类似，有一个累加单元数组，put时的+1操作会对某个cell单元进行CAS操作
  * 累加单元数组是懒初始化，累加单元也是懒初始化操作。所以需要判断两次
  * CAS累加操作
  * 若此时size超出阈值，进行扩容
  * 求取size时，遍历所有的累加单元，可能存在误差，因为遍历时，其他线程可能还在操作

  

* capacity 代表预估的元素个数，capacity / factory 来计算出初始数组大小，需要贴近 $2^n$ 
* loadFactor 只在计算初始数组大小时被使用，之后扩容固定为 3/4，**不可修改**
  **（意思是，扩容因子，只有在初始创建的时候才会用到，后面的扩容依然为jdk设置的0.75）**
* 超过树化阈值时的扩容问题，如果容量已经是 64，直接树化，否则在原来容量基础上做 3 轮扩容

## 8.ThreadLocal

* ThreadLocal 可以实现【资源对象】的线程隔离，让每个线程各用各的【资源对象】，避免争用引发的线程安全问题
* ThreadLocal 同时实现了线程内的资源共享，**即各个方法内的共享**

**原理**

每个线程内有一个 ThreadLocalMap 类型的成员变量，用来存储资源对象**（ThreadLocalMap是线程独立的）**

* 调用 set 方法，就是以 ThreadLocal 自己作为 key，资源对象作为 value，放入当前线程的 ThreadLocalMap 集合中
* 调用 get 方法，就是以 ThreadLocal 自己作为 key，到当前线程中查找关联的资源值
* 调用 remove 方法，就是以 ThreadLocal 自己作为 key，移除当前线程关联的资源值



**ThreadLocal一个线程只能存放一个变量吗？想存多个怎么搞**

- 每一个ThreadLocal只能保存一个对象，因为以ThreadLocal为key（key是唯一的，所以value也是唯一的）
- 解决办法
  - 一个线程内创建多个ThreadLocal，就可以保存多个对象
  - 在一个ThreadLocal中，value为一个map，这样也可以保存多个对象





ThreadLocalMap 的一些特点

* key 的 hash 值统一分配（**对象加一个数字作为hash值**）
* 初始容量 16，扩容因子 2/3，扩容时容量翻倍
* key 索引冲突后用开放寻址法解决冲突。（**开放寻址法，是发生哈希碰撞，则寻找数组中下一个空闲位置，而不是构建链表**）
* ThreadLocalMap 中的 key 被设计为弱引用



明明每一个ThreadLocal只能保存一个对象，为什么会涉及到扩容的问题？

- 因为一个线程内可以创建多个ThreadLocal
- 每一个线程只有一个ThreadLocalMap ，但是可以有多个ThreadLocal





为什么ThreadLocalMap 中的 key 被设计为弱引用？

**弱引用 key，仅仅是通过GC回收了key，value未回收**

ThreadLocalMap 中的 key 被设计为弱引用，原因如下

* Thread 可能需要长时间运行（如线程池中的线程），如果 key 不再使用，需要在内存不足（GC）时释放其占用的内存



**内存释放时机，即GC回收了key，如何释放value？**（**ThreadLocalMap 存在内存泄露问题**）

- 被动GC释放key
  - 仅是让key的内存释放，关联value的内存并不会释放
- 懒惰被动释放value
  - get Key时，发现是null key，则释放其value内存
  - set key时，使用启发式扫描，清除临近额null key的value内存，启发次数与元素个数，是否发现null key有关。**即存储或者是修改key时，会将临近的null key清理掉**
- 主动remove释放key，value
  - 会同时释放 key，value 的内存，也会清除临近的 null key 的 value 内存
  - **推荐使用它，因为一般使用 ThreadLocal 时都把它作为静态变量（即强引用），因此无法被动依靠 GC 回收key，懒惰被动释放value的方法全部失效**







## 9. CAS

在JVM中。

## 10. AQS

### 1，简介

- **抽象的队列同步器**

是用来构建锁或者其它同步器组件的重量级基础框架及整个JUC体系的基石，通过内置的CLH（FIFO）队列的变种来完成资源获取线程的排队工作。并通过**int类型变量表示持有锁的状态。**



AQS使用一个volatile的int 类型的成员变量status 来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，将每条要去抢占资源的线程封装成一个**Node节点**来实现锁的分配，通过CAS的方法完成对status 值的修改



CLH:Craig、Landin and Hagersten 队列,是一个单向链表,AQS中的队列是CLH变体的虚拟双向队列FIFO

![image-20220318171044674](%E5%A4%8D%E4%B9%A0.assets/image-20220318171044674.png)

- AQS为什么是JUC内容中最重要的基石

  这些锁都继承了AQS

  (ReentrantLock | CountDownLatch | ReentrantReadWriteLock | Semaphore)

![在这里插入图片描述](%E5%A4%8D%E4%B9%A0.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RaODQ1MTk1NDg1,size_16,color_FFFFFF,t_70)

-  锁,面向锁的使用者。同步器,面向锁的实现者
- **加锁会导致阻塞、有阻塞就需要排队,实现排队必然需要队列**
- 如果共享资源被占用,就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是**CLH队列**的变体实现的,将暂时获取不到锁的线程加入到队列中,**这个队列就是AQS的抽象表现。**它将请求共享资源的线程封装成队列的结点(**Node**) ,通过CAS、自旋以及LockSuport.park()的方式,维护state变量的状态,使并发达到同步的效果

### AQS内部结构

- AQS内部int变量: status 
- CLH队列(三个大牛的名字组成),为一个双向队列，内部对象类型为Node<Thread>

**Node内部结构为**

- 成员变量：waitStatus 表明当前Node的等待状态
- 前后Node指针

**AQS同步队列的基本结构**

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201024105320135.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RaODQ1MTk1NDg1,size_16,color_FFFFFF,t_70#pic_center)



### AQS源码

- 公平锁与非公平锁
  - 创建锁时判断是否传入参数 true|false|不填。 不填或者false为非公平锁，true为公平锁
  - 公平锁是指**未处于阻塞队列**中的线程来争抢锁，如果队列不为空，则老实到队尾等待
  - 非公平锁是指**未处于阻塞队列**中的线程来争抢锁，与队列头唤醒的线程去竞争，谁抢到算谁的
  - 二者区别： 公平锁与非公平锁的lock()方法唯一的区别就在于公平锁在获取同步状态时多了一个限制条件:**hasQueuedPredecessors()**
    - hasQueuedPredecessors()：是公平锁加锁时判断等待队列中是否存在有效节点的方法

**流程**

- **lock.lock( ) 源码**
  - 加锁，进入锁内方法，通过CAS抢占线程。若抢占不到，则二次抢占或者说后续线程抢占

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210705205642730.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RaODQ1MTk1NDg1,size_16,color_FFFFFF,t_70)

- **acquire( ):源码和3大流程走向**

  - tryAcquire(arg)再次抢占线程，区分为公平锁和非公平锁方法。抢占不到，则添加到等待队列

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/20201025201418303.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RaODQ1MTk1NDg1,size_16,color_FFFFFF,t_70#pic_center)

- **非公平锁中，**再抢占一次，查看是否成功。成功则抢占。不成功，else if判断：当前线程是否是当前持有的线程（即锁重入），是的话，抢占。不成功则返回false。调用acquire中的addWaiter方法

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201025202052403.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RaODQ1MTk1NDg1,size_16,color_FFFFFF,t_70#pic_center)

- **addWaiter（Node.EXCLUSIVE）入队操作**

**传入要入队的Node**，若时队列为空，头结点和尾结点为null。进入enq(node)方法。若不为空，则加入到队列

- 初始化队列，**会创建一个哨兵，即空节点，不存储任何信息，只是占位**。真正第一个数据的结点在第二个开始。
- 第二次循环，将Node插入到队列。首先新节点的prev指向旧的尾结点。旧尾结点的next指向新节点。tail更新为新节点。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201025202813662.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RaODQ1MTk1NDg1,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201025203416851.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RaODQ1MTk1NDg1,size_16,color_FFFFFF,t_70#pic_center)

- **acquireQueued(addWaiter(Node.EXCLUSIVE), arg)**
  - 在进入队列后会进入该方法。进入一个死循环，首先获取头节点，再次尝试获取锁。
  - 没获取到则进入shouldParkAfterFailedAcquire方法。
    - 第一次进入该方法，则将Node的waitstatus设置赋值为Node.SIGNAL 为-1。
  - 退出再次回到acquireQueued重新循环，再次抢占锁。再次进入shouldParkAfterFailedAcquire方法。
    - 由于头结点的值为Node.SIGNAL，则返回true。
  - 执行parkAndCheckInterrupt方法
    - park方法，将线程挂起。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201028212208656.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RaODQ1MTk1NDg1,size_16,color_FFFFFF,t_70#pic_center)

shouldParkAfterFailedAcquire

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201028213303522.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RaODQ1MTk1NDg1,size_16,color_FFFFFF,t_70#pic_center)

parkAndCheckInterrupt

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201028213629725.png#pic_center)

**入队和阻塞完成，等待执行线程结束**

- **执行线程结束会执行unlock（）方法**，unlock方法会调用tryRelease()
  - tryRelease（）方法会调用tryRelease()方法，将AQS的status设置为0，将Owner持有锁线程改为null，并返回true
  - 返回true，调用unparkSuccessor( ) ：将哨兵的状态改为0。并激活线程  Unpark
- 上面的acquireQueued.parkAndCheckInterrupt（）方法重新执行，并将重新获取线程。
  - 方法中，将阻塞队列的头节点（哨兵）设置为当前获取到线程的node，并取消原哨兵的引用，使其等待GC回收。并将新哨兵节点的线程清除



![在这里插入图片描述](https://img-blog.csdnimg.cn/20201028214828280.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RaODQ1MTk1NDg1,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201028214637248.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RaODQ1MTk1NDg1,size_16,color_FFFFFF,t_70#pic_center)



# Redis

## Redis单线程为什么这么快？

Redis是单线程还是多线程？

- 若是核心业务，命令处理部分，是单线程
- 要是整个redis，则是多线程

**原因**

- 纯内存操作
- 核心是基于IO多路复用机制
- 单线程反而避免了多线程频繁上下文切换带来的性能问题
- 多线程会面临线程安全问题，使得复杂度增高





Redis基于Recator模式开发了网络事件处理器，文件事件处理器。。因为事件处理器是单线程的，所以redis才叫做**单线程的模型**。

文件事件处理器包括：

- 多个Socket
- IO多路复用程序
- 文件事件分派器
- 事件处理器

**单线程处理流程：**Socket（套接字，接收请求）

多个Socket可能并发的产生不同的事件，IO多路复用会监听多个Socket，有事件发生，字符将Socket加入到队列中排队。每次队列有序，同步从队列中取出Socket给事件分派器，事件分派器把Socket交给对应的事件处理器。然后事件处理器执行完，IO多路复用会将队列职中下一个Socket给事件分派器。











## 1，项目注意点

- 请求用户信息时，不能返回用户所有的信息，只封装用户需要的信息。（不能说请求用户名，把用户所有信息，用户名，id，密码都返回这是不应该的）
  - 解决方法：DTO类与TO类相仿，只保存请求相关的信息



![image-20220510174628403](%E5%A4%8D%E4%B9%A0.assets/image-20220510174628403.png)

## 2，redis解决Session共享

- 将之前保存在session中的value信息保存在redis。key保存在cookie中
- 
- 拦截器功能：拦截需要登录的功能，判断用户是否登录，若登录，更新redis的登录用户的过期时间。**避免因为用户一直操作却自动下线的功能**
- **登录拦截器优化**（用处不大，因为很多页面都会进行登录校验，因为登录和未登录显示界面不同）
  - 拦截器拦截，进行登录验证。若用户登录，但只请求不需要拦截的网址。则拦截器失效。另外redis的过期时间也无法更新
  - **解决方法：**
    - 再设置一个拦截器，
    - 拦截器1，所有请求均会通过，若已登录，获取用户登录信息，并更新过期时间
    - 拦截器2，判断当前请求是否为需要登录的请求，若是且未登录拦截。

## 3，redis作为缓存

将用户数据保存到redis，获取数据时先在redis中获取，若没有则数据库获取，并保存到redis。

- redis自带内存淘汰机制。在内存不足时随机淘汰数据

### 缓存一致性问题

主动更新缓存和数据库来保证高一致性。

- ### 更新操作是更新缓存还是删除缓存

  - 更新缓存：每次更新数据库都要更新缓存，无效写操作太多
  - **删除缓存：**更新数据库时缓存失效，查询缓存时再更新缓存

- ### 如何保证缓存与数据库操作的同时失败与成功

  - 单体系统，将缓存与数据库放在一个事务中
  - 分布式系统，利用TCC等分布式事务方案

- ### 更新操作的一致性

  - 先删缓存，再操作数据库（存在线程安全问题，概率高，因为操作数据库慢，更新缓存快）
    - 线程1先删缓存，此时线程2进来查询缓存查不到，查询数据库（旧值），并写入缓存（旧值），此时线程1更新数据库（新值）   **缓存数据库不一致**
    - ![image-20220510203623979](%E5%A4%8D%E4%B9%A0.assets/image-20220510203623979.png)
  - **先操作数据库，再删缓存**（也存在线程安全问题，但概率低，1，查询该缓存刚好失效，2，且其他线程更新此数据，最后3，线程1慢于线程2（操作缓存慢于操作数据库））
    - 线程1查询缓存，此时缓存失效，从数据库中查（旧值），此时线程2更新数据库（新值），并删除redis中的缓存。线程1此时更新缓存（旧值）
    - ![image-20220510204013241](%E5%A4%8D%E4%B9%A0.assets/image-20220510204013241.png)

### 缓存穿透

- 客户端恶意发送请求查询缓存数据库都不存在的空值，redis没有则从数据库中查询，查询压力落在数据库。
- **解决方法**
  - 缓存空对象
    - 优点：实现简单，维护方便
    - 缺点：
      额外的内存消耗（需要redis保存空值，可以设置过期时间来解决）
      可能造成短期的不一致（此时redis保存空值，但数据库添加了该数据库，则造成了不一致）
  - 布隆过滤
    - 先查询布隆过滤器，若存在，再从redis和数据库中查询
    - 原理：https://www.cnblogs.com/wangwust/p/9467720.html
      - **布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。**
      - 内部维护一个全为0的bit数组，和多个hash计算函数
      - 输入数据时，每个hash函数计算，并将每个结果值对应的数组位置置为1.
      - 验证数据时，依然每个hash函数计算，若每个结果对应的数组位置为1，则认为存在。
      - 数组越长，所占空间越大，误判率越低

### 缓存雪崩

- 同一个时段，大量的缓存key同时失效，或者redis宕机，则所有的请求打到数据库，数据库压力过大
- 解决方法：
  - 给不同的key的过期时间添加随机值
  - redis集群提高服务的可用性（防止redis宕机）
  - 对缓存业务进行降级限流

### 缓存击穿

- 热点key：高并发访问并且缓存重建业务复杂。这个key失效，则无数请求瞬间落在数据库。
- 解决方法
  - **加互斥锁**，可以使用分布式锁
    - 不能在方法上加锁（与单例设计模式类似），否则没有过期时由于互斥锁而导致请求过慢
  - **逻辑过期**
    - 在redis中保存一个逻辑过期时间（可以理解为一个数值，并不是真正的过期时间）
    - 线程1请求，发现逻辑过期，则获取互斥锁，并分出一个子线程，查询数据库对缓存中的数据更新。若此时其他线程也获取该数据，发现逻辑过期，并获取不到锁，则返回旧数据
    - ![image-20220510214524992](%E5%A4%8D%E4%B9%A0.assets/image-20220510214524992.png)

## 4，Redis秒杀

生成唯一性ID，作为订单ID

- **超卖问题**
  - 线程1查询库存，线程2查询库存，线程1判断是否有库存，有则下单成功（此时没有库存）。线程2判断有库存（旧值）下单成功。导致超卖
  - 使用乐观锁，
    - 有可能会出现200个请求抢100个商品，由于CAS，只能有一个线程进行下单，导致其他线程请求失败，（请求只请求了一次）。虽然没有超卖，但造成了可能只有15个人抢到了商品，85个商品没卖出。
    - **所以下单时，先减库存，再下订单**，下订单过程已经释放锁。
      - 减库存时，判断是否有库存。**需要库存-1操作并且判读是否还有库存（利用数据库的原子性）。**本质为CAS，即更新操作时判断是否还有库存，若没有则下单失败。
      - 降低占用锁的时间。
  - 实现一人一单
    - 需要确保一个用户只能秒杀一次，加悲观锁。（不能用CAS，因为先减库存，涉及不到用户信息，若CAS，导致减了库存，又发现当前用户已经购买，则再进行回滚）
    - 加悲观锁
      - 锁对象为用户ID，注意每次请求都会创建新的对象，导致锁不住。可以toString().intern()。转化成字符串并加入到串池，避免同一时刻多个下单
      - 另外，下单时，会再次验证当前用户是否购买，若已购买，则不能重复下单

## 5，分布式锁

**向redis保存值作为锁，分布式的服务中加锁**

- **上锁**（向redis保存值，并设置过期时间（原子指令）。setnx ex）
  - 使用setnx ：保存该key，value。若该key不存在才保存，否则执行失败
  - **设置过期时间**：避免因为上锁后，线程出现异常，无法释放锁。
  - **保存锁值，设置过期时间为一条指令**：避免在保存锁值后，设置过期时间时出现异常，则锁一直存在。
- **释放锁**（校验要删除的value是否与保存的value是否一致，一致再删除，不一致，则视为为已经删除。使用lua脚本）
  - **校验value：**占有该锁时，线程执行时间过长，或者陷入阻塞，此期间锁过期，线程未执行完。则其他线程开始获取该锁，并进行业务操作。多个线程持有锁
    - 保存锁的value值不能为随意值。设置value：UUID+特征符号。UUID可以避免分布式下多个特征符号相同，导致value相同的情况。
  - **删除锁必须保证原子性。使用redis+Lua脚本完成：**若判断锁存在，此时陷入阻塞，此期间锁过期，其他线程竞争到了锁。该线程恢复运行时，会执行删除锁操作。删除了其他线程的锁

- **Lua脚本**：![image-20220511162024788](%E5%A4%8D%E4%B9%A0.assets/image-20220511162024788.png)
- **Redisson**，在redis基础上实现的Java驻内存网格，包含多种分布式Java对象，其中就有分布式锁，**有实现锁重入，锁重试，信号量**
  - **锁重入**：利用hash结构记录线程id和重入次数
    - 借鉴的AQS，将键值对的分布式锁改为hash形式。key获取hash，hash的key为线程，value为status（当前线程持有锁个数，进行锁重入）
    - 获取锁和释放锁使用lua脚本。
    - **持有锁：**首先判断是否有其他线程占有锁，若占有，则判断是否为当前线程，status+1，进行锁重入。并重置有效期
    - **释放锁：**获取锁，判断锁是否是自己占有的锁，若是则status-1，重置锁有效期。若status为0，释放锁，删除hash。否则锁已经释放
  - **可重试**：使用信号量和发布订阅功能实现等待，唤醒，获取，锁失败的重试机制
  - **超时续约**：利用watchDog，每隔一段时间（releaseTime / 3），重置超时时间

## Redis的持久化机制

- **RDB**： Redis DataBase将某一时刻的内存快照，以二进制的方式将**数据**写入内存
  
  - 手动触发
    - save命令，是Redis处于阻塞状态，直到redis持久化完成，才会继续响应客户端请求（慎用）
    - bgsave命令，fork出一个子进程执行持久化，主进程会在fork过程（分出一个子进程）中有短暂的阻塞，子进程创建后，主进程就可以响应客户端请求（由于子进程持久化过程与主进程读写数据并行执行，使用COW（copy  all write  写时拷贝）避免因为主进程修改数据，使得子进程的持久化出现错误，父进程将要修改的内容copy出一个备份，在备份中操作，持久化完成后，写入父子进程的共享内存）
  - 自动触发
    - save m n：在m秒内，如果有n个键发生改变，则自动触发持久化，通过bgsave执行，如果设置多个，只要满足一个，则出触发持久化。
    - flushall：清空redis所有数据库的内容，flushdb清空当前redis所在库，会清空reb文件，生成新的dump.rdb,内容为空
    - 主从复制：全量同步时会自动出发bgsave命令，自动生成rdb发动给从节点
  
  **优点**
  
  1. 整个redis数据库只有一个dump.rdb文件，方便持久化
  2. 容灾性好，方便备份
  3. 性能最大化，fork子进程来完成写操作，让主进程继续处理命令，保证了IO最大化（并行执行），使用子进程进行持久化，主进程不会进行任何IO操作（写时拷贝），保证了reids的高性能。
  4. 相对于数据集大时，比AOF的启动效率更高
  
  **缺点**
  
  1. 数据安全性低，RDB是间隔一段时间持久化，若持久化期间发生故障，则数据丢失。
  2. 若降低间隔时间，则fork子进程操作频繁，则阻塞次数过多，则阻塞时间也会变长  （2,3好像是一个意思）
  3. 若数据集较大，fork子进程会占用CPU时间过长，可能导致服务器停止服务几百毫秒，甚至1s
  
- **AOF**：以日志的形式记录redis所处理的每一个**修改操作**，以文本的方式记录。（**redis默认不开启**）

  - 流程
    1. 所有修改命令会追加到AOF缓冲中
    2. AOF缓冲区根据对应的**策略**刷盘
    3. rewrite模式：随着修改操作的增加，AOF会定期进行重写，将多条指令合并，达到压缩的目的
    4. redis重启，加载aof可以进行数据恢复
  - 刷盘策略（和MySQL相似）
    - 每秒同步：异步完成，效率非常高，一旦系统出现宕机，则最多丢失1s修改的数据
    - 修改同步：每次修改操作，都会刷新到磁盘。最多丢失一条
    - 不同步：将要刷盘的内容交给操作系统，由操作系统决定什么时候刷盘
  - **优点**
    1. 数据安全
    2. 通过append模式写文件，即使由于服务器宕机也不会损坏已经写入的内容，可以通过redis-check-aof工具解决数据一致性问题
    3. AOF机制的rewrite模式，定期对AOF文件进行重写，以达到压缩的目的
  - **缺点**
    - AOF文件比RDB文件大，且恢复速度慢
    - 数据集大的时候，比rdb启动效率低
    - **运行效率没有rdb高**

**AOF与RDB对比**

- AOF文件比RDB更新频率高，优先使用AOF还原数据

- AOF比RDB更安全也更大

- RDB性能比AOF好

- 如果两个都搭配，优先加载AOF



## Redis集群方案

- 主从模式
  - 这种模式较为简单，主库可以读写，并会和从库进行数据同步，这种模式下，客户端直连接主库或某个从库，若主库或者从库宕机，客户端需要手动修改IP，另外这种模式下也比较难进行扩容，整个集群所能存储的数据受到某台机器的内存容量限制，所以不能支持特大数据量
- 哨兵模式
  - 这种模式是主从模式的升级版，主机宕机后，哨兵会发现主库节点宕机，然后在从库中选择一个库作为主库继续，另外哨兵也可以做集群，从而保证某一个节点宕机后，还有其他哨兵节点可以继续工作。这种模式可以很好的保证redis集群的高可用，但仍不能很好的解决redis容量上限问题
- Cluster
  - Cluster模式支持多主多从，这种模式可以按照key进行槽位分配，可以使得不同key分散到不同的主节点上，利用这种模式可以使得整个集群支持更大的数据容量，同时每个主节点可以拥有自己的多个从节点，如果该节点宕机，会从它的从节点再选举一个新的主节点
- 如果redis要存的数据量不大，可以选择哨兵模式，如果redis要存的数据量大，需要持续扩容，则选择cluster模式



### 主从模式

**单节点redis的并发能力是有限的，要进一步提高redis的并发能力，搭建Redis集群**

- **Replication Id**：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid
- **offset**：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。

**主从模式**（读写分离）

- **步骤**

  - ### 全量同步（发生在第一次主从同步）

    - （性能较差）
    - 第一阶段：**判断是否为第一次请求数据同步，**
      - slave请求增量同步，写携带replid和偏移量
      - master判断请求replid是否与自己的一致，第一次请求一定不一致因为slave原来的replid可能是自己的或之前的master的。
      - 不一致，返回主节点的replid和偏移量
    - 执行bgsave生成的RDB发送给slave，slave清空本地数据并加载rdb
    - 在生成rdb期间执行的所有命令写入repl_baklog日志，
    - 持续的将日志发送给slave，slave执行命令保持同步
    - ![image-20220511210222844](%E5%A4%8D%E4%B9%A0.assets/image-20220511210222844.png)

  - ### 增量同步

    - 若slave重启，重启后第一次连接，使用增量同步，只更新slave与master有差异的部分（性能较好）
    -  步骤
      - slave请求发送replid和偏移量，master判断replid一致，使用增量同步。
      - 从repl_backlog中找到slave的offset对应位置后的数据，发给slave

  - ### repl_backlog

    - 固定大小的数组，是环形的，角标到达数组末尾后，会再次从0开始读写，覆盖原来的数据。
    - repl_baklog中会记录Redis处理过的命令日志及offset，包括master当前的offset，和slave已经拷贝到的offset：
    - 增量同步时，将slave与master差异的数据发给slave
    - ![image-20220511212156352](%E5%A4%8D%E4%B9%A0.assets/image-20220511212156352.png)
    - 若slave与master差异过大，导致master覆盖了slave设置的offset的位置数据，则只能做**全量同步**

  - **优化主从集群**

    - 在master中配置repl-diskless-sync yes启用无磁盘复制，直接网络发送到slave，避免全量同步时的磁盘IO。（适用于IO慢，网络快的情况）
    - Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO
    - 适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步
    - 限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力
      - ![image-20220511213002924](%E5%A4%8D%E4%B9%A0.assets/image-20220511213002924.png)

  **简述全量同步和增量同步区别？**

  - 全量同步：master将完整内存数据生成RDB，发送RDB到slave。后续命令则记录在repl_baklog，逐个发送给slave。
  - 增量同步：slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave

  **什么时候执行全量同步？**

  - slave节点第一次连接master节点时
  - slave节点断开时间太久，repl_baklog中的offset已经被覆盖时

  **什么时候执行增量同步？**

  - slave节点断开又恢复，并且在repl_baklog中能找到offset时



- 特点：
  - 只有一个master，master可以读写数据，执行写操作，将要出现变化的数据自动同步到slave
  - slave只能读数据，可以有多个slave
  - **数据的复制是单向的，只能从主节点到从节点，即Master以写为主，slave以读为主**

**主从复制的作用：**

1. 数据冗余：主从复制实现数据的备份，是持久化之外的一种数据冗余方式
2. 故障恢复：党主节点出现问题，可以由从节点提供服务，实现快速的故障恢复，实际上是一种服务的冗余
3. 负载均衡：在主从复制基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写redis数据时应用连接主节点，读redis数据时应用连接从节点），分担服务器负载，尤其是在写少读多的情景下，通过多个从节点分担读负载，可以大大提高redis服务器的并发量
4. 高可用基石：主从复制是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础

![Image](%E5%A4%8D%E4%B9%A0.assets/Image.png)

**具体：**

1. 主机可以读写，从机不能写只能读！主机中的所有信息和数据，都会自动被从机保存！
2. 若主机断开，从机依然可以查询数据。但从机不能写。若主机重新启动，则从机依然可直接获取主机的信息
3. 若从机断开，重新连接主机，若已配置为从机（配置文件中配置）,则可以获取当前主机的全部数据



### 哨兵模式

避免了因为master宕机导致redis集群全部不可用的情况。







哨兵Sentinel有以下功能：

- 集群监控：负责监控redis master和slave进程是否正常工作
- 消息通知：如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员
- 故障转移：如果master node挂掉，会自动转移到slave node（选举一个新的master）
- 配置中心：如果故障发生，通知client客户端新的master地址

哨兵用于实现redis集群高可用的特点（上面是哨兵模式的功能，下面是redis实现哨兵模式）

<img src="%E5%A4%8D%E4%B9%A0.assets/image-20220512100729161.png" alt="image-20220512100729161" style="zoom: 50%;" />

- **服务状态监控**
  - 应用心跳机制，每一秒向集群的每个master和slave发送一个ping指令
  - **主观下线**：哨兵节点发现某个实例未在规定时间内响应
  - **客观下线：**多个哨兵（最好超过哨兵一半个数）都认为该节点主观下线，则认为客观下线。
- **选举新master**：发现master出现故障，则从slave中选择新的master
  - 首先判断slave与master断开时间长短，若时间过长，则舍弃
  - 再判断slave节点的slave-priority值，越小优先级越高
  - 若优先级一致，则对比offset，越大表明，数据越新。
  - 最后判断slave节点的id大小，越小优先级越高
- **实现步骤**
  - 选举成功后，哨兵想该节点发送slaveof no one命令，成为新master
  - 哨兵向其他节点发送新节点的地址和端口
  - 最后哨兵将故障节点标记为slave，故障恢复后成为slave节点

### 分片集群

解决主从复制中，每个节点redis保存内存过少的问题，因为但节点设置过大，使得redis主从复制困难

解决写操作较多的情况

- 有多个master，每个master保存不同数据
- 每个master有多个slave
- master之间通过ping检测彼此健康状态
- 客户端请求任意节点，会最终路由到正确节点
- ![image-20220512103112749](%E5%A4%8D%E4%B9%A0.assets/image-20220512103112749.png)



- ### **散列插槽**

  - redis将16384个插槽分配给不同的master节点。
  - set和get数据时，redis通过key计算插槽值，找到对应的master，并操作
    - set {xxx}key value   将{}内的内容进行计算插槽值
    - set key value 计算key的插槽值

- ### 集群伸缩

  - 在集群添加和删除master。注意要对插槽进行重新分配。要指定旧master的插槽迁移到新的master中

# Redis原理

## 数据结构

### 1，动态字符串SDS

![image-20220512205932859](%E5%A4%8D%E4%B9%A0.assets/image-20220512205932859.png)

Redis自定义了字符串结构：SDS（**简单动态字符串**）

- **SDS结构：**为一个结构体，（与Java中的类相似）

  - alloc:C语言需要自己申请字节数，为字符串留出裕量，则alloc>len

  - flag：指定当前SDS最大容量，避免容量太大，占用空间，容量太小，不成盛放数据。
    - 有多种大小的SDS

  - ![image-20220512133245014](%E5%A4%8D%E4%B9%A0.assets/image-20220512133245014.png)

- **动态扩容**

  - 在原本内容上添加字符串，**会申请更多的内存空间**，避免多次申请内存，申请过程消耗性能
    - 如果新字符串小于1M，则新空间为扩展后字符串长度的两倍+1；
    - 如果新字符串大于1M，则新空间为扩展后字符串长度+1M+1。称为**内存预分配**

- 优点：

  - 获取字符串长度时间复杂度为O（1）
  - 支持动态扩容
  - 减少内存分配次数
  - 二进制安全

### 2，IntSet

![image-20220512205915006](%E5%A4%8D%E4%B9%A0.assets/image-20220512205915006.png)

- 整数集合，**使用连续内存**
  - 集合编码方式 不同的编码方式表示为存储的整数大小不同
  - 数组实际指向元素地址，只保存地址值。encoding指定每个元素所占字节数
  - ![image-20220512171109952](%E5%A4%8D%E4%B9%A0.assets/image-20220512171109952.png)
- **特点**
  - **Redis会确保Intset中的元素唯一、有序。**计算元素位置：startPar+（sizeof（encoding）*index）
    - ![image-20220512171843225](%E5%A4%8D%E4%B9%A0.assets/image-20220512171843225.png)
  - **intset升级**
    - 向intset添加元素，若此元素超出encoding设置的范围，则进行intset升级
    - 流程
      - 升级到合适的编码encoding，并按新的编码方式更新旧的数据
      - 倒序依次将数组中的元素拷贝到扩容后的正确位置（正序会覆盖原来的元素）
      - 添加新的元素
      - 更改encoding和length属性
  - **由于intset有序，唯一，所以通过二分法插入和查找元素**

### 3，Dict

![image-20220512205900362](%E5%A4%8D%E4%B9%A0.assets/image-20220512205900362.png)

- redis的键值对通过Dict实现
- Dict包括 哈希表（DictHashTable）、哈希节点（DictEntry）、字典（Dict）
  - Dict![image-20220512174613279](%E5%A4%8D%E4%B9%A0.assets/image-20220512174613279.png)
  - DictHashTable
    - sizemask掩码计算插入位置，与Java的hashmap相同，与运算节省计算量。出现hash冲突，则生成链表
      - ![image-20220512174907201](%E5%A4%8D%E4%B9%A0.assets/image-20220512174907201.png)
    - table为DictEntry结合
    - ![image-20220512174519534](%E5%A4%8D%E4%B9%A0.assets/image-20220512174519534.png)
  - DictEntry![image-20220512174540818](%E5%A4%8D%E4%B9%A0.assets/image-20220512174540818.png)
- **Dict扩容/收缩**size必须是2^n
  - **扩容**
    - 在hash表元素过多时，需要进行扩容
    - 触发扩容条件（负载因子（LoadFactor = used/size））
      - hash表的LocalFactor>=1,并且服务器没有执行bgsave或者AOF持久化操作
      - hash表的LocalFactor>5
  - **收缩**
    - 若LocalFactor<0.1时，收缩
  - **渐进式rehash**：扩容/收缩会创建新的hash表，导致hash表的size和sizemask变化，将旧hash表的数据重新计算位置到新hash表。渐进式为了避免因为hash表过大一次rehash操作过慢，阻塞主线程
  - **步骤**
    - 计算新的hash表的size
    - 创建新的大小为size的hash表，赋值给Dict的dict.ht[1]
    - **rehash操作不是一次性完成**，每次增删查改，都会将dict.ht[0]旧hash表中的一个链表迁移到新hash表。直到全部迁移，
    - 交换dict.ht[0]和dict.ht[1]，并释放dict.ht[1]，rehash结束
    - 新增操作直接写入ht[1],查，修，删会在rehash操作时两个表都查找执行

### 4，ZipList

![image-20220512213650296](%E5%A4%8D%E4%B9%A0.assets/image-20220512213650296.png)

压缩列表：特殊双端链表，底层并不是双向链表，但可以实现双向链表功能。**使用连续内存**

![image-20220512203736912](%E5%A4%8D%E4%B9%A0.assets/image-20220512203736912.png)

- zlbytes：记录整个压缩列表占用的字节数
- zltail：记录尾结点距离拉锁列表起始位置的偏移量。可以计算确定尾结点的地址（快速查找）
- zllen：包含的结束数
- zlend：结束字符，标记压缩列表末端
- entry：节点，长度不固定，随内容变化，节省内存
  - ![image-20220512204132893](%E5%A4%8D%E4%B9%A0.assets/image-20220512204132893.png)
  - previous_entry_length：前一节点的长度，占1个或5个字节
    - 前一节点的长度小于254字节，占1个字节，大于则占5个字节
  - encoding：编码属性，记录content的数据类型，以及长度
    - 00、01或者10开头代表字符串，分别占有1,2,5比特。后面为content长度
    - 11开头，content为整数，只占用1字节，表示整数占用字节数
      - ![image-20220512210833503](%E5%A4%8D%E4%B9%A0.assets/image-20220512210833503.png)
  - contents：节点数据

压缩列表操作到指定位置的数据，每个节点，可知上一个节点的长度，进而得知previous_entry_length，在根据encoding的前两位知道encoding的长度和content的长度，得到了整个entry的长度，可以到下一个entry

- **连续更新问题**
  - 如下链表时，在首节点插入一个超过254字节的entry，则后续的第一个entry的previous_entry_length就要增加4，，但该entry的结点长度原来是是250字节，增加后，后续节点也要加4.
  - ![image-20220512213745723](%E5%A4%8D%E4%B9%A0.assets/image-20220512213745723.png)
  - ZipList这种特殊情况下产生的连续多次空间扩展操作称之为**连锁更新（**Cascade Update）。新增、删除都可能导致连锁更新的发生。

### 5，QuickList

![image-20220512220010542](%E5%A4%8D%E4%B9%A0.assets/image-20220512220010542.png)

- 为双向链表，每个节点为ZipList（ZipList需要连续内存，双向链表使得可以使用多个ZipList，从而一定程度缓解使用连续内存的问题）。
- ZipList可以设置list上限，可以设置大小或者节点个数
- 可以对ZipList进行压缩。进一步节省内存
- ![image-20220512215853882](%E5%A4%8D%E4%B9%A0.assets/image-20220512215853882.png)

### 6，SkipList

![image-20220513102855426](%E5%A4%8D%E4%B9%A0.assets/image-20220513102855426.png)

**跳表**

- 双向链表，有序
- 每个节点不仅可以指向下一个节点，还可以指向不同跨度的节点（在查找元素时更快）
- ![image-20220513103016857](%E5%A4%8D%E4%B9%A0.assets/image-20220513103016857.png)

### RedisObject

redis中的数据，键和值都会封装为一个RedisObject。

![image-20220513104130815](%E5%A4%8D%E4%B9%A0.assets/image-20220513104130815.png)

redis会根据不同的数据类型，选择不同的编码方式，即一个对象类型有多种编码方式。HT为hashtable

![image-20220513104258838](%E5%A4%8D%E4%B9%A0.assets/image-20220513104258838.png)

包含11种不同类型：11种不同类型：

![image-20220513104541000](%E5%A4%8D%E4%B9%A0.assets/image-20220513104541000.png)



### 五种基本数据类型

首先都是redisObject对象，更底层使用不同的编码方式

#### String

- 基本编码方式：RAW，基于简单动态字符串（SDS）实现，上限是512MB。
- 若存储的SDS长度小于44字节，则采用EMBSTR编码（读法：M String）编码，
  - **注意**，此编码格式下，RedisObject与SDS在内存中为连续空间，不是指针指向的关系。（申请内存时只需要调用一次内存分配函数，效率高）
  - 此编码下，该对象最多占用64字节
  - 此时底层仍使用SDS保存对象
- 若存储为整数值，采用INT编码，RedisObject中的pre直接保存数值，不用使用SDS了 

#### List

- 底层使用QuickList，可以双端访问，且内存占用较低，包含多个ZipList，存储上限高

![image-20220513112645518](%E5%A4%8D%E4%B9%A0.assets/image-20220513112645518.png)

#### Set

无序，元素唯一，可以求交集并集，差集

- 底层采用HT编码，即Redis中的Dict。Dict 可以保存键值对,value统一为null
- 若存储的所有数据都是整数时，且元素数量不超过set-max-intset-entries阈值，采用intset节省内存

#### Zset

set存储，且按分数排序，元素唯一，可以通过元素获取分数

- 底层使用SkipList和HT结合的方式，

  - SkipList：可以排序，按分数排序，可以同时存储元素和分数。（保证有序性）

  - HT（Dict）：键值存储，key=元素，value=分数   （保证键值对，通过元素获取分数）

- 在数量较小时，采用ZipList结构节省内存。

- （同时维护两个结构，消耗内存，数量很小时，无序和有效没有太大差别）

  - 同时满足如下两个条件
  - 元素数量小于阈值（默认128）
  - 元素大小小于64字节
  - ZipList没有排序功能，也不是键值对存储，采用了新的编码方式
    - ZipList为连续内存，因此score和element是紧挨在一起的两个entry， element在前，score在后
    - score越小越接近队首，score越大越接近队尾，按照score值升序排列

#### Hash

键值存储，唯一

- 底层使用HT（Dict），与Zset类似
- Hash结构默认采用ZipList编码，相邻的两个entry分别保存key和value
- 数据量较大时，会转为HT编码（Dict），触发条件（满足一个则转变）
  - ZipList的元素数量超过了阈值，默认512
  - ZipList的entry大小超过阈值64字节

## 网络模型

### 1，用户空间和内核空间

为了避免用户应用与操作系统在计算机上冲突，分为内核空间和用户空间（用户态和内核态）

- 用户态只能调用自己的资源，系统资源需要向系统申请，由内核态代为执行
- 内核态可以调用系统一切资源



- ## Linux下的IO过程

  - 在用户空间和内核空间都有缓冲区
  - 写数据时，要把用户缓冲数据拷贝到内核缓冲区，然后写入设备
  - l读数据时，要从设备读取数据到内核缓冲区，然后拷贝到用户缓冲区
  - 五种IO模型 
    - 看操作系统的IO模型

### 2，Redis网路模型

- 看redis 单线程

### RESP协议

是RESP2协议，客户端发送遵从此协议的信息，与Redis的Service通信

- u单行字符串：首字节是 ‘**+**’ ，后面跟上单行字符串，以CRLF（ "**\r\n**" ）结尾。例如返回"OK"： "+OK\r\n"

- 错误（Errors）：首字节是 ‘**-**’ ，与单行字符串格式一样，只是字符串是异常信息，例如："-Error message\r\n"

- 数值：首字节是 ‘**:**’ ，后面跟上数字格式的字符串，以CRLF结尾。例如：":10\r\n"

- 多行字符串：首字节是 ‘**$**’ ，表示二进制安全的字符串，最大支持512MB：

- 如果大小为0，则代表空字符串："$0\r\n\r\n"

- 如果大小为-1，则代表不存在："$-1\r\n"

- 数组：首字节是 ‘*****’，后面跟上数组元素个数，再跟上元素，元素数据类型不限:（一般都使用数组）

- set name ”虎哥”

  - ```
    *3\r\n
    $3\r\nset\r\n
    $4\r\nname\r\n
    $6\r\n虎哥\r\n
    ```

### 内存策略

若占用内存过多，影响性能，若是达到上限，则无法存储其他数据。所以采用了一些策略实现内存回收

#### 内存过期策略

- Redis是如何知道一个key是否过期呢？
  - 数据库中保存有两个Dict，即两个字典，一个是key-value，一个是key-ttl保存过期时间。所以在获取数据时，从一个Dict中获取值，从一个Dict中获取过期时间，验证是否过期

- 是不是TTL到期就立即删除了呢？
  - 不是，因为实时检测每个key的过期时间过于消耗性能，采用了两种方式
  - **惰性删除：**获取数据时，检测是否过去，若过期，则删除该key。
    - 为避免保存在redis的key，已过期没有访问，又引入了周期删除
  - **周期删除**：周期性的抽样部分key，判断是否过期，进行删除
    - 服务器初始化时，按照server.hz的频率执行过期key的处理，使用SLOW模式
    - 每个事件循环前，执行过期key清理，使用FAST模式
  - SLOW模式（速度较慢，但效率高）
    - 执行频率受server.hz影响，默认为10，每个周期100ms
    - 执行一次删除操作不超过周期的25%
    - 每个遍历db，遍历db中的bucket，抽取20个key判断是否过期。
    - 如果没达到时间上限（25ms）并且过期key比例大于10%，再进行一次抽样，否则结束
  - FAST模式（速度快）
    - 执行频率受事件调用影响，两次之间间隔不低于2ms
    - 执行清理耗时不超过1ms
    - 每个遍历db，遍历db中的bucket，抽取20个key判断是否过期。
    - 如果没达到时间上限（1ms）并且过期key比例大于10%，再进行一次抽样，否则结束

#### 内存淘汰策略

在redis内存使用超出阈值，会主动删除部分key，释放内存。**需要设置redis内存上限才会执行内存淘汰**

- noeviction： 不淘汰任何key，但是内存满时不允许写入新数据，默认就是这种策略。
- volatile-ttl： 对设置了TTL的key，比较key的剩余TTL值，TTL越小越先被淘汰
- allkeys-random：对全体key ，随机进行淘汰。也就是直接从db->dict中随机挑选
- volatile-random：对设置了TTL的key ，随机进行淘汰。也就是从db->expires中随机挑选。
- allkeys-lru： 对全体key，基于LRU算法进行淘汰
- volatile-lru： 对设置了TTL的key，基于LRU算法进行淘汰
- allkeys-lfu： 对全体key，基于LFU算法进行淘汰
- volatile-lfu： 对设置了TTL的key，基于LFI算法进行淘汰

LRU（Least Recently Used），最少最近使用。用当前时间减去最后一次访问时间，这个值越大则淘汰优先级越高。

LFU（Least Frequently Used），最少频率使用。会统计每个key的访问频率，值越小淘汰优先级越高。

![image-20220513202627236](%E5%A4%8D%E4%B9%A0.assets/image-20220513202627236.png)



# 数据结构

## 红黑树

自平衡的二叉搜索树：**本质红黑树是对2-3-4树的一种实现**，将所有的结点看做为黑结点形成2叉结点，红结点与父黑结点结合形成3-4叉结点。都是黑色结点

2叉结点：只包含大于它的结点和小于它的结点

3叉结点：一个黑结点与一个红结点结合     （15,30） 指向3个位置：x<15  15<x<30,x>30

4叉结点：一个黑结点与两个个红结点结合   （15,27,33）

https://zhuanlan.zhihu.com/p/273829162

规则：

1. 结点是红色或黑色。
2. 根结点是黑色。
3. 每个叶子结点都是黑色的空结点（NIL结点）。
4. 每个红色结点的两个子结点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色结点)
   - **因为红黑树是2-3-4树的具体体现，红色结点可以连接，则意味着不止是4叉的结点，可能多个，不满足条件**
5. 从任一结点到其每个叶子的所有路径都包含相同数目的黑色结点。
   - **红色结点与黑色结点绑定，则只有黑色结点贡献真实高度，所以在相同的黑色结点意味着该树真正的平衡**


调整的方式有两种：变色和旋转（左旋和右旋），来满足规则

从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。

- **原因：因为任一结点到叶子节点的所有路径都包含相同的黑色节点个数，则最长路径为最短路径的2倍往上，则以为着一条路径上，红色结点个数多于黑色节点个数，也就是说：红色结点连接在一起，与定义矛盾**



“您应该知道红黑树的五条定义，如果我构造一颗只有黑色节点的红黑树，这样子可行吗？因为这样子没有破坏任何一条红黑树的规则。”

- 您说的一点问题也没有，但需要满足如下要求
- 由于任一节点到每一个叶子节点的所有路径包含相同数目的黑色节点。**则需要所有叶子节点等高**
- **添加元素或者删除元素，需要保存等高的要求，也就是说添加结点需要添加一整层才可以，删除也是。**







# JVM

## jvm怎么调优？





## 运行时出现了while （true）即Java运行程序占用CPU100%，问题排查？（Linux）

![image-20220328203844503](%E5%A4%8D%E4%B9%A0.assets/image-20220328203844503.png)

https://juejin.cn/post/7040422748981100551



https://www.cnblogs.com/rinack/p/12969851.html

https://blog.csdn.net/baiye_xing/article/details/90483169

1. **top**   （查看系统CPU的占用情况）
2. top -Hp 进程ID   （查看进程下所有线程的CPU占用，进程ID从第一条命令获取）
3. printf "%x\n" 线程ID    （将需要的线程ID转换为16进制格式，也可以自己手动转换，不输入指令）
4.  jstack 进程号 | grep 线程ID   （查找该进程下某线程的详细情况，也可以只查进程，**注意此时线程ID需要写16进制数字**， stack  ）
   1. "VM Thread" os_prio=0 tid=0x00007f871806e000 nid=0xa runnable   （如果显示“VM Thread”，表示为垃圾回收线程，当前系统缓慢的原因主要是垃圾回收过于频繁，导致GC停顿时间较长。）
      1. jstat -gcutil 进程号 统计间隔毫秒 统计次数（缺省代表一直统计）   **查看某进程GC持续变化情况**
      2. 如果发现返回中FGC很大且一直增大，则可以确认为**内存溢出问题**
         1. 代码中一次获取了大量的对象，导致内存溢出，此时可以通过eclipse的mat工具查看内存中有哪些对象比较多；
      3. 内存占用不高，但是Full GC次数还是比较多，此时可能是显示的System.gc()调用导致GC次数过多，这可以通过添加-XX:+DisableExplicitGC来禁用JVM对显示GC的响应。
      4. jmap -heap 进程ID   查看进程堆内存使用情况
   2. 如果不是垃圾回收线程，则是执行问题，可能出现了while（true）问题，**在步骤4 jstack，可直接定位到代码行**，所以下面1,2意义不大
      1. jstack [进程]|grep -A 10 [线程的16进制]    -A 10表示查找到所在行的后10行
         1. 例子： jstack 21125|grep -A 10 52f1  
         1. 所以也可以直接  jstack 进程ID |grep 线程ID   定位到出现问题的代码
   3. 还有可能是死锁，此时会直接提示。关键字：deadlock.
5.  jmap -dump:format=b,file=filename pid   （导出某进程下内存heap输出到文件中。可以通过eclipse的mat工具查看内存中有哪些对象比较多）





# 网络篇

拥塞控制

## TCP 面试系列之快重传与快恢复

https://zhuanlan.zhihu.com/p/261096328

- 快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等待自己发送数据时才进行捎带确认。
- 快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段 M3，而不必继续等待为 M3 设置的重传计时器到期。

快恢复

- 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把慢开始门限ssthresh 减半。这是为了预防网络发生拥塞。请注意，接下去不执行慢开始算法。
  （慢开始算法，拥塞窗口最开始为1，快恢复只用将窗口减半）

![img](https://pic2.zhimg.com/80/v2-71c881dd3ce05d691b4b7d937dab8a85_720w.jpg)

## SYN攻击

**简介**：利用TCP协议栈三次握手弱点来进行网络攻击，

- TCP协议建立连接的时候需要双方相互确认信息，
- SYN攻击通过故意不完成建立连接所需要的三次握手过程，造成连接一方的资源耗尽。
- 通过发送大量的半连接请求，耗费CPU和内存资源。

**相关概念：**

- **半连接**：服务器发送SYN-ACK之后，收到客户端的ACK之前的TCP连接称为半连接
- **半连接队列**：服务器维护一个半连接队列，存放半连接
- **SYN-ACK 重传次数**：服务器发送完SYN－ACK包，如果未收到客户确认包，服务器进行重传，有次数限制
- **半连接存活时间**：服务从收到SYN包到确认这个报文无效的最长时间

**SYN攻击**

- 大量发送伪造源IP的SYN包也就是**伪造第一次握手数据包**，服务器每接收到一个SYN包就会为这个连接信息分配核心内存并放入半连接队列，如果短时间内接收到的SYN太多，半连接队列就会溢出
- 客户端在短时间内伪造大量不存在的IP地址，向服务器不断地发送syn包，服务器回复确认包，并等待客户的确认，由于源地址是不存在的，服务器需要不断的重发直至超时，这些伪造的SYN包将长时间占用未连接队列



攻击梳理：

- 通过伪造源IP，发送第一次握手数据包，服务器将其添加到半连接队列，（队列溢出）
- 不断的超时重传第二次握手，占用网络资源。

**SYN攻击防范技术**

- **SYN攻击不能完全被阻止**
- 通过防火墙、路由器等**过滤网关防护**
- 通过**加固TCP/IP协议栈防范**

- 缩短超时时间



## TCP建立连接后怎么保持连接？

用TCP协议自身的保活定时器实现**心跳机制**。

- 心跳机制的实现有两种方式：
  - 应用层自己实现心跳包
    - 应用程序发送心跳包
  - TCP本身存在心跳机制

- 定时向被检测系统发送心跳包，被检测系统收到心跳包进行回复，收到回复说明对方存活。心跳能够给长连接提供保活功能，能够检测长连接是否正常，一旦链路死了，不可用了，能尽快知道，

  



# MySQL

## 存储过程

简介：都类似于java中的方法，将一组完成特定功能的逻辑语句包装起来，对外暴露名字

- 创建   procedure  ` /prəˈsiːdʒə(r)/ `

  - ```
    create procedure 存储过程名(参数模式 参数名 参数类型)
    begin
              存储过程体
    end
    注意：
    1.参数模式：in、out、inout，其中in可以省略
    2.存储过程体的每一条sql语句都需要用分号结尾
    ```

- 调用

  - call 存储过程名(实参列表)

- 删除

  - drop procedure 存储过程名;

创建和使用

```sql
# 创建
DELIMITER $
CREATE PROCEDURE sql2()
BEGIN
    SELECT * FROM beauty;
END $
# 使用
CALL sql2()$ 
```

## delete和truncate的区别

truncate和delete只删除数据，而drop则删除整个表

- delete
  - 表空间中其被删除数据的表占用的空间还在，便于以后的使用，**即可以进行恢复**
  - delete 可以有where条件，所以可以删除指定的数据，
  - delete 是逐条删除
  - truncate 重置auto_increment的值。而delete不会
- truncate
  - 删除表再创建，清空了表的数据
  - 无法进行回滚恢复，
    - 即执行事务，使用delete删除数据，可以回滚恢复
    - 使用truncate无法恢复
- drop
  - 删除表，上面两个仅仅是删除表中的数据

## 表多且表数据很多，怎么分库分表

https://cloud.tencent.com/developer/article/1819045

- 数据切分（单表的数据超过1000万条，或者单表超过100G，影响到了处理性能，即使添加索引，性能仍下降）：
  - 作用：减少数据库的负担，缩短查询时间
- **垂直分库**：根据业务耦合性，将关联度低的不同表存储在不同的数据库
- **垂直分表**：将表中的某些列拆分到扩展表。MySQL底层使用数据页存储，若单条记录占用空间过大，导致跨页（多页来保存一条记录）。必然会消耗性能。此时垂直分表就十分重要
  - 优点
    - 解决了业务系统层面的耦合，业务清晰
    - 与微服务的治理类似，对不同业务的数据进行了分级管理，维护
    - 高并发场景下，垂直切分一定程度的提升IO、数据库连接数、单机硬件资源的瓶颈
  - 缺点：
    - 依然存在单表数据量过大的问题（数据行数过多）
    - 分布式事务处理复杂

- 水平分表



# Spring

## 事务怎么配置，事务什么时候会失效

- spring事务
  - 声明式事务（用的较多）
  - 编码式事务
- spring事务管理**通过AOP方法来实现**
- **事务管理代码的固定模式作为一种横切关注点，可以通过AOP方法模块化，进而借助Spring AOP框架实现声明式事务管理**
- 步骤：
  - 开启事务管理器（本质为管理事务的切面类）
  - 在事务方法上添加@Transactional注解
- **事务失效的情况**
  - **事务通过AOP进行了切面增强，失效根本原因是AOP没起作用**
  - 事务方法所在类没有被spring管理，->首先是一个spring的Bean才能使用AOP
    - **AOP的实现基于动态代理。所以需要满足动态带来的要求**
      - 在同一个类中的方法直接内部调用,会失效>对象本身通过this调用，绕过了代理类调用，。
      - 该事务方法被final修饰的->子类无法继承和重载，代理类无法重写该方法来添加事务
      - 方法不是public修饰， **@Transactional注解只能⽤于 public 的⽅法上**
  - 数据库不支持事务
  - 异常在方法内被catch掉，事务不会回滚
  - 未发生@Transactional指定的异常。（默认是RuntimeExcelption，运行时异常）

### 在同一个类中的方法直接内部调用,事务失效的问题解决办法

可以通过aspectj来解决

- 引入AspectJ的相关配置包
- 开启注解@EnableAspectJAutoProxy(exposeProxy = true)：开启AspectJ动态代理，**并暴露代理对象**
- 本类的方法的相互调用
  - 本类方法的直接调用

```Java
MallOrderApplication order =(MallOrderApplication) AopContext.currentProxy();
order.method1();
order.method2();
```



## AOP：AspectJ、原生动态代理，CGLIB关系 

## Spring 中的bean 是线程安全的吗？

https://www.cnblogs.com/myseries/p/11729800.html

**不是线程安全的**

- Spring容器没有提供Bean的安全策略。所以容器中的Bean不具备线程安全的特性。但具体还是要结合Bean的作用范围
  - 若是原型Bean，不被容器管理，则每次线程使用需要自己创建对象。**不存在Bean共享问题**
  - 单实例Bean，所有线程使用一个单实例Bean，所以存在线程间的资源竞争
  - **spring单例，为什么controller、service和dao能保证线程安全？**
    - Spring中的Bean默认是单实例的，又没有准备Bean安全策略。不具备线程安全的特性。
    - 虽然controller、service和dao层本身不是线程安全的。但是这些Bean不会保存数据。多线程调用的是一个实例方法，也就是在每个线程的虚拟机栈的栈帧来处理。所以是安全的。

## Spring能不能解决循环依赖问题？

https://cloud.tencent.com/developer/article/1769948

循环依赖：A依赖B，B依赖A。

能

spring内部有三级缓存：

- singletonObjects 一级缓存，用于保存实例化、注入、初始化完成的bean实例
- earlySingletonObjects 二级缓存，用于保存实例化完成的bean实例
- singletonFactories 三级缓存，用于保存bean创建工厂，以便于后面扩展有机会创建代理对象。



![img](%E5%A4%8D%E4%B9%A0.assets/1620.png)

![img](%E5%A4%8D%E4%B9%A0.assets/v2-abe8d96f198a33fcfd51bb2108b00004_720w.jpg)

首先Spring尝试通过ApplicationContext.getBean()方法获取A对象的实例，由于Spring容器中还没有A对象实例，因而其会创建一个A对象

然后发现其依赖了B对象，因而会尝试递归的通过ApplicationContext.getBean()方法获取B对象的实例

但是Spring容器中此时也没有B对象的实例，因而其还是会先创建一个B对象的实例。

读者需要注意这个时间点，此时A对象和B对象都已经创建了，并且保存在Spring容器中了，只不过A对象的属性b和B对象的属性a都还没有设置进去。

在前面Spring创建B对象之后，Spring发现B对象依赖了属性A，因而还是会尝试递归的调用ApplicationContext.getBean()方法获取A对象的实例

因为Spring中已经有一个A对象的实例，虽然只是半成品（其属性b还未初始化），但其也还是目标bean，因而会将该A对象的实例返回。

此时，B对象的属性a就设置进去了，然后还是ApplicationContext.getBean()方法递归的返回，也就是将B对象的实例返回，此时就会将该实例设置到A对象的属性b中。

这个时候，注意A对象的属性b和B对象的属性a都已经设置了目标对象的实例了

读者朋友可能会比较疑惑的是，前面在为对象B设置属性a的时候，这个A类型属性还是个半成品。但是需要注意的是，这个A是一个引用，其本质上还是最开始就实例化的A对象。

而在上面这个递归过程的最后，Spring将获取到的B对象实例设置到了A对象的属性b中了

这里的A对象其实和前面设置到实例B中的半成品A对象是同一个对象，其引用地址是同一个，这里为A对象的b属性设置了值，其实也就是为那个半成品的a属性设置了值。
