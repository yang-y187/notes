# 梳理

**表的信息**

- attr：属性表  （颜色，长度，重量）

- attr-group 分组  每个分组下有多个属性，即分组（基本信息）   --属性（颜色，长度，重量）
- category   目录，即三级分类表，即手机-->分组(主体，基本信息)
- wms库存
  - ware 仓库
- spu：属性值、特性相同的商品就可以称为一个SPU
- sku： 具体的商品。     SPU 就是类，SKU就是对象。

**微服务名字**

1. 商品微服务：
   - 三级列表，商品详情，品牌，spu，sku，商品属性

2. 自动登录微服务：
   - 登录微服务。（与成员微服务分隔开）（方便后续做单点登录）

3. 购物车微服务：
   - 加入购物车

4. 订单微服务：
   - 生成，取消订单以及支付操作

5. 公共微服务：【其他的微服务都继承了该微服务】
   - 盛放公共类，DO，TO，contant（固定字段），R（每次请求都是返回R对象，R（code，data），异常的枚举类）

6. 优惠券微服务：
   - 优惠劵相关信息(仍在开发)

7. 网关微服务：
   - 请求转发，针对所有请求进行统一鉴权、限流、熔断、分发、跨域配置、日志等。

8. 用户微服务：
   - 操作用户信息

9. 查询微服务：
   - 使用ES查询

10. 秒杀微服务：
    - 秒杀功能的 实现

11. 第三方微服务：
    - 云服务器上传图片（存储图片）
    - 发送短信服务

12. 库存微服务：

    

13. 启动脚手架：后台服务的脚手架框架

**商品数据库**

- 商品三级分类表
  - **pms_category**![pms_category](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220724155253197.png)
  - **pms_brand**![image-20220724155307624](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220724155307624.png)
  - **pms_category_brand_relation**![image-20220724163551228](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220724163551228.png)
    - **你明明有类别表，又有品牌表，怎么又有一个品牌与三级分类的关联表，那你怎么不直接在品牌表里添加一个字段表明类别？**
      - 不行，现在的品牌都多样化，一个品牌可能手机，平板，卖很多种类商品，添加一个字段不能表明。需要品牌_类别关系表，后面还有这种关系表。（一个类别里有多个品牌，一个品牌也可以涉及多个类别，**涉及到多对多的关系** ）
      - 而且我们品牌关联的请求，这样操作很方便，解耦。不会对原来的类别表和三级分类表有影响。在创建类别，三级分类，以及建立关系时更加方便
    - 因为使用中间表
      - 对于需要经常联合查询的表，可以建立中间表以提高查询效率。 
      - 通过建立中间表，将需要通过联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询。
  - **pms_attr_group**![image-20220724155640198](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220724155640198.png)spu的公共信息，屏幕，芯片，主体等信息
  - **pms_attr**![image-20220724155404887](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220724155404887.png)上市年份，入网型号，机身工艺，CPU型号，内存（销售属性，有内存容量集合)，颜色（销售属性,有颜色集合)
  - **pms_attr_attrgroup_relation**![image-20220724155428448](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220724155428448.png)
  - **pms_product_attr_value**![image-20220724155458956](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220724155458956.png)spu属性值表: 颜色，黑色；颜色，绿色【一个属性值对应一条记录，方便内存使用以及返回用户，**重点表明是哪个商品的属性，虽然手机有些公共属性，但不排除一些spu有特殊的属性，需要与spu进行对应**】
    - **与商品属性表的区别**
      - **属性表着重于有哪些属性，值拼接到在一个字段，而属性值表有与spu的对应关系，以及一个值对应一条记录**
  - **pms_spu_info**![image-20220724155711708](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220724155711708.png)
  - **pms_spu_info_desc**![image-20220724155731869](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220724155731869.png)
  - **pms_spu_images**![image-20220724155751144](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220724155751144.png)
  - **pms_sku_info**![image-20220724155812561](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220724155812561.png)spuid，名称，描述，状态【是否上架，0：未上架，1：上架】
  - **pms_sku_sale_attr_value**![image-20220724155832913](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220724155832913.png)
  - **pms_sku_images**![image-20220724155859353](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220724155859353.png)

- # Redis信息

  - 存取了三级分类的目录，使用springCache中间件。

    - 清除数据

      ```
      @CacheEvict(value = "category", allEntries = true)
      ```

    - 保存数据

      ```
      @Cacheable(value = {"category"}, key = "#root.method.name")
      ```
      
    - 为避免缓存击穿，进行了加分布式锁，只允许一个线程去访问数据库

  - 已登录用户信息

    - 【登录凭证，用户登录后，客户端有一个cookie（key：token，value：uuid）后台服务器收到该cookie后，取出uuid，从redis中获取对象信息】

    - 为什么不用threadLocal？
      - threadLocal虽然是单线程可以线程内共享 ，但跨服务的话，就无效了，反倒是redis更方便一些。所以在一个微服务内先用拦截器拦截，从redis中获取用户的信息，保存在ThreadLocal中。
  
  - 验证码：手机号为key，验证码与获取时的时间拼接为value
  
  - 热点商品信息【等待商榷】
  
  - **购物车**    key：gulimall:cart：userId，value=hash，内部是一个hash，key=skuId，value=商品信息
  
    - 为什么把购物车放在redis，而不是数据库，那redis是缓存还是数据库？
      - 因为购物车读多，写多。所以我们将数据放在了redis。redis开启了RDB持久化。
    - 会有缓存不一致性的问题吗？
      - 购物车中的信息可能数数据库中的价格不一致，所以下订单结算时，【查询三次价格，进入购物车时，去结算进入订单确认页，提交订单进入结算页 】
      - 但是我们并未设置商品价格改动的部分，后续我们会进行完善；
  
  - 秒杀的商品信息
  
    - 秒杀会场信息：多个list集合，key： seckill:sessions:startTime_endTime，value：sessionId-skuId的list集合（以此区分不同的秒杀活动有不同的价格）
    - 秒杀的商品信息：   所有的秒杀商品保存在一个hash中。key：seckill:skus   value：hash    
      - hash内部，key：sessionId-skuId，value 商品信息，商品的详细信息，该商品的结束起始结束时间，数量，价格，每名用户允许购买的价格，随机码信息
    - 商品信号量：key：seckill:stock:随机码   ，value：库存个数=信号量
    
  - **原子令牌：**
  
    - 下订单前有一个结算页，





- 缓存失效问题的使用
  - 防止缓存击穿，缓存雪崩，缓存穿透
    - 缓存击穿：redis中数据过期，查询数库时，加悲观锁（分布式情况下为分布式锁）。获取锁后，再次判断redis是否有数据，有数据直接返回，没有数据，访问数据库，保存到redis中后再释放锁，即使竞争到锁，也先在redis中再获取一次对象。而且先保存数据，再释放锁。【三级分类】
    - 缓存穿透：将null保存在redis中，设置短暂的过期时间
    - 缓存雪崩：设置过期时间时，加上一定的随机数





# 启动相关服务 

1. 启动服务器
2. cmd连接服务器，vagrant ssh  必须是系统所在文件夹下的cmd
3. 启动nacos



# 备用知识

指定要变成实现类的接口所在的包，然后包下面的所有接口在编译之后都会生成相应的实现类

```
@MapperScan("com.example.mall.ware.dao")
```



# ==简历==

商城项目：适应B2C模式，商家将商品卖给用户

- 为什么要进行压测？
  - 测试应用在高并发情况下是否会报错，进程是否会挂掉，
  - 测试应用的抗压能力，预估应用的承载能力，为后面的运维提供扩容的依据。
  - 验证系统性能指标,同时**发现系统中存在的性能瓶颈, 最后起到优化系统的目的。**
  - 另外，通过压力测试，可能找到其他方法很难发现的错误，例如：**内存泄露，并发与同步。**
- **通过压力测试及内存监控定位系统吞吐量瓶颈并进行了业务优化；**
  - （监控性能，包括中间件以及数据库，最后进行JVM调优）
    - TPS原本是不到1300左右，到2300左右
  - 业务层面
    - 系统：**无关的日志不打印**
    - 业务逻辑
      - 涉及到feign调用的内容，使用线程池通过异步编排的方式请求，CompletableFuture，提高响应速度。
      - 优化业务逻辑，比如说之前是查询多次数据库，现在可以一次性查出所有的数据，或者线程池请求；
    - DB：
      - MySQL优化，给需要的字段加上索引
      - **异步执行：创建线程池，异步查询数据，提高响应速度**
    - 使用Redis缓存，将一些数据放入Redis中（热点商品信息，秒杀活动商品信息，已登录用户信息，验证码等信息）
    - 模板的渲染速度：开启thymeleaf缓存
    - 静态资源处理：**Nginx实现动静分离**，静态页面的获取直接在Nginx中获取，不会落到后端服务器上。动态请求来到后端服务器
      - ngnix作用：
        - 静态http服务器，将静态资源放在ngnix服务器上，缓解后端服务器压力
        - **反向代理**服务器：客户请求ngnix，又ngnix再请求应用到服务器，实现负载均衡。
        - 负载均衡
    - jvm调优：
      - 增大服务内存占用，会增加内存空间，减少GC次数（无论是老年代GC还是新生代GC都会减少），提高吞吐量
      - 指定堆内存最大 ：-Xmx1024m
      - 指定堆内存初始大小：-Xms1024m     （与最大堆内存相同，则表示堆内存就是1024m，不必在运行时申请内存，影响性能）
      - 指定新生代大小：-Xmn512m   （因为测试请求，大量的请求进来会创建需要临时对象改为1:1）
      - -XX: NewRatio，默认值：2，也就是说新生代和老年代的默认比值是 1：2；
      -  Eden 和 Survivor 大小比例  8:1:1      改变Eden 和 Survivor比例  -XX:SurvivorRatio=8
      -  使用G1垃圾回收器  -XX：+useG1GC
- **分布式锁：**使用Redis缓存商品信息数据避免了缓存失效的情况，使用分布式读写锁解决了缓存一致性问题
  - 分布式锁：
    - 使用场景：秒杀，分布式情况下，需要加锁的场景。
      - 比如说，从数据库获取三级列表（**我们认为是访问量最大的接口，在首页完成的三级列表展示**），定时任务（尽量不要说）
  - 防止缓存击穿，缓存雪崩，缓存穿透
    - 缓存击穿：redis中数据过期，查询数库时，加悲观锁（分布式情况下为分布式锁）。获取锁后，再次判断redis是否有数据，有数据直接返回，没有数据，访问数据库，保存到redis中后再释放锁，即使竞争到锁，也先在redis中再获取一次对象。而且先保存数据，再释放锁。
    - 缓存穿透：将null保存在redis中，设置短暂的过期时间
    - 缓存雪崩：设置过期时间时，加上一定的随机数



- **分布式事务**：分布式事务就是为了保证不同数据库的数据一致性。还是不要写在简历里面（这个问题可以往深了问，自己并没有学那么深）
  - 没有分布式事务，Seata保证了数据的一致性，因为数据需要分布式事务需要各种加锁，不能满足高并发的要求，选择了**可靠消息的最终一致性方案。即业务处理服务，业务事务提交前，发送消息**
  - 流程
    - 消息生产者通过业务操作完成数据的操作，在准备发送消息的时候，先将消息存储一份，然后发送给消息中间件集群。
    - 消息消费者监听消息中间件中的消息，消费者消息处理之后处理之后，调用消息生产者接口，进行消息消费确认。
    - 消息生产者接受消息确认之后，删除消息数据。
    - 消息查询服务查询消息在被接收之后没有返回消息消费确认，那么就通过消息恢复熊进行消息重新发送。










- **可靠消息的最终一致性方案应用：**应用rabbitMq，通过延时队列完成订单过期取消，实现可靠消息的最终一致性：


  - 延时队列：实现

    -  下单成功时，将消息交给交换机路由给一个队列，该队列没有消费者，等待30分钟过期，再将该队列转发给死信队列。消费者消费该死信队列；
    - **mq消息队列：将消息交给交换机，交换机通过路由键传递给对应的队列。消费者从队列中获取消息。**

  - 维护两个延时队列

    - 解锁库存延时队列，和关单延时队列【而且要求 关单延时队列早于库存延时队列】

  - 下订单库存锁定成功，向交换机通过路由键（stock.locked）找到延时队列【死信队列，没人消费】，等待响应的时间，消息过期，将死信交给新的交换机，并通过新的路由键（stock.release），找到release队列，消费者监听该队列，执行响应的解锁库存和关单操作
  - 解锁库存延时队列

    - 生产者【库存微服务】，消息：保存的工作单Id和详情单
      - 锁定库存时，会保存一个工作单和详情单，分别对应订单和订单上的购物项。保存到数据库。 
      - 生产者每锁定完一个商品则保存一个详情单，并将工作单 ID与详情单信息添加到消息队列
      - 若下订单失败，则抛出异常，由于是订单微服务异常仅回滚订单微服务的操作，库存微服务中所有详情单和工作单并不回滚。
    - 消费者【库存微服务】
      - 消费者得到消息首先判断是否存在该工作单，不存在，则表明下订单失败，必须回滚，解锁库存（应该是写错了，应该是保存工作单时失败，已经抛出异常，所以查询工作单不存在，已经回滚，不再需要回滚）
      - 或者工作单存在，则根据工作单上的订单sn请求订单微服务，获取订单详情，判断订单状态是否为订单取消状态或者新建转态，是，则消费者解锁。【只有在订单时取消状态时才能解锁库存，新建状态不可以解锁库存。这也是为什么，在解锁订单时，会再发一次消息给解锁库存延时队列】
      - 解锁则将商品的锁定数减少即可。【判断商品库存有两个字段`stock`和`stock_locked`订单锁定的库存，实际可自由操作的 库存是`stock-stock_locked`】
  - 关单延时队列

    - 生产者：下订单成功后将订单的相关信息发送到延时队列，过期向关闭队列发送消息，包含订单的相关信息。
    - 消费者：解锁解锁订单消息，将订单状态改为已取消

    - **为避免因为订单发送消息卡顿，导致库存消息先于订单消息过期（消费者收到消息，发现订单仍在新建状态，解锁库存时只有在订单在已取消时才解锁。库存消息被消费），在订单消息过期，进行解锁时，没有库存消息，从而无法实现解锁库存。（所以选择在订单解锁后，再发一个消息到库存解锁队列（不必进行验证，保证订单解锁先于库存解锁），进行解锁（即每次库存解锁会收到两个解锁消息，有一个成功即可））**
  - 你为什么要用两个延时队列呢？你只使用关单的延时队列，如果关单成功后，再解锁每个库存不是也可以吗？为什么还有再添加一个解锁库存的延时队列？

    - 因为我们锁定库存是每个购物项都锁定，并发送一条消息，如果说，ab两个购物项，a锁定成功了，b没锁定成功，则订单操作失败，并不会生成该关单的消息，但是库存锁定了。这个时候就需要有解锁库存的延时队列来保证最终一致性。

  - **消息队列中的消息有哪些？**
    - 关单消息队列：订单VO，包含订单Id，订单sn，所有购物项信息
    - 保存的工作单Id和详情单即每一个购物项为一个消息，包括，详情单Id，skuId以及锁定库存数量和工作单Id
  - 若是锁定ABC库存时，发现C没有库存，则抛出异常，订单微服务回滚。原本生成的订单回滚，此时ABC消息已经发出，

  

- **接口幂等性的处理：**（**保证幂等性，即请求1次与请求多次是相同的**）
  - **接口幂等性**：是用户对于同一操作发起的一次请求或者多次请求的结果是一致的
  - 注册用户使用短信，实现接口防刷
    - 虽然前端点击发送验证码，会显示倒计时60s，但是打开开发者工具，仍可以看到，点击发送验证码，会出现一个新的请求（携带这手机号等信息），避免一些恶意用户，通过此链接大量请求，消耗短信资源。）
    - 将生成的验证码信息保存在redis中。前端页面的60s，是避免重复发送验证码，而不是验证码的有效时间，验证码的有效时间我设置为20分钟。所以不能使用redis保存key时的过期时间，来解决这个问题。
    - 我们采用了逻辑过期的方式，即保存验证码的时候，把当前时间也保存上。key=手机号,value=验证码+“-”+当前系统时间。获取验证码时，判断是否存在该验证码，若没有或者时间超出60s，则可以获取新的验证码
  - 加入购物车操作，会转发到新的加入成功页面，刷新页面会出现重复加入购物车操作。
    - 进行**重定向**到加入成功页面，重新在后端服务器上获取刚才加入成功的商品信息。（转发不顶用，因为网址仍然是加入购物车的网址）
  - **提交订单，避免重复提交。**
    - 添加随机码，进入订单确认页时，会生成一个随机码，请求下订单时携带该随机码
    - 服务器保存了该随机码，若判断该随机码与用户的随机码相同，则验证成功，并删除该随机码，【必须是原子操作，lua脚本】。再后续的创建订单流程。
    - **避免了因为网络卡顿等原因，多次点击提交订单，导致生成多个订单的问题**



- **细节点**

  - **逻辑删除：**删除数据，逻辑删除。将状态位改为1

  - **上传云服务器**

    - 用户向服务器请求一个Policy，用户凭借此Policy向OSS发送数据，Policy封装了OSS保存的信息，安全，且省资源。

  - **统一异常处理：**构建一个类处理全局异常，减少重复代码

    - @ControllerAdvice（指定包的位置）+@ExceptionHandler修饰，处理全局异常。使用controller， advice用过AOP的方式进行处理异常。
    - 因为系统代码很多，逻辑也很多，可能出现的异常就很多。若只选择状态码4xx不足以表明详细的错误信息。 我们构建一个枚举类，选择了自己构建状态码和状态信息。前端会根据状态码，显示不同的错误信息。
      - 5位，前两位表示业务场景（通用错误信息，订单，商品，购物车），后3位表示错误码。
        - 参数格式校验异常

  - **全局统一返回：**

    - R为一个map，可以保存回显的数据信息data->data,
    - 也可以保存状态码，指定对应的message信息

  - **数据校验：**

    - 使用JSR303校验，但是请求校验，分不同场景，新增商品，不能携带商品Id，更新商品必须要携带Id，所以统一校验出现差池，选择分组校验。
    - 在entity类中添加：校验注解@NotNull（message），可以自己设置校验操作信息message
    - 开启分组校验，在controller层方法对应形参加上@Validated（value={}），需要指定要验证的分组

  - **VO的划分：**

    - entity主要是与数据库的映射关系，VO对应的是与前端的映射关系，
    - 原本的entitiy实体类对应数据库中的对象，但是数据库的信息映射并不一定与游览器显示一致，比如：前端获取用户信息，可能前端只需要用户头像地址，网名，至于密码，手机号，邮箱等信息无需返回，全部信息返回，这种做法并不规范，所以选择VO。

  - 你简历项目中都是用到了redis，说说你把什么数据放在redis中呢？

    - 将即时性，数据一致性要求不高的数据放在redis中。比如说验证码，已登录用户信息，还有秒杀商品信息
    - 访问量大且更新频率不高的 数据（读多，写少）

  - **redis作为数据缓存使用：**

    - 保证缓存与数据库的一致性
    - 防止缓存击穿，缓存雪崩，缓存穿透
      - 缓存击穿：redis中数据过期，查询数库时，加悲观锁（分布式情况下为分布式锁）。获取锁后，再次判断redis是否有数据，有数据直接返回，没有数据，访问数据库，保存到redis中后再释放锁，即使竞争到锁，也先在redis中再获取一次对象。而且先保存数据，再释放锁。
      - 缓存穿透：将null保存在redis中，设置短暂的过期时间
      - 缓存雪崩：设置过期时间时，加上一定的随机数

  - **短信验证码：接口防刷**

    - 注册用户时，虽然前端页面发送短信后，有60s倒计时，但打开游览器控制台，会发现添加了一个新的请求。若有恶意软件，通过这个请求，无限制访问后端，造成短信资源丢失。所以进行接口防刷
    - 验证码：有效期10分钟。1分钟后可以申请新的验证码
      - 在redis中存储验证码，设置过期时间为10分钟。value值为验证码与当时保存时间的拼接。【取出时，可以split拆分，并与当前系统时间对比】
      - 发送验证码请求，会先在redis中获取，比较设置时间，若超过1分钟，则可以申请新验证码，

  - 购物车：

    - 添加购物车：购物车数据都放在redis中，为保证一致性，redis开启了持久化。
    - 设置拦截器。（判断用户是否登录）
      - 若没登录，则为用户创建一个临时身份（与临时购物车有关），将用户身份保存在ThreadLocal中。
      - 临时身份在方法执行结束，postHandle方法中，为客户端添加cookie，设置过期时间为30天
    - 加入购物车操作，在用户登录后，会将临时购物车的数据合并到用户购物车，并将临时购物车删除。
    - 加入购物车成功后，到成功页面。【此时需要重定向】，因为成功页面刷新，可能还会进行加入购物车操作。所以只有重定向，一个全新的页面才会解决这个问题。【主要原因是，加入购物车请求，和加入成功请求是分开的才行】

  - 消息队列，rabbitMq

    - **如何避免消息丢失？**

      - 消息的丢失，在MQ角度考虑，一般有三种途径：
        1. 生产者确认发送到MQ服务器（生产者确认机制）
           1. ConfirmCallback  只确认消息是否正确到达 Exchange 中
           2. ReturnCallback   消息没有正确到达队列时触发回调，如果正确到达队列不执行
        2. MQ服务器不丢数据（消息持久化）
           1. **队列、Exchange，消息都持久化**
        3. 消费者确认消费掉消息（消费者确认机制）
           - 三种消息确认模式：（应答模式）
             1. 不确认模式：（消息队列不管程序是否异常，消息立马被消费）
             2. 自动确认模式：（**默认**：消费者没异常，才会自动确认，有异常，则不确认 ）
             3. 手动确认模式：（手动调用ack应答，目前使用的方式）
      - 生产者/消费者保证消息不丢失有两种方式：
        - 开启事务模式（事务模式会大幅降低消息发送已经接收频率，**使用少**）
        - 消息确认模式   （就是上面的消费者确认模式）

    - **面试题：避免消息堆积？**

      1）采用workqueue，多个消费者监听同一队列。   （增加消费者）

      2）接收到消息以后，而是通过线程池，异步消费。   （提高消费者消费能力）

  - **秒杀**

    - 首先定时上架，每天3点将近三天要秒杀的商品加入到redis中。
      - 【使用cron执行完成定时任务，spring开启定时任务】
      - @enableScheduling 开启定时管理
      - @enableScheduled（cron=” * * * *”） 开启一个定时任务
    - 访问商品详情页面时查询该商品是否是秒杀，若是显示秒杀信息
    - 商品上架
      - 使用定时提前将秒杀商品加入到redis中。需要使用分布式锁，避免重复保存秒杀活动。
      - 保存秒杀活动和秒杀商品到 redis
      - 每一种商品有一个随机码，秒杀该商品时，携带该随机码，避免抢单工具直接购买。只有在商品上架后才能获取该随机码。
      - 商品上架，需要设置信号量【同一时刻有多少进程可以访问该商品】，信号量即该秒杀商品的库存。可以避免超卖。
    - 购买
      - 校验随机码，时间，数量等信息
      - 判断是否购买过该商品，没有则可以购买，将用户信息保存到redis中
      - 生成订单号，对信号量进行扣除。避免超卖
      - 生成MQ通知订单服务生成订单，进行流量削峰
      - 也可以实现，抢购成功后，显示立即支付按钮，和5s后自动跳转页面，【流量错峰】
    
  - 进入商品详情页，获取spu的规格参数**==（最复杂的SQL语句）==**，传入spuId和categoryId
  
    - **首先根据categoryId，查询pms_attr_group表，查找到手机分类下所有的属性分组，主体，基本信息，屏幕，主芯片；**
  
    - **其次，根据分组查找分组下的所有属性，（通过pms_attr_attrgroup_relation分组属性关联表，找到对应的属性Id）**
  
    - **再而，根据属性的Id，查找对应的属性的名字和值，此时还需要使用spuId进行校对（每个SPU有其对应的属性信息，属性信息不是公共的），因为不同的spu，分组，属性可能相同，但是属性值不同。【因为分组内的属性并不全部符合该spu】**
  
      
  
    - **三表联合查询，**分为三张表，分组表，属性表，分组属性关系表【面试时可以说三表联合查询，实际是四表查询，基础表：分组表，联合表：分组属性关系表，属性表，商品属性详细信息表（会与spu关联，所以会有属性表和商品属性详细表）】
  
      - 分组表：主体，芯片，屏幕。以芯片为例：芯片也有品牌，规格等信息。一个分组对应多个属性，详细信息保存在属性
  
    - 查找当前三级分类所有的分组
  
      - **在分组表中进行查询，获取分组的详细信息**
  
    - 通过分组查找每一个分组下的所有属性
  
      - 根据分组查找在关系表中查找每一个分组对应的属性Id
      - 根据属性Id再查找到所有的属性详细信息

​					商品详情页也需要显示spu的所有信息，一些spu的信息，即sku的公共信息，如制作工艺，芯片，屏幕，机身长度等等；

- 异常信息

  - 订单
    - 订单验证失败
    - 验价失败
    - 锁库存失败

  - 登录
    - 用户名相同，手机号相同，用户名密码错误
    - 短信验证码频率过高，请稍后再试（接口防刷）








**重写方法**

- 获取三级分类
- 获取商品详情
- 购物车方法：
-  订单确认功能
- 下订单功能以及过期取消功能
- 秒杀功能





redis分布式锁的使用

```java
// 1.构造redisson实现分布式锁必要的Config
Config config = new Config();
config.useSingleServer().setAddress("redis://127.0.0.1:5379").setPassword("123456").setDatabase(0);
// 2.构造RedissonClient
RedissonClient redissonClient = Redisson.create(config);
// 3.获取锁对象实例（无法保证是按线程的顺序获取到）
RLock rLock = redissonClient.getLock("lockKey");
try {
    /**
     * 4.尝试获取锁
     * waitTimeout 尝试获取锁的最大等待时间，超过这个值，则认为获取锁失败
     * leaseTime   锁的持有时间,超过这个时间锁会自动失效（值应设置为大于业务处理的时间，确保在锁有效期内业务能处理完）
     */
    boolean res = rLock.tryLock((long)waitTimeout, (long)leaseTime, TimeUnit.SECONDS);
    if (res) {
        //成功获得锁，在这里处理业务
    }
} catch (Exception e) {
    throw new RuntimeException("aquire lock fail");
}finally{
    //无论如何, 最后都要解锁
    rLock.unlock();
}
```









# ==基础篇==

# 1，Spring-Cloud

## nacos-feign注册中心

spring-cloud-nacos作为注册中心，便于模块间的调用

spring-cloud-Feign实现远程调用

以member模块调用Coupon为例

- 导入包，注意与springboot的版本匹配

```
 <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-openfeign</artifactId>
        </dependency>
```

```xml
<dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>org.springframework.cloud</groupId>
                <artifactId>spring-cloud-dependencies</artifactId>
                <version>${spring-cloud.version}</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>
```

- member写一个feign接口方法

  - ```Java
    @FeignClient("mall-coupon")
    public interface CouponFeignService {
    
        @RequestMapping("/coupon/coupon/getCoupons")
        public R getCoupons();
    }
    ```
    
    - 方法中指定要调用coupon模块的application-name，并指定请求（对应coupon内部的controller方法）
  
- member启动类方法指定添加注解EnableFeignClients

  - 注解内并指定要feig包的全类名

  - ```Java
    @EnableFeignClients(basePackages = "com.example.mall.member.feign")
    @EnableDiscoveryClient
    @SpringBootApplication
    public class MallMemberApplication {
        public static void main(String[] args) {  SpringApplication.run(MallMemberApplication.class, args);
        }
    }
    ```

## nacos-config配置中心

配置中心统一配置信息

- 导入依赖

  - ```
    <dependency>
        <groupId>com.alibaba.cloud</groupId>
        <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
    </dependency>
    ```

- 创建一个bootstrap.properties

  - ```properties
    spring.application.name=mall-coupon
    spring.cloud.nacos.config.server-addr=127.0.0.1:8848
    ```

- 

- 在Nacos注册中心中，点击“配置列表”，添加配置规则：

![1587716911435](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/1587716911435-16488057174182.png)

- 需要在配置中心默认添加一个数据集，
  - 数据集 Data Id： 应用名.properties

- 动态获取所需得配置
  - @RefreshScope：动态获取并刷新配置
  - @Value("${配置项的名}")：获取到配置。
  - 如果配置中心和当前应用的配置文件中都配置了相同的项，**优先使用配置中心的配置**

## 配置中心参数

- 命名空间（实现配置隔离）
  隔离方式分为环境隔离和微服务隔离

  命名空间需指定：空间ID
  **本质上每个微服务都加载自己的配置空间，但是可以将多个微服务指向同一个命名空间**

  ```
  spring.cloud.nacos.config.namespace=55d3fb25-f8be-434b-a635-baf25b44c2a0
  ```

  - 环境隔离（开发，测试，生产环境来做隔离）
  - 微服务之间相互隔离，每一个微服务都创建自己的命名空间

- 配置集: 所有配置的集合

- 配置集ID：类似文件名
  Data ID：文件名

- 配置分组

  - 默认所有的配置都是在默认分组下

  - 可以自己设定分组，一个组下可以有多个命名空间

    - 修改“bootstrap.properties”配置，添加如下的配置


    ```properties
    spring.cloud.nacos.config.group=tmp
    ```


因此，配置信息nacos的使用

- 将原本的application.yml这种配置文件抽离出来，在nacos中配置
- nacos配置，将不同的微服务配置不同的配置文件，即一个微服务可以配置多个配置文件
- 微服务可以配置多个环境，分组

- 指定配置文件，分组，更新为refresh，不同的分组内，可能配置文件名是相同的
  - datasource.yml ：用于存储和数据源有关的配置
  - mybatis.yml：mybatis相关的配置
  - other.yml：其他配置文件
- 三个配置共同完成对一个微服务的配置，优先级高于application.properties

## 网关

客户端会先将请求发送到 API 网关，然后由 API 网关根据请求的标识信息将请求转发到微服务实例。类似于SpringMVC的dispatchServlet

# 2，商品服务

## 1）三级分类

### 1.获取所有的分类

将商品作为一级分类，二级分类，三级分类。一级（二级（三级（...）））,根据商品类型的getParentCid来判断，

- ParentCidId为0，一级，可以其他Id，则是它的子类

CategoryController：内部方法，获取一级分类，内部包含所有二级，二级包含三级...



categoryService 内部方法：

根据商品类型的getParentCid来判断

-  该方法为lamboa格式数据：
  - filter（）选择只要目标getParentCid
  - map中设置实体子集，调用buileTree，通过递归
  - sorted排序，选择将商品类型有设置级别，按设置的级别进行排序，要进行null判断，因为可能有空数据
  - collect将最终筛选的结果设置为list

删除数据时，采用逻辑删除，即将信息状态改为0,1。1表示已经删除，只能在数据库中，不能返回到页面







- **构建三级分类的方法**
  - **首先获取的所有的三级分类列表**
  - **filter只剩下一级分类，遍历该一级分类，将每个一级的对象进入buildTree方法，遍历三级分类对象列表，找到该一级分类下的二级分类**
  - **将二级分类的列表找到该下面的三级分类，  category表中，有parent_cid和id，和cat_level层级**



为避免缓存击穿，进行了加分布式锁，只允许一个线程去访问数据库



### 2，启动项目renren

启动后端项目renren-fast

启动前端项目renren-fast-vue：

- 可以在renren-fast-vue设置一个级别菜单，使其显示在该菜单中，需要在该目录下新建category.vue文件

- 设置方法请求，出错

  - 出错的原因是：vue的请求是基本地址+后续请求
  - 基本地址为在替换“static\config\index.js”文件中“window.SITE_CONFIG['baseUrl']”
  - 替换为http://localhost:88/api -->**基本请求到网关gateway，又网关进行转发到其他微服务，若是直接请求各个微服务，过于繁琐，需要每个指定不同的localhost全域名（端口，地址啥的都不同）**

- 所以的请求发送到网关，网关进行转发到其他微服务

  - renren-fast注册到nacos注册中心，

  - 并在gateway中添加路由规则

    ```yml
     - id: admin_route
              uri: lb://renren-fast
              predicates:
                - Path=/api/**
    ```

- 登录时，验证码出不来，原因是：

分析原因：

1. 现在的验证码请求路径为，http://localhost:88/api/captcha.jpg?uuid=69c79f02-d15b-478a-8465-a07fd09001e6
2. 原始的验证码请求路径：http://localhost:8001/renren-fast/captcha.jpg?uuid=69c79f02-d15b-478a-8465-a07fd09001e6

向renren-fast发送的请求需要重写，因为默认是只在加尾部添加请求

```yml
        - id: admin_route
          uri: lb://renren-fast
          predicates:
            - Path=/api/**
          filters:
            - RewritePath=/api/(?<segment>/?.*), /renren-fast/$\{segment}
```

- 验证码已经出现，但是无法登录

   问题描述：已拦截跨源请求：同源策略禁止读取位于 http://localhost:88/api/sys/login 的远程资源。（原因：CORS 头缺少 'Access-Control-Allow-Origin'）

  **跨域问题**

  以为将renren-fast加入到注册中心，所有的请求先请求网关，网关再进行转发，转发后localhost：8080端口号发生了改变。**因为请求的域名和端口与原来的请求不同，请求会被限制，gateway网关进行了限制**

  解决办法是：将gatemall请求使用filter，进行能够拦截，设置响应头，允许所有的网址请求

![image-20220402155710835](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220402155710835-16488862337914.png)

跨域流程：

![image-20220402155725390](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220402155725390-16488862484076.png)

![image-20220402155734804](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220402155734804.png)

![image-20220402155742960](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220402155742960-16488862639358.png)

## 2，品牌管理

### 15，删除数据

**逻辑删除：并不真正删除数据，而是将数据的显示状态改为-1**

mybatis-plus有这个方法，但是需要自己配置删除规则

- 在application.yml文件中添加内容

```
mybatis-plus:
  global-config:
    db-config:
      id-type: auto
      logic-delete-value: 1
      logic-not-delete-value: 0
```

- 默认是status=1为删除，status=0为显示，可以更改，在实体类中entity.CategoryEntity中，将状态属性，指定值value（显示状态为），delval（不显示状态）

  ```
  	/**
  	 * 是否显示[0-不显示，1显示]
  	 */
  	@TableLogic(value = "1",delval = "0")
  	private Integer showStatus;
  ```

- 调用删除方法

  - **deleteBatchIds**，而不是平时的removeByIds

### 16，添加上传

将数据上传到阿里云服务器进行存储，**使用对象存储**

创建Bucket-->上传文件-->通过accessKeyId和accessKeySecret

获取文件-->URL 地址   Bucket.阿里云设置的域名.文件名。



![image-20220403162910510](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220403162910510.png)

#### 对象存储流程

- 方式1：用户提交到服务器，服务器再提交到OSS云存储
  - 过于慢，浪费资源
- 方式2：用户直接提交到OSS云存储，需要服务器将id发送给客户，客户再提交
  - 会暴露OSS云存储的accessKeyId和accessKeySecret，**不安全**
- **方式3：**用户向服务器请求一个Policy，用户凭借此Policy向OSS发送数据，Policy封装了OSS保存的信息，安全，且省资源**（目前使用）**

SpringCloud Alibaba集成了此方式。

**流程**

1. 用户发送上传Policy请求到应用服务器。
2. 应用服务器返回上传Policy和签名给用户。
3. 用户直接上传数据到OSS。





#### 实现方式

**为降低耦合，因为很多微服务都需要上传和请求数据，所以我们将创建了一个微服务专门处理用户第三方的应用**

- 新建mall-third-party，导入相关依赖，在在nacos中注册，首先设置命名空间
- 设置相关的id和key

#### 上传组件问题：CORS跨域问题

```
Access to XMLHttpRequest at 'http://gulimall-images.oss-cn-shanghai.aliyuncs.com/' from origin 'http://localhost:8001' has been blocked by CORS policy: Response to preflight request doesn't pass access control check: No 'Access-Control-Allow-Origin' header is present on the requested resource.
```

需要在阿里云服务器开启跨域访问



### 18. JSR303校验

虽然前端已经进行了校验，但是后端也需要进行校验。前端为了提高体验，后端为了安全

- **使用校验注解**
  - 在实体类属性上添加注解，可以自己设置校验操作信息message

（1）@NotNull（message）

The annotated element must not be null. Accepts any type.
注解元素禁止为null，能够接收任何类型

（2）@NotEmpty

该注解修饰的字段不能为null或""

（3）@NotBlank

该注解不能为null，并且至少包含一个非空白字符。接收字符序列。

- **在controller层开启校验，添加注解@Valid**，

  - 没有该注解，则即使实体类添加了@NotNull也不会进行校验

- **在添加@Valid后面紧跟一个BindResult，可以获取校验结果**

  ```Java
  public R save(@Valid @RequestBody BrandEntity brand, BindingResult result)
  ```

**虽然上述已经处理了校验操作，但是为了降低耦合，可以单独写一个类来实现专门处理操作错误信息**

#### **==统一异常处理==**

在common微服务中，写一个类，专门处理异常

- springMVC提供了@ControllerAdvice注解，主要用于**结合@ExceptionHandler用于全局异常的处理**所以在微服务中的各种异常可以直接抛出，在common该类处理
- **在类内，@ExceptionHandler(value = Exception.class)，指定要处理的类，**将获取错误信息，并返回400+错误信息map
- 再添加一个默认异常处理，可以处理所有错误信息

#### 错误状态码

**错误状态码设置过于随意，然而正规开发过程中，错误状态码有着严格的定义规则**，为了定义这些错误状态码，我们可以单独定义一个常量类，用来存储这些错误状态码

- **在以后处理异常，统一调用该常量类中的错误验证码**

![image-20220403172322327](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220403172322327.png)

```Java
public enum BizCodeEnum {
    UNKNOW_EXEPTION(10000,"系统未知异常"),
    VAILD_EXCEPTION( 10001,"参数格式校验失败"),
    TO_MANY_REQUEST(10002,"请求流量过大，请稍后再试"),
    SMS_CODE_EXCEPTION( 10002,"短信验证码频率过高，请稍后再试"),
    PRODUCT_UP_EXCEPTION(11000,"商品上架异常"),

    USER_EXIST_EXCEPTION(15001,"存在相同的用户"),
    PHONE_EXIST_EXCEPTION(15002,"存在相同的手机号"),
    NO_STOCK_EXCEPTION(21000,"商品库存不足"),
    LOGINACCT_PASSWORD_EXCEPTION(15003,"账号或密码错误");
    
    private int code;
    private String msg;
}
```

#### 19，分组校验

虽然可以进行校验，但是很多时候是，更新操作，可能并没有携带一些数据，**即更新和添加数据的校验是不同的，需要引入分组校验**

- ```Java
  	@NotEmpty
  	@NotBlank(message = "品牌名必须非空",groups = {UpdateGroup.class,AddGroup.class})
  	private String name;
  ```

  - 若没有指定分组的校验属性不生效

- **开启分组校验，@Validated（value={}）**需要指定要验证的分组

- 默认情况下，在分组校验情况下，没有指定分组的校验注解，则不生效，只有在不分组的情况下才生效

#### 20，自定义校验

如显示状态码，只有0，1为合格，需要自定义校验规则，

- 编写一个自定义的校验注解@interface ListValue 
- 编写一个自定义的校验器-->ListValueConstraintValidator
- 自定义的校验注解指定校验器
- 在showStatus属性添加该注解，并使用

流程：

- 指定vals集合为合规的参数，传入校验注解，
- 校验注解通过校验器判断请求来的值是否符合规则

3，品牌属性

### 21，商品SPU和SKU管理

SPU：具体的一个类，比如说苹果13，里面有很多销售属性，比如说内存容量 8+128G，或者16+256G。还有蓝色，金色，黑色等。但也有相同属性:比如芯片，材质，屏幕大小，系统等信息。

SKU：具体到对象，苹果13： 16+256G 蓝色。

### 22，分类关联

都在   品管管理-->品牌关联(操作 品牌_类别关联表 )

- 一个品牌有多个类别，即华为有手机，电视等，需要加入相关的关联
- 更新一个品牌信息时，与之关联的信息都需要进行更改，（即更新品牌名，旗下的电视，手机品牌名都需要更改）
- 若我们更新级联信息，即上述的三级分类信息，（即我们把三级分类的手机改为手机平板，则该品牌关联中也需要更改）

### 23. 规格参数新增与VO

- PO：持久化对象，一个PO对应数据库中的一条数据
- DO：领域对象，抽取的一个概念，符合该概念的对象
- TO：数据传输对象，不同微服务之间的传输的对象
- DTO：数据传输对象，不同微服务之间的传输的对象
- VO：接收页面传递来的数据，封装为对象，将业务处理完成的对象，封装成页面要用的对象。（前后端交互的对象）



**VO：**原本的entitiy实体类对应数据库中的对象，但是数据库的信息映射并不一定与游览器显示一致，比如（三级分类，类型有一个childern，数据库中没有，但是页面需要显示层级关系，所以添加了一个）这种做法并不规范，所以选择VO

**VO：**接收页面传递来的数据，封装成对象，将业务处理完成的对象封装成页面要用的数据。。VO包含页面要的所有数据，数据库中的数据仅仅是其中一项（三级分类可以包含childern）

- 以后VO对象为实体对象所有属性，以及新添加的属性。
- 将VO对象赋值给新的实体对象， BeanUtils.copyProperties(attr,attrEntity);



页面规格参数需要catelogName，groupName，catelogPath，需要使用attr。

添加属性，和修改操作都需要涉及到相关的表，**由于不使用多表联合查询**，所以每个字段都单表查询，再进行匹配



属性表中有两种属性  规格属性（基本属性）和销售属性

规格属性时spu共同的属性，所以需要添加关联关系，与分组关联。

销售属性不必。保存属性时要进行区分。

- 规格属性时每个关系表都需要添加的
- 销售属性就在attr表中



- 查询指定分组关联的所有属性
- 在指定分组添加属性时，需要将为关联的属性列举出来



- 查询分组未关联的属性：需要该分组下所在类的所有属性，
  - 找到已经关联的属性
  - 再从所有属性中，移除已经关联的属性
  - 再判断是否有模糊查询，有，要再添加模糊查询的相关信息



# 4，新增商品

- 新增商品在选择分类后，选择品牌会获取到该分类category下的所有品牌，并显示以供选择。（方法中为方便复用，service依然选择搜寻所有的entity，并未只搜索品牌名称和id）

- 规格参数获取所有的attr-group，每个分组下有自己的属性配置

- 将商品的设置的所有信息，保存在数据库中，因为有不同规格，所以不同规格1*不同的规格2。。。就是商品的格式数量

  商品的保存需要保存的表

  ```Java
  //1,保存spu基本信息`pms_spu_info`
  
  //2，保存spu的描述信息`pms_spu_info_desc`
  
  //3，保存spu的图片集`pms_spu_images`
  
  //4，保存spu的规格参数 `pms_product_attr_value`
  
  //5、保存spu对应的所有sku信息
  
  //5.1）、sku的基本信息；pms_sku_info
  //5.2）、sku的图片信息；pms_sku_image
  //5.3）、sku的销售属性信息：pms_sku_sale_attr_value
  //5.4）、sku的优惠、满减等信息；跨库操作  gulimall_sms->sms_sku_ladder\sms_sku_full_reduction\sms_member_price
  ```

- 添加商品时，需要添加优惠劵等信息，所以需要添加到新的微服务coupon中。
  - 通过feign远程调用微服务
    1. 引入open-feign
    2. 编写一个接口，指定要调用的远程服务
    3. 声明接口的每一个方法，指定被哪个服务调用
- spu_id,需要在实体类中配置该主键不是自增主键，即保存的时候对主键也需要赋值操作,
  - 已经在实体类中设置，指定
    @TableId(type = IdType.INPUT)
- 对

# 5，仓库管理

- 采购单和采购需求的模糊查询功能：在service层创建wrapper，进行if判断，发送的key信息与数据表数据映射，添加eq，like等条件语句
- 将采购需要合并到采购单
  - 确认当前采购单是新建或者已分配状态（不指定，则视为新建）
  - 可以不指定采购单，自己创建一个新的采购单。
  - 可以指定采购单，创建传入mergeVO，判断purchaseId是否为空，为空则创建新的，并保存到数据库，并将获取采购单id
  - 合并采购需求，指定采购需求的，采购单号，并改变采购状态
  - 合并完，记得更新 订单的更新时间
- 领取采购单
  - 确认当前采购单是新建或者已分配状态
  - 更新采购单状态，和时间
  - 改变采购需求的状态
- 完成采购
  - 可以采购成功，修改状态
  - 采购不成功，加上原因
  - 请求内容为下列，创建了两个vo，一个为订单vo，一个是订单上每一个需求的vo，与前端对应
  - 流程
    - 改变采购项的状态
    - 根据采购项的状态，来改变采购单的状态
      - （只有有一个采购项不成功，则采购单失败）
    - 将成功采购的物品入库
      - 入库需要判断，是否已经有该库存，如果有，则增加库存，如果没有，则需要创建，并保存
      - 入库，还需要sku的名字
        - 远程调用feign

```
{
    id:5,
    items:[
        {itemId:9,status:3,reason:""},
        {itemId:10,status:4,reason:"无货"}]
}
```

- spu商品规格维护
  - 点击规格，会回显当前spu商品的各种设置
  - 可以进行更改并保存
    - 更改保存使用的是，先删除，后保存。（因为我们并不清楚到底用户更新 了那个属性，所以更新并删除反而使更高效的方法）

# 小结：

**1.  在open fen中会将调用的数据转换为JSON，接收方接收后，将JSON转换为对象，此时调用方和被调用方的处理JSON的对象不一定都是同一个类，只要它们的字段类型吻合即可。**

**基础篇**

- 应用
  - 微服务，注册中心，配置中心，Feign远程调用，
  - Feign远程调用
  - 网关 ：跨域问题
- 环境搭建
  -  Vagrant、Linux、Docker（MySQL、Redis）逆向工程&人人开源
- 开发规范
  - 数据校验JSR303
    - 在entity类中添加：校验注解@NotNull（message），可以自己设置校验操作信息message
    - 在controller类的方法中开启校验，添加注解@Valid
    - 也可分组校验，指定分组
      - 在实体类指定校验的group信息
      - 在controller层的方法添加注解@Validated（value={}）开启分组校验
  - 全局异常处理
    - 将所有的异常抛出，在Common微服务中：处理所有的异常信息，并记录再日志
    - 设置业务状态码，即返回异常的状态码，在一个枚举类中调用，避免状态码的混乱
    - 
  - 全局统一返回：
    - R为一个map，可以保存回显的数据信息data->data,
    - 也可以保存状态码，指定对应的message信息
  - 全局跨域问题
    - 使用gate网关，解决跨域问题
  - VO的划分：
    - entity主要是与数据库的映射关系，VO对应的是与前端的映射关系，
    - 前端传来VO对象数据，VO中包含一部分数据库的信息，在通过后端处理，保存到数据库
  - 逻辑删除：
    - 并未真正删除数据，而是将数据的显示状态改为不显示

# **==高级篇==**

# 1，ElasticSearch&Nginx

-  Index    对应MySQL的数据库
- Type   对应MySQL的表数据
- Document 对应MySQL的一个数据，文档是json格式。



正向代理：看服务器为谁服务，为客户端服务，则正向代理，比如科学上网；为后端服务，反向代理。

正向代理：对客户端已知，对服务端透明的代理应用，为正向代理（科学上网）

反向代理：对服务端已知，对客户端透明的代理应用，为反向代理，nginx

**Nginx**

Nginx使用反向代理：所有的请求，都请求到ngnix，通过反向代理，访问后端服务器集群，再实现负载均衡。

**Nginx+windows构建域名访问环境原理：**

- Windows游览器访问：gulimail.com 。Windows配置了host文件，指定了虚拟机的ip地址，又由于请求IP默认访问端口为80。
- 所以会请求到虚拟机，虚拟机配置了Nginx，监听80端口，所以请求到了Nginx。
- 在Nginx配置了文件，将请求来的地址，直接代理给网关。
  - Nginx转发给网关需要手动设置host请求头，因为Nginx自动丢掉。
- 网关直接转到Windows主机电脑的IP地址和端口【因为服务器在Windows的idea上运行】



![image-20220528131306180](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220528131306180.png)



# 1，商品上架

（很繁杂的方法）在spuInfoService.up方法，传入spuId。在类的所有商品上架

1. 通过spu查找sku_Info表到所有的sku的信息，品牌等.
2. 根据所有的sku，保存所有的skuIds，请求库存微服务，查看每一个sku是否有库存，将结果封装为map
   1. 远程调用ware微服务，为避免封装每个sku都要远程调用，将所有的sku，放在一个请求中，以一个map形式返回。
   2. 若map为null，可能是远程出现颠簸未请求到数据，设为默认有库存
      - ware方法中，需要将找到所有的库存，需要是：（库存-锁定）的总和

3. **查询spu属性表，查找到spu的所有属性，但所有属性并不一定都是可以作为查询条件的，需要进行过滤，比如说【入网型号，制作工艺不能作为搜索条件】，这些spu的属性是所有sku共享的属性。所以需要查询attr表。查看字段search_type。**  最终找到可以作为搜索条件的spu的属性，所有sku共享。比如说，CPU品牌，型号
4. 遍历1中查到的skuinfo信息，并保存到skuESModel方法



- 封装所有的sku信息，将信息封装为进入EsSearch中的所有skuEsModel格式。

  - 需要sku的基本信息，进行属性赋值

- 远程调用：search，进行保存到es中。**key为product**，kibana中可以查找

  ```
  GET product/_search
  ```

  - 上架保存到es中时，为避免重复上架，所以设置一个id，当前id下，的上架，重复上架是更新，不会出现上架多个

- 若保存成功，则将spu的商品状态改为上架

  - sku的基本信息，进行赋值
  - sku是否有库存




- ## 商品上架

- 通过传入的spuId，将该类下的所有商品上架。
- 通过spu，查找到所有的sku
- feign调用mall-ware微服务，远程请求所有的skuId查看是否有库存
- 通过spuid查找到所有的属性id，再通过属性id找到所有可以作为**搜索条件**的属性值【属性表里面有该字段】
- 查询spu中所有sku的相关数据
  - sku的基础信息，价钱，描述等信息
  - sku是否有库存
  - SKU对应的 品牌名字以及logo，和三级分类的名字
  - sku的属性值
- 添加到ES中。以对应skuid为key，避免重复添加
- 更改spu_info 数据表中的对应的spu状态，改为已上架



**feign调用：**原理

1. 构造请求数据，将对象转为JSON
   RequestTemplate template = buildTemplateFromArgs.create(argv);

2. 发送请求进行执行，（转换成http请求，执行成功后会解析响应数据）
   executeAndDecode(template)

3. 执行重试机制【使用重试器进行重试】

   ```
   while（true）{
   	try{
   		// 远程请求
   		executeAndDecode(template)
   	}catch{
   		try{
   			// 若请求失败后，执行该方法，使用重试器，若重试次数超过指定次数，该方法也会抛异常，会进行该catch，然后再抛出异常
   		   retryer.continueOrPropagate(e)
   		}catch{
   			throw e;
   		}	
   	}
   }
   ```

   





# 1.5 压力测试

- 为什么进行压力测试？
  - 考察当前元硬件系统所能承受的最大负荷，并找出系统瓶颈所在。最后起到优化系统的目的。
  - 另外，通过压力测试，可能找到其他方法很难发现的错误，例如：**内存泄露，并发与同步。**
- **性能指标**
  - HPS：每秒点击数，（用处不大）
  - TPS：每秒处理交易数，即请求一个网址的所有信息。 单位是 笔/秒
  - **QPS**：每秒处理查询次数，单位是次/秒
  - 区别：
    - 若某些业务有且只有一个请求连接，那TPS=QPS=HPS，**TPS表示请求该网页中所有的接口的请求，QPS来表示controller层一个接口的查询次数。**
  - **响应时间**：服务处理一个请求或任务的耗时
  - **90%响应时间**：所有用户的响应时间进行排序，第 90%的响应时间。
  - **错误率**：一批请求中出现错误请求所占比例。
- JMeter：**测试工具**，步骤：
  1. 添加线程组
  2. 添加Http请求
  3. 添加监听器
- **jconsole**: 查询内存占用情况   （读音：jei  康嗖）
  - 监控内存泄露，跟踪垃圾回收，执行时内存、cpu 分析，线程分析
- 根据压力测试，进行性能优化（与下面图片对应）
  - 直接请求Nginx，和gateway，只请求地址，由于是CPU密集型，只进行转发，性能很高。
  - 简单服务：springboot 设置hello， 直接请求该hello的controller。
  - Gateway+简单服务：通过网关，再转发到服务器
  - 全链路：用户请求到Nginx，再转发到网关，再转发到服务器
  - 后续的首页等请求都是：直接压自己，并没有通过网关和Nginx（主要是反应问题）
    - 全量数据：直接请求页面，将页面所有数据（从后端获取的请求和静态资源，如果有图片，还有从云服务器获取的数据）

响应时间单位：ms

![image-20220528150946891](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220528150946891.png)



- **优化：**

  - 中间件

  - **中间件越多，性能损失越大，主要损失在网络交互**，可以使用更高级的网络协议，更换更高性能的网卡

  - **业务层面**   最终TPS： 1300-->2300 
    - 开启数据库索引
    
    - 开启thymeleaf缓存
    
    - 降低日志数据级别，由默认的info级别改为error级别。
      - spring日志级别：trace，debug，info，warn，error
    - 动静分离（动态请求：到springMVC映射的请求，静态请求，即相同的请求）
      - 将静态资源放在Ngnix服务器上，静态请求直接在Nginx服务器上获取，不必再转发到后端服务器。提高吞吐量，减少后端服务器压力
      - 
    - 使用 redis缓存
    
  - jvm调优：
    - 增大服务内存占用，会增加内存空间，减少GC次数（无论是老年代GC还是新生代GC都会减少），提高吞吐量
    - 指定堆内存最大 ：-Xmx1024m
    - 指定堆内存初始大小：-Xms1024m     （与最大堆内存相同，则表示堆内存就是1024m，不必在运行时申请内存，影响性能）
    - 指定新生代大小：-Xmn512m   （因为测试请求，大量的请求进来会创建需要临时对象）
    - NewRatio，默认值：2，也就是说新生代和老年代的默认比值是 1：2。





# 2，商城业务

## 首页三级分类

此次为不是使用renrenfast页面，而是使用html实现三级分类

- 首先获取1级分类（父类ld为0）
- 再从分类id为1级分类中找到对应的二级分类
- 再从二级分类中找到3级分类

# 3,缓存Redis

引入redis 。在properties中配置：指定地址和端口，可以直接导入redisTemplate

引入redisSon：在properties中配置，写端口和地址  所有对Redisson的使用都是通过RedissonClient。**RedissonClient可以实现分布式锁**

## 缓存三级分类

- 请求三级分类数据，首先请求redis，若redis没有再从数据库中查找，并保存到数据库中，提高了吞吐量
- redis中的数据都保存为String ，value对象的String类型是通过JSON格式的字符串。方便转换，另外所有框架中通用，而不仅限于Java
- **高并发情况下，会产生产生堆外内存溢出**
  - Spring-boot底层，可以使用lettuce客户端和jedis作为redis的底层客户端，Spring都封装为redisTemplate
  - springboot2.0以后默认使用lettuce操作redis的客户端
  - lettuce的bug导致netty堆外内存溢出
    - 可设置：-Dio.netty.maxDirectMemory，设置netty的最大堆外内存空间来缓解这种情况，并不能解决问题
    - 解决方法
      - lettuce客户端。
      - 切换使用jedis（很久不更新了）

## 高并发下的缓存失效问题

- **缓存穿透**

  - 查询一个一定不存在的数据，由于缓存不命中，则去数据库中查询，数据库也没有，则会每次这种请求都获取到数据库中查询。

  - 风险：

    利用不存在的数据进行攻击，数据库瞬时压力增大，最终导致崩溃

  - 解决：

    null结果缓存，并加入短暂过期时间

- **缓存雪崩**

  - 我们在Redis设置的key采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时 压力过重雪崩。

  - 解决：

    原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这 样每一个缓存的过期时间的重复率就会降低，就很难引发集体 失效的事件。

- **缓存击穿**

  - 某个key为热点数据，在某一时刻失效，在失效时，刚好有大量请求，则所有的key的查询都落在数据库中

  - 解决：

    加锁

    大量并发只让一个去查，其他人等待，查到以后释放锁，其他 人获取到锁，先查缓存，就会有数据，不用去db



## 缓存穿透的细节问题

在查询数据库时加锁。但多并发情况下仍有可能会出现时序问题

- 多个线程获取锁，此时已经判断缓存为空。一个线程执行完后，其实已经将数据放在缓存中。
  - 在获取锁进行代码段后，需要再次查询缓存
- 再次查询缓存没有，则查询数据库，查询结束后，返回，然后保存在缓存中。可能保存缓慢，锁对象已经释放，另外的线程查询缓存还为空，则继续查询数据库
  - 需要保证加锁的操作为原子操作。
  - 加锁内：**（不能在方法结束后，此时再将方法返回值加入redis，就晚了，3,4部不能颠倒）**
    1. 先确认缓存是否有
    2. 查询数据库
    3. 保存在缓存中
    4. 方法结束

## 分布式锁

普通加锁的情况，分布式情况下失效

- 分布式：多个服务器运行相同的程序共同操作同一个数据库，也就是说，多个相同的程序，会有多个相同的锁对象（即使是单实例），**所以查询数据要加分布式锁**，更改数据要加数据库的行锁。

![image-20220409095829807](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220409095829807.png)



**获取分布式锁：**

**阶段一**

- 可以在redis中设置一个值，代表锁 setnx（key，value）   setIfAbsent（）

  - 若不存在key，则设置成功，返回true，
    - 执行业务，执行完毕
    - 删锁，退出
  - 存在，则设置失败，返回false。

- 根据执行返回值，进行判断是否抢占锁成功。**未成功可以进行锁自旋**

- 问题：

  - 若抢占成功，执行业务，但出现异常，并未对锁进行释放，或者说删除该key，造成了死锁

- 解决：

  **设置锁的自动过期，即使没有删除，会自动删除**

**阶段二**

- 设置锁的过期时间。

- 问题：
  若设置过期时间过程中出现异常，则又出现死锁

- 解决
  **设置过期时间和占位必须是原子的（一块执行）**，redis支持使用setnx ex

    setIfAbsent（）传入时间

**阶段三**（最终版）

可以使用redisSon，已经封装好的jar包

- 删除锁问题
  由于业务执行时间过长，则锁过期，其他线程获取锁执行业务，在当前线程执行完，删除了其他线程的锁
- 解决：
  - 业务执行时间过长导致锁过期，设置看门狗，只有还占有锁，则进行自动续期
  - 抢占锁时，值指定为UUID，删除时，只有与自己的抢占的一致才能进行删除锁操作，这个判断并删除的操作也得是原子操作。
  - **删除锁必须保证原子性。使用redis+Lua脚本完成**

![image-20220409110055568](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220409110055568.png)

## 缓存一致性问题

**首先一定是先更新库再更新缓存，不能先更新缓存再更新库，这样做，数据不一致的时间更久**

即更新数据库中的数据，缓存中的数据与数据库中的数据不一致

两个模式

- 双写模式
  - **更新完数据库中的数据，再查询一次，更新到缓存**
  - 问题：
    并发情况下，由于卡顿，出现了写入不一致问题
    ![image-20220409163623350](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220409163623350.png)
  - 解决办法：
    - 1，加锁:只有在完成写入数据库和写入缓存后，才释放锁**（读写锁）**
    - 2，添加过期时间：
      添加过期时间后，这种脏数据仅仅是暂时的，缓存过期以后，又会得到正确的数据。
- 失效模式
  - **更新完数据库中的数据，删除缓存的数据，等待下一次查询，再放入到数据库**
  - ![image-20220409174531012](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220409174531012.png)
  - 解决方法
    - 加锁，
    - 这种数据更新如此频繁，我们可以考虑不加入缓存



**无论是双写模式还是失效模式，都会导致缓存的不一致问题。即多个实例同时更新会出事。怎么办？**

•1、如果是用户纬度数据（订单数据、用户数据），这种并发几率非常小，不用考虑这个问题，缓存数据加 上过期时间，每隔一段时间触发读的主动更新即可

•2、如果是菜单，商品介绍等基础数据，也可以去使用canal订阅binlog的方式。

•3、缓存数据+过期时间也足够解决大部分业务对于缓存的要求。

•4、通过加锁保证并发读写，写写的时候按顺序排好队。读读无所谓。所以适合使用读写锁。（业务不关心 脏数据，允许临时脏数据可忽略）；



**总结**

•我们能放入缓存的数据本就不应该是实时性、一致性要求超高的。所以缓存数据的时候加上过期时间，保证每天拿到当前最新数据即可。

•我们不应该过度设计，增加系统的复杂性

•遇到实时性、一致性要求高的数据，就应该查数据库，即使慢点。

**最终解决方案**

- **缓存的所有数据都设置过期时间，数据过期后下次查询触发主动更新**
- **读写数据的时候，加上分布式的读写锁**





使用SpringCache来控制redis执行缓存步骤

**SpringCache：简化缓存开发：类似中间件，可以选择不同缓存器，通过springCache进行控制，主要是为了统一不同的缓存技术**

![image-20220409195210864](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220409195210864.png)

![image-20220409195215912](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220409195215912.png)

- 使用：引用spring-cache 的jar包
  - 在main中添加注解@EnableCaching
  - 指定cache使用的类型
  - 在需要加入缓存的方法加入注解@Cacheable({"category"})，给方法的返回值会加入到缓存。（可以指定区，类似分库操作）
- 默认：
  - 在加入到缓存后，再次访问该方法只会在缓存中获取，不再执行该方法
  - key默认自动生成            @Cacheable可以指定key
  - 默认缓存时间为-1.     在配置文件中指定 redis.time-to-live
  - 缓存的value为jdk格式。   创建配置文件，指定redis的配置格式为JSON
- @Cacheable(value = {"category"},key = "#root.method.name")
  - 加入缓存，指定分区为category，key为方法名
- @CacheEvict(value = "category",allEntries = true)
  - 更新数据后，将分区内的数据全部清除



# 4，检索服务

在search微服务中设置ngnix。gulimall.com的请求服务会通过ngnix转到search.gulimall.com。通过ngnix转发到了search微服务

- 将所有的搜索条件封装到一个VO实体中，方便封装的同时，方便获取
- 生成DSL语言，获取Es的数据

前端根据用户输入的查询、过滤、排序、分页条件等，后台生成DSL，查询出最终结果响应给前端，渲染页面展示给用户。

流程

- 准备检索请求
- 执行查询
- 将结果封装为页面需要的对象返回



- 准备检索请求：生成一个完整的DSL语言，来在es上进行查询
  - search?keyword=小米&brandId=1,3&cid=225&props=5:高通-麒麟&props=6:骁龙865-硅谷1000&sort=1&priceFrom=1000&priceTo=6000&pageNum=1&hasStore=true
  - **创建一个SearchParam参数对象，将请求来的所有参数封装到该对象中**
  - 
    1. 是否有模糊查询
    2. 三级分类查询
    3. 品牌查询，即按品牌Id查询
    4. 按指定属性查询，属性可能是多个，另外需要对请求来的数据进行拆分
    5. 按有无库存查询
    6. 按价格区间查询
    7. 排序，分页，高亮
    8. **聚合**：列出上述符合条件的所有分类
       1. 品牌分类
          1. 获取品牌名字和图片
       2. 三级分类的分类
          1. 获取三级分类的名称
       3. 属性分类
          1. 获取属性的名称和id
- 将结果封装为页面需要的对象返回：
- 查询到的结果，重新封装为一个VO的容器中
  - 查询的所有商品
  - 所有关键字，并显示高亮
  - 当前商品涉及到的所有属性信息
    - 属性Id，name，值
  - 当前商品涉及到的所有分类信息
    - 类Id，名字
  - 当前商品涉及到的所有品牌信息
    - 品牌Id，品牌名字，品牌图片
  - 页码，总数等信息

# 5，异步 线程池（商品详情）

## 线程池

- 初始化线程的四种方式
  - 继承Thread
  - 实现Runnable
  - 实现Callable接口+FutureTask（可以拿到返回结果，可以处理异常）
  - 线程池

线程池的优点：

- 控制资源，性能稳定



## **CompletableFuture**：异步编排

### 为什么使用异步编排？

- 将两个异步计算之间相互独立，同时第二个又依赖于第一个的结果。此时需要异步编排。（若是结果不相互依赖，直接异步即可，没必要异步编排）
- 查询商品详情页的逻辑复杂，有些数据需要远程调用。必然花费更多时间。可以使用线程池，异步获取数据，进行编排提高响应速度。
- 例如：进入商品详情页（携带skuId）
  1. 获取SKu的基本信息    异步1
  2. 获取SKU的图片信息    异步1
  3. 获取SKU的促销信息     异步1
  4. 获取spu的所有销售属性   需要等待查询到（获取SKu的基本信息中的spuId）才能获取spuId     异步2
  5. 获取规格参数  异步2
  6. 获取spu详情    异步2
- 原本需要等待6个请求时间累加，变为两次异步操作的时间，极大的提高了响应时间。





jdk1.8，添加了CompletableFuture，进行异步编排。

将两个异步计算之间相互独立，同时第二个又依赖于第一个的结果。此时需要异步编排。

- ### 创建异步对象

  - 没返回值runAsync

    ```Java
            ExecutorService executor = newFixedThreadPool(10);
            CompletableFuture<Void> future = CompletableFuture.runAsync(() -> {
                System.out.println(Thread.currentThread().getId());
            }, executor);
    ```

  - 有返回值supplyAsync

    ```Java
    CompletableFuture<Long> future = CompletableFuture.supplyAsync(() -> {
                long id = Thread.currentThread().getId();
                System.out.println(id);
                return id;
            }, executor);
            Long aLong = future.get();
    ```

- ### 线程执行完成的回调方法

  - whenComplete(BiConsumer<? super T,? super Throwable> action);
    - 在线程执行完成后，将返回值和异常，进行操作，T为线程执行结果，action为异常信息。
  - exceptionally(Function<Throwable,? extends T> fn);
    - 线程出现异常，优先进入该方法，可以设置返回值，使得即使异常也会有返回值
  - whenComplete与exceptionally一块执行，若出现异常，先执行exceptionally，再执行whenComplete

whenComplete 和 whenCompleteAsync 的区别：
		whenComplete：是执行当前任务的线程执行继续执行 whenComplete 的任务。
		whenCompleteAsync：是执行把 whenCompleteAsync 这个任务继续提交给线程池来进行执行。

- ###  线程串行化方法

  ​	（即一个线程执行结束，再执行下一个线程）

  - thenRun，thenRunAsync方法：上一个线程结束，执行thenRun，不能获取上一个线程的结果，也不能有返回值
  - thenAccept，thenAcceptAsync：能获取上一个线程的结果进行操作，但不能有返回值
  - thenApply，thenApplyAsync：能获取上一个任务的结果，并返回当前值

```Java
        ExecutorService executor = newFixedThreadPool(10);
        CompletableFuture<Long> future = CompletableFuture.supplyAsync(() -> {
            long id = Thread.currentThread().getId();
            System.out.println(id);
            return id;
        }, executor).thenApplyAsync(res->{
            return res*2;
        },executor);
        Long aLong = future.get();
        System.out.println(aLong);
```

- ### 多任务组合

  - allOf：等待所有任务完成

  - anyOf：只要有一个任务完成。返回值调用anyof方法，可以获取率先执行结束线程的结果

    ```Java
    public static CompletableFuture<Void> allOf(CompletableFuture<?>... cfs);
    
    public static CompletableFuture<Object> anyOf(CompletableFuture<?>... cfs);
    ```

  - 注意：**这两个方法调用，要使用get();**,否则在anyof中不能，达到any的目的
    

    ```Java
            CompletableFuture<Void> all = CompletableFuture.allOf(future1, future2, future3);
            all.get();
    ```
  
  - 未知任务个数时，传入集合
  
    ```java
    CompletableFuture.allOf(futures.toArray(new CompletableFuture[0]));
    ```
  
    

## 商品详情

请求为skuId，返回的页面是，携带有spu完整信息的页面

创建一个商品详细的VO：包括下述信息

请求页面携带skuId

- sku基本信息获取（skuid->sku_info）
  - 返回一个skuinfo实体【spuId，标题，子标题，图片等信息】
  
- sku的图片信息 (skuid->sku_images)
  - 返回一个List，包含各种图片的地址
  
- spu下所有的sku销售属性组合==**（较为复杂的SQL语句）**==   即内存，颜色等信息，【通过获取的skuInfo实体，请求所属spu下的所有销售属性，即对应当前spu下所有的sku】
  - 返回一个list，包含多个销售属性Vo  
    - 销售属性Vo，包含属性Id，属性名字（内存，颜色），属性值：（具体的属性：256GB，64GB）
    - 为了能选择方框，可以进行切换sku，还包含了符合该销售属性所有skuId。
      在请求时，对已经选好的销售属性，进行匹配，得出唯一的sku
      - 颜色：黑色  （skuIds：1，3，5）只有1，3，5有黑色属性
      - 内存：256GB（skuIds:2,4,5）
      - 在请求时，会进行匹配选择两个销售属性都包含的skuId 5，
    
  - SQL查找，找到该spu下的所有销售属性，并进行封装
    1. 根据spuId查找所有的sku，（找到隶属于该spu的所有sku）  【先查询 pms_sku_info表，根据spuId，查找所有的skuId】
    
    2. 找到每一个sku的销售属性，每一个sku的销售属性不一定相同，【连接查询pms_sku_sale_attr_value，skuId相等】
    
    3. 进行分组，整合。**列出有符合该销售属性的所有skuid**，因此前端可以进行验证，在选择颜色属性后，只能选择有该颜色属性的版本sku
    
       -------  ---------  ----------  ---------
            attr_id  attr_name  attr_value  sku_ids  
           -------  ---------  ----------  ---------
                 9  颜色         亮黑色         3,4      
                 9  颜色         星河银         1,2      
                 9  颜色         罗兰紫         7,8      
                 9  颜色         翡冷翠         5,6      
                12  版本         8GB+128GB   2,4,6,8  
                12  版本         8GB+256GB   1,3,5,7
  
- 获取spu的介绍
  - 返回一个spu的统一信息，即该spu类的详细介绍    各种宣传图片，可以理解为
    - 华为Mate40 的统一信息
    - sku为华为Mate40，内存，颜色等不同的具体信息
  
- 获取spu的规格参数**==（最复杂的SQL语句）==**，传入spuId和categoryId
  
  - 首先根据categoryId，查询pms_attr_group表，查找到手机分类下所有的属性分组，主体，基本信息，屏幕，主芯片；  
  
  - 其次，根据分组查找分组下的所有属性，（通过pms_attr_attrgroup_relation分组属性关联表，找到对应的属性Id）
  
  - 再而，根据属性的Id，查找对应的属性的名字和值，此时还需要使用spuId，因为不同的spu，分组，属性可能相同，但是属性值不同。【因为分组内的属性并不全部符合该spu】
  
    
  
  - **三表联合查询，**分为三张表，分组表，属性表，分组属性关系表【面试时可以说三表联合查询，实际是四表查询，基础表：分组表，联合表：分组属性关系表，属性表，商品属性详细信息表（会与spu关联，所以会有属性表和商品属性详细表）】
    
    - 分组表：主体，芯片，屏幕。以芯片为例：芯片也有品牌，规格等信息。一个分组对应多个属性，详细信息保存在属性
    
  - 查找当前三级分类所有的分组
    - **在分组表中进行查询，获取分组的详细信息**
  
  - 通过分组查找每一个分组下的所有属性
    - 根据分组查找在关系表中查找每一个分组对应的属性Id
    - 根据属性Id再查找到所有的属性详细信息
  

商品详情页也需要显示spu的所有信息，一些spu的信息，即sku的公共信息，如制作工艺，芯片，屏幕，机身长度等等；



- ### 将自定义信息，properties配置

- 可以将一些自定义的配置信息加载到properties中，最终可以在nacos配置中心中配置

- 以线程池配置为例

  - 创建一个类和核心线程数，最大线程数，存活时间等属性，加载到容器中@Component，设置get，set方法。
  - 该类加上注解@ConfigurationProperties(prefix = "gulimall.thread")
  - 可以在application.properties中直接配置相关信息  gulimall.thread.xxx=100



- ### 异步串行化

  多线程加载信息，返回给客户端，提高响应速度

- 配置线程池：写一个配置类，有一个方法@Bean修饰，返回ThreadPoolExecutor

  - 则所有的多线程操作可以在线程池下获取线程

- 将其他线程不使用的数据，多线程执行，实现异步编排，确定顺序
  1. 获取sku的基本信息（1个线程）supplyAsync：异步执行需要返回值，给下属任务
     - sku的销售属性（在1之后，需要sku信息），
     - sku的销售属性组合（在1之后，需要sku信息）
     - 获取spu的介绍（在1之后，需要sku信息）
  2. sku的图片信息（1个线程），不用返回值

- 调用allof方法，等待5个线程执行全部结束后，返回结果

# 6，认证服务（登录注册）

- ### 短信发送验证码服务：

  - 引入包和httpUtil，购买阿里云市场的短信服务，需要指定method和appcode
  - 将可能会变化的服务改为在application.properties中配置
  - 指定手机号与code代码即可

- 短信发送业务在mall-third-party微服务中，需要mall-auth-server使用feign远程调用。实现发送短信服务

- 将验证码的信息保存在redis中，短暂保存，进行验证

- ### 验证码安全问题

- **接口防刷：**
  
  - 在页面端，可以发现请求验证码的地址：http://xxx?phone=138...。恶意用户可能按此网址进行频繁发送，消耗短信资源，所以需要接口防刷
  
- 验证码的验证
  - 保存逻辑过期

  - 在redis保存的验证码，包含填入验证码时的系统时间。请求获取验证码时，对获取原来时间与当前时间对比，若低于60s，则不允许重新获取验证码
  



- ### **避免重复提交：**

**使用重定向到其他页面，避免重复提交。如果需要携带数据，使用RedirectAttributes（与Model）类似，可以自动注入，重定向时携带。**

**RedirectAttributes**: 模拟重定向携带数据，利用session原理。将数据放在session中，只要跳到下一个取出数据后，session里面的数据会删除

- ### 加密流程

- 注册页面需要验证用户名和有手机号没有被他人注册过，所以需要进行验证
  - 验证流程为：如果发现该手机号已经注册过，则**抛异常**，仅使用一种新的方式来判断，
  - 方法内抛出，在controller层进行统一处理
- 密码MD5加盐
  - MD5加密：
    - 不可逆
    -  抗修改性：对原数据进行任何改动，哪怕只修改1个字节，所得到的MD5值都有很大区别
    -  强抗碰撞：想找到两个不同的数据，使它们具有相同的MD5值，是非常困难的
    -  压缩性：任意长度的数据，算出的MD5值长度都是固定的。
    - 容易计算：从原数据计算出MD5值很容易。
  - 缺点：确实不能逆运算算出来，但是可以通过彩虹表，暴力算出，即彩虹表中有所有的MDK5加密前后的键值对。
  - 加盐：
    - 通过生成随机数与MD5生成字符串进行组合
  - **实现**：
    - 使用spring的加盐工具，每次的加盐后的代码是不一样的，但是可以使用方法进行验证，将加盐后的代码和明文进行匹配

- ### 登录

- 登录，验证密码等信息，

  - 社交登录：使用社交登录，通过登录微博，来实现登录该网站
  - 登录判断，若是已登录，则不用再进入登录页面。
    - 在redis中获取对象来判断是否已经登录



- ### Session同步方案

- 登录请求域用户微服务有关，登录后，会转到mall-product服务中，但是原本在member的session不能使用，即获取的登录信息无法传输到mall-product服务中。因为所有的数据都保存在session中，普通的session不能跨服务。或者分布式，一个微服务布置在多台服务器上，

  - 构建tomcat集群（占用网络带宽，而且过多占用内存）

  - hash一致性：将IP进行hash操作，指定当前IP下请求的微服务


- 解决方案：（使用springSession来完成下述功能）

  - **session的保存**
    - 统一存储，即将用户信息存储在redis中。每次访问微服务，在redis中获取。
  - session的范围**（访问其他微服务，原本的jsessionId失效，因为访问了不同域名，即不同服务，子域）**
    -  **cookie的作用域是请求路径本身以及它的所有子域名。**
    - 扩大cookie的作用域：指定为统一的gulimall.com。
    -  **解释**：
       -  redis保存所有session。但是cookie也有作用域。即登录页面的cookie，在请求商品微服务时，不能携带。
       -  父域名： gulimall.com    ，子域名： auth.gulimall.com
       -  在mall-auth-server微服务中，写了配置类。扩大了登录cookie的作用域。指定名称和作用域。

- ### SpringSession核心原理

  - 在main类加上@EnableRedisHttpSession注解，导入配置
  - 在容器中添加组件sessionRepository-->通过redis操作session，增删改查
  - 设置过滤器filter，
    - 将原本的request和response进行包装。
    - 并重写了getSession方法。将原本从currentMap获取session的操作【默认tomcat保存的session信息到currentMap中】，改为从sessionRepository中获取。已经在配置文件中配置。
  - **使用了装饰者模式**

- 客户端请求某个html页面

  - 因为不是静态页面，所以需要通过controller，需要在controller层写一个空方法

  - 可以选择写如下配置

    ```Java
    @Configuration
    public class mallWebConfig implements WebMvcConfigurer {
    
        @Override
        public void addViewControllers(ViewControllerRegistry registry) {
    
            registry.addViewController("/login.html").setViewName("login");
            registry.addViewController("/reg.html").setViewName("reg");
        }
    }
    ```

- ### 单点登录（SSO）

  - 简介：springSession：可以解决在一个商城系统中，登录后，访问该系统下，所有微服务的应用都已经登录。
    - 但是一个软件可能包含多个系统。订单系统，库存系统，商户系统。。。这些跨系统，并不能使用session来进行访问。
    - SSO是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。
    - 流程：有一个中央认证服务器，ssoserver.com，其他系统登录在该域名登录，登录后跳转回来
  - 步骤：
    - 设置一个登录中心：管理登录等功能。一些网址请求时，需要携带请求前的地址，方便登录后，重定向回原来地址。
    - 用户登录时，验证用户的账户和密码
    - 登录完成后，生成一个token令牌，保存在redis中，key为token，value为用户信息
      - 并且，生成一个cookie，key=“token”，value=令牌序列号
    - 在请求其他微服务，或者其他系统时，在转发登录时，判断是否有cookie。有cookie，则从redis中获取用户信息
    - 将用户数据保存在当前的Session中，这样就可以访问当前微服务或者系统时，不必进行登录。(key为token，value为用户信息)

# 7，购物车

- 需求
  - 在未登录状态下，可以将商品加入临时购物车，登录后，会将购物车和临时购物车合并，把临时购物车清空
  - 未登录状态下，即使游览器关闭，下次进入，临时购物车的数据还在（可能目前没有这么使用的了，但仍然存在读多写多的情况，所以不适合 使用MySQL，**建议使用redis**）
  - 购物车，认为是读多写多的情况，所以放入redis中；
  
- 选择将所有的数据放在redis中 数据结构使用Map，原因是：购物车读多写多，若是使用list，则无法进行
  - Map<String k1,Map<String k2,CartItemInfo>>
    - k1:用户信息 即每个用户有自己的购物车
    - k2：购物项的Id
- **实现临时购物车**
  
  - 访问临时购物车首先需要创建临时用户：
    - 访问临时购物车时，判断是否登录，若没登录，判断是否有临时身份，设置在cookie中，每次请求都会携带一个该cookie，过期时间为1个月。在方法结束后，将threadLocal中的数据清除
  - 选择拦截器，进行判断
    - 写配方方法实现WebMvcConfigurer添加拦截器和拦截范围
    - 写拦截器，实现handlerInterceptor（拦截购物车的所有请求）
      - 前缀方法：
        - 创建一个TO（数据传输的对象），该TO包含用户的key，ID以及是否为临时用户。
        - 在SpringSession中获取对象，（如果登录，会在session中保存user）
        - 若获取不到，则尝试获取游览器的临时用户信息，即cookie（key=user-key）。并保存在TO
        - 最终将TO保存在threadlocal中（方便以后用户的获取）。如果是第一次访问购物车，则TO为默认值
      - 后缀方法：
        - 目的是判断如果是临时用户，为其分配一个临时的user-key，保存在cookie发给客户端
        - 保存一个月
  - 如果登录，则在session中保存该用户信息
  
- ### 将商品加入购物车

  - 在product微服务的item.html页面选择加入购物车（skuid和num）添加数据
  - service层
    - 首先判断购物车中是否有该商品，如果有，则仅需要更改购物车中该商品的数量
    - 若没有
      - 在cart中，创建一个cartItemVo：
      - 远程调用product获取该商品信息，保存在cartItemVo（异步进行，由于远程调用花费时间，异步调用，添加线程池）
      - 远程调用product获取该商品的销售信息，保存在cartItemVo
      - 记得调用异步编排的allof().get()方法。等待两个线程全部执行完毕，将Vo保存在redis中，
      - 注意：redis以hash的方式保存，hash->（skuid，vo）
  - **为避免刷新重复添加，需要将添加商品后，进行**==**重定向**==（转发不可以）
    - 由于页面需要重定向之前保存购物车，返回的商品信息，所以需要将商品的skuid通过重定向传入到新方法
    - 在新方法中，再次从redis中，获取该商品信息
  - 更改购物车某商品的数量，删除某个商品

# 8，消息队列RabbitMQ

- 交换机：（由交换机来决定发给哪个队列）
  - **direct**（需要完全匹配，才能发送）
    - 点对点的交换机
  - **fanout**
    - 发布订阅模式：一个发布，多个接收
  - **topic**
    - 模式匹配，即。将路由键与多个队列模式进行匹配。
    -  它将路由键和绑定键的字符串切分成单 词，#匹配0个或多个单词，*匹配一 个单词。

- 监听消息@RabbitListener
  - 可以有很多人来监听同一个消息队列，只要收到消息则队列删除消息，
  - 同一个消息，只能有一个客户端收到。即使多个人监听
  - 一个消息完全处理完，才能接收其他消息，或者说（只有消息处理完，执行完该方法，消息队列才能分配另一个消息）

# 9，订单业务

- 下订单需要用户登录才能完成操作
  - 在订单微服务中：添加拦截器，若已登录，则在threadLocal中添加用户，方便调用
  - 对订单服务添加配置类并实现webMVCConfigration。来添加拦截器和拦截路径（该服务下的所有路径）
    - 若未登录，则先登录再进行下订单操作

- 订单确认页（先进入订单确认页，再下订单）
  - 需求
    1. 在购物车中进行结算，转入订单确认页，
    2. 订单确认页的转入需要用户登录，未登录则转入到登录页面
    3. 订单确认页只有购物车选中的商品。
    4. 显示是否有货
    5. 根据选择收货地址，动态更改运费
  - **实现：**
    - 订单的请求在order微服务中
    - 首先设置拦截器，若没有登录，则拦截，并让其重定向到登录页面
    - 已经登录，则从session中获取user，并保存在threadlocal中
    - **service方法中**
      - 异步执行，远程获取当前用户的所有收货地址  userId->member微服务
      - 异步执行，远程获取当前用户购物车中哪些商品选中
        - 另外**需要重新确认价格**，避免因放在购物车时间过久，价格更改。远程调用product微服务，获取价格信息并保存到当前商品
      - 在获取商品后，异步编排执行：当前商品是否有货，并保存为map，返回到页面显示
      - 等待所有执行结束，方法结束
    - 客户选择收货地址，在最下方显示邮费，ajax请求发送。获取当前用户的地址（远程调用），邮费计算返回结果
- **问题**
  
  - feign远程调用，可能调用的服务需要获取用户信息，被调用的微服务拦截器会先获取用户信息
  - **feign远程调用丢失请求头**（feign远程调用异步调用时会创建新的request）
    - feign远程调用，若是单线程，则当前线程执行完远程调用，再执行后续代码
    - **异步执行：使用线程池，则会使用新的线程，创建一个新的request去请求远程服务。原本请求头携带的信息全部丢失，即cookie，session和threadlocal都丢失了**
    - 解决办法：**使用feign请求拦截器：**
      - 创建新的request请求头时，会将拦截器设置的信息保存到新的请求头。
      - 所以可以将需要保存的请求头信息，从旧请求头保存到拦截器中
        - **又由于旧请求头的获取都是在当前线程的threadLocal中。所以旧的请求头信息无法获取，所以需要在使用线程池时，在当前线程获取request信息，保存在新线程新创建的RequestAttributes中**（问题二）
      - ![image-20220415145212853](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220415145212853.png)
  
- **问题二**
  
  - **Feign异步情况丢失上下文问题**
    - 由于现在所有的操作都在service层，旧的请求头获取，使用的是RequestContextHolder.getRequest。若request实质上是保存在ThreadLocal中。
    - 所以远程调用微服务，仍然不能实现，虽然已经将cookie保存带request。但是request无法获取
    - 所以我们需要将request的相关信息也保存在新请求中
    - ![image-20220415182358480](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220415182358480.png)
  
- ### 多次提交问题（接口幂等性问题）

  - （由于网速等各种原因，用户点击 了多次提交订单，而应该只执行一次）
  - **接口幂等性讨论**
  - **幂等性**：用户对同一操作发起的一次请求或多次请求的结果是一致的
    - 需要防止的情况：
      - 用户多次点击按钮
      - **用户页面回退后，再次提交**
      - 微服务互相调用，由于网络问题，导致请求失败。feign 触发重试机制
    - 一些情况是已经满足幂等条件：查询，更改x =1....
    - 但更改x = x+1等情况是不幂等的（而很多场景都是通过此方式来更改数据）
  - **幂等解决方案**
    - **token 令牌机制**（以提交订单为例）
      1. 客户端在执行提交订单前，向服务器获取token，服务器并把token保存在redis中。（方便验证令牌）
      2. 客户端提交订单时，把token一块提交
      3. 服务器判断请求来的token是否与redis中的一致（redis中的保存为userId:token）。所以需要用户和token都一致才判断成功。**并将redis中的token删除。**，注意此时验证token与redis一致并删除操作得是原子的，不然会出现问题
      4. 若不存在该token，则不能执行后续业务
    - **token的注意事项**
      - **在判断token以后，要先删除token。再执行后续业务。**
      - **判断和删除时必须是原子性的**。要么一致判断成功，并删除。要是失败返回。避免并发判断一致，多个线程一块执行后续业务的情况
      - **redis通过lua脚本实现**
    - 数据库加锁（乐观锁，悲观锁）
    - 业务层（分布式锁）
    - 唯一性约束
      - 数据库唯一性约束，
      - redis唯一性约束，将数据保存redis set中。
      - 构建防重表，对已经请求的，进行记录。
  - **为避免提交订单和进行结算时多次提交，方式为对MySQL表中订单号添加唯一性条件和索引，另外选择token令牌机制**

- 提交订单无需提交需要购买的订单，去购物车再取一次已选中的即可。

- ### 下订单

  - 在确认订单页面获取token，提交订单，首先判断是否token一致，一致删除token，继续执行
  - 创建订单
    - 创建订单
      - 生成一个不重复订单号，并将数据库中订单号建立索引
      - 获取收货信息
        - 远程调用库存微服务。（用户的收货地址，运费）
      - 设置订单的状态信息
    - 获取所有的订单项（集合）
      - 此时获取订单项的信息都是在数据库中获取，**并不是直接订单确认页的订单项，避免确认订单时，价格改变（最后一次确认价格）**【三次确认价格，加入购物车时查询价格，订单确认页查询价格，下订单生成时查询价格】
        - 远程调用购物车微服务，将购物车中选择的商品生产购物订单，**并不是订单确认的页的数据。**
      - 购物车中的订单项很少，需要重建订单项
        - 订单号，sku信息，积分信息，优惠信息（打折，满减等）
        - 远程调用product微服务，获取订单的spu详细信息
        - 生成当前购物项的实际金额
    - 验价格（订单项的总金额是否与订单确认页执行）
      - 重新查询的订单项与确认订单页面提交来的总额进行比较（若差额<0.01）则视为价格没变化。并将所有信息（金额，优惠，地址，用户，积分，订单）保存在订单vo中，后续保存到数据库
      - 否则，重新提交订单，并提醒用户价格改变
    - 锁库存
      - 数据库的库存表中：包含库存数量和锁定库存数据（下订单，还未付款的总数）
      - 在订单项中获取所有的skuId，数量，
      - 远程调用库存微服务执行锁库存方法（事务执行）
        - 该方法内，所有执行失败的情况都抛出异常
        - 查询每个订单项，获取所有有库存的仓库Id集合
        - 遍历每一个订单项下的每一个仓库能否满足当前订单项的数量
          - 若当前订单项中。仓库为空，或者库存数量不能满足订单项的数量，则跳出循环，抛异常
        - **另外**：锁定库存时，会



**下订单流程**

- 首先在购物成中选中商品，去结算。先进入订单确认页，此时还没有生成订单

- ## 购物车去结算->订单确认页

  - 查看该用户 保存的地址，（远程请求member微服务，查看ums_member_receive_address表，用户名，手机号，邮编，省，市，区，memberId,因为一个用户可能会有多个收货地址）

  - 获取该用户购物车中选中的商品信息，请求购物车微服务，在获取到该用户购物车选中的商品后，**遍历每个商品获取商品的最新价格。**
  - 获取该用户选中商品的是否有货信息，请求库存微服务，【注意，在下订单时会锁定库存，所以查看有货无货时，是库存-已锁定库存>0】
  - 使用UUID生成一个原子令牌，保存在redis中，避免由于网络卡顿，用户点了多次下订单操作

- ## 提交订单按键->结算页 

  - 首先查看用户的原子令牌是否还存在，并且相等，相等则删除，如果不存在则不再执行 后续操作 【使用lua脚本完成该任务】
  - 创建订单：【订单内容，购物项内容，两张表中】
    - 订单内容: 生成订单号，保存用户名用户Id，收货地址信息，设置订单状态。
    - 购物项内容：再次从购物车中获取所选取购物项【获取商品时会请求商品微服务，更新商品价格。**每次获取商品价格都是从数据库中获取**】
      - 进行验价，比较订单确认页时显示的价钱和再次查询购物项商品微服务计算后的价钱【查询三次价格，进入购物车时，去结算进入订单确认页，提交订单进入结算页 】
  - 保存订单【保存到两个表中】
    - 保存订单，保存所有购物项；
  - 锁定库存：创建一个购物项集合，请求库存微服务，锁定所有购物项库存要买的个数，内部有一个购物项的解锁库存的消息队列
    - 保存一个工作单，记录是哪个订单的信息，**方便回溯**
    - 遍历每个购物项，锁定库存，保存详情单。【将详情单的信息交给解锁库存的消息队列】
    - 若没有锁定成功则抛出异常，之前所有锁定的购物项库存都回滚
  - 请求成功后，将订单VO添加到关单的延时队列。
  - **锁定库存成功后，**将订单信息添加 到关单的消息队列



工作单，详情单是库存微服务的概念

- **工作单**：订单Id，订单SN【二者不同，订单Id是保存在数据库的序列号，订单SN是返回给用户看的唯一编号，且不易伪造】
  - 创建时间，创建地址，订单的详情信息等
- **详情单**
- 消息队列中的消息：
  - 详情单Id，详情单的VO信息【数据库可能回滚，导致详情单没保存到数据库但是消费者可通过详情单Id查询出来，详情单的VO可有可无】



# 分布式事务

**问题**

- 在一个service层事务方法添加回滚，若该方法有远程调用。远程调用结束后，发生异常回滚，则远程调用执行的方法并不会执行回滚。
  - 默认使用的事务是本地事务







- 使用Seata控制分布式事务（流程）
  - 每个微服务先创建undo_log表
  - 安装事务协调器。seata-server
    - spring中导入依赖依赖
    - 在需要 远程调用事务的方法上添加 @GlobalTransactional（但是该全局事务会加锁，导致服务器处理过慢，不适用高并发场景）
- 我们商城使用的方法：
  - 为保证高并发，库存服务自己回滚，可以发消息给库存服务
  - 库存服务本身自动解锁，**使用消息队列中的延时队列**。
    将远程调用的更改相关信息写入表中，延时队列延时查询执行

# 10，MQ延时队列

- 为什么使用延时队列？
   - **因为我们要定时完成任务，而定时任务过于消耗性能。**
      - 而且存在误差，比如说，30分钟扫描一次是否有过期订单，用户1分钟时，下订单，31分时，过期。系统是0分，30分，60分， 扫描。所以，30分钟时没有扫描到，而是等到60分组时，29分钟的延迟，这是不能接收的。
      - ![image-20220604203609737](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220604203609737.png)
   - **保证事务的最终一致性**

- **使用**
  - 给队列设置过期时间，队列过期，则将消息发个死信路由**（推荐）**
    1. 或者一个普通队列中的消息设置一个过期时间，该队列不要将其被消费
  - 该消息过期后，成为**死信**，转入到另一个死信路由（与普通路由一样），可以监听该路由下的消息，实现延时（延时时间即消息的过期时间）
- 消息队列流程：向交换机提交消息对象和路由键，MQ通过路由键找到对应的队列，存入消息
- **使用场景**：**订单过期取消，和库存锁定过期取消。这是两个延时队列**。而且订单过期取消早于库存锁定过期取消。反过来，可能会出现库存已取消锁定，但是订单支付，无货的情况。
  - 为什么不使用一个延时队列？
    - 因为是不同的微服务，下订单过程是订单微服务，库存锁定是库存微服务。若是合成一个看似方便，实际在发送消息时，麻烦一些。反倒不如用两个消息队列。
  - 当前设置为：
    - 库存锁定成功，向交换机提交路由键（stock.locked），锁定库存，交换机根据路由键，找到延时队列。等待相应的时间。等待过期后，将死信发送给交换机，并提交了新的路由键（stock.release）。交换机提交到release队列，进行发布
    - 延时队列创建时，需要指定死信路由（过期后提交到哪个交换机），死信路由键，过期时间

![image-20220417144947692](%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E.assets/image-20220417144947692.png)

- 库存解锁的情况：
  - 下订单成功，但是没有支付，或者用户取消订单，
  - 下订单成功，但由于接下来的业务调用失败，导致订单回滚(购买abc,三个产品,ab锁定成功,C锁库存失败,由于远程调用,无法进行回滚远程业务)【此时没有使用延时队列】

- 库存解锁功能:
  - 使用延时队列实现对订单的处理(**订单在30分钟内有效,可能用户取消,可能过期取消,全局事务不适合高并发场景,所以选择消息队列的延时队列**)
  
  - **订单过期:**(放在延时队列中,若过期,则交由死信路由，在交给另一个队列，处理该队列，可以实现消息的延时)
    
    - 工作单指一次下订单业务（每次下订单会有一个工作单）
    - 详情单为每个购物项的详细信息（每次锁库存会有一个详情单，即一个订单上的所有商品项）
    - 生产者
      - 锁定库存前，向数据库中保存工作单（工作单指一次下订单业务，详情单为每个购物项的详细信息），保证出错后仍有记录可以回滚
      - 锁库存操作
      - 锁定多个库存时：
      - 对一个商品锁定成功后，则保存详情单到数据库，并将详情单信息以及工作单Id添加到延时队列
      - 若某个商品未锁定成功，则导致所有的锁定失败，当前下订单业务的所有购物项回滚。在数据库中保存的工作单和详情单也回滚。但是远程事务需要通过详情单中的信息，skuId,wareId,数量，进行回滚。在延时队列中
      - 消息队列需要手动确认回复，不能自动回复，避免因远程调用异常，解库存操作失败
    - 消费者【有两种消息，双重解锁保证可靠性】
      
      - 库存延时队列发送的消息，传入详情单对象
        - 查找详情单，若是存在【可能会不存在，因为锁定库存时出现异常，回滚，保存的所有的详情单已经回滚没了】
        - 若存在，根据详情单查找工作单，查看工作单的状态
        - 若是工作单不存在，或者工作单状态为取消状态【因为订单延时队列早于库存延时队列，此时已经是取消转态，工单不存在是锁定库存时出现异常】
        - 此时判断是否解锁过，若是已经解锁，则不解锁了。
        - 更新锁的状态，将stock_locked减少数量
      - 订单延时队列的消费者取消订单后，也发送消息来取消库存锁定，传入订单对象
        - 查询最新的工作单状态（判断是不是已经取消或者支付）
        - 查找该工作单下的所有详情单
        - 遍历解锁详情购物项
      
      
      
      
      
      
      
      
      
      
      
      - 延时队列过期，通过路由键将消息发给库存解锁队列。消费者获取消息
      - 查询数据库关于该订单的锁库存信息
        - 有，证明锁定库存成功。
        - 解锁：首先获取当前详情单的信息，若有，表明库存一定锁定
          - 获取工作单信息
            - 没有->表明发生回滚，必须解锁
            - 有当前订单：
              - 已取消 订单：解锁库存
              - 已经售卖：不能解锁库存
        - 没有该订单，则表示锁定库存时，出现了异常【锁定某个商品时，没货，锁定失败】
  
  远程锁定库存时，先保存工作单，再保存详情单。保存详情单时，是遍历所有的购物项，将每个购物项进行锁定库存，锁定成功后，将将消息发送给库存的延时队列
  
  
  
  - 订单过期解锁订单信息：
    - 下订单成功后将订单的相关信息发送到延时队列，过期向关闭队列发送消息，包含订单的相关信息。
    - 消费者解锁解锁订单消息，将订单状态改为已取消
  
    - **为避免因为订单发送消息卡顿，导致库存消息先于订单消息过期（消费者收到消息，发现订单仍在新建状态，解锁库存时只有在订单在已取消时才解锁。库存消息被消费），在订单消息过期，进行解锁时，没有库存消息，从而无法实现解锁库存。（所以选择在订单解锁后，再发一个消息到库存解锁队列（不必进行验证，保证订单解锁先于库存解锁），进行解锁（即每次库存解锁会收到两个解锁消息，有一个成功即可））**
      - 消息过期后，路由给死信队列，消费者消费消息
      - 先检查订单状态，若是新建状态，则将订单状态更改为已取消，并通过
  



- ### 保证消息的可靠性：

  - #### 消息丢失：
    
    - 网络问题：消息没有抵达服务器
      - **将每个消息保存到数据库，**定期去数据库中扫描未成功的消息，进行重发
    - 消息抵达Broker，还未持久化，宕机（生产者认为发送了消息，消费者收不到消息）
      - 生产者也必须加入确认回调机制，即发送消息也要确认（并修改数据库消息状态）    即使用消息确认机制实现可靠 抵达
    - 消费者收到消息，没来得及处理，会处理出现异常，导致消息已经消费
      - 消费者使用手动Ack
    
  - #### 消息重复

    - **原因**
      - 消息者消费成功，事务已经提交，消费者ack时，宕机导致ack没成功，broker重新发送
      - 消息者消费失败，由于重试机制，自动将消息发送出去。【这个是允许的，也是应该的】

    - **方法**
      - 消费者的业务消费接口是**幂等性**的，【即解锁库存时会判断订单状态，若是重复消费，之前消费者已经将库存详情表改为已解锁，所以不再二次消费】
      - 使用**防重表**，发送消息每个业务的唯一标识，处理过就不用再处理。
      -  rabbitMQ的每一个消息都有redelivered字段，可以获取是否是被重新投递过来的，而不是第一次投递过来的  （？？并不懂）

  - #### 消息积压

    - 原因
      - 消费者宕机，导致消息积压
      - **消费者消费能力不足**
      - 生成者发送流量过大，消息产生过多

    - 方法：
      - 上线更多的消费者，进行正常消费
      - 上线转门的队列消费服务，将消息先批量取出，保存在数据库中，离线慢慢处理




# 支付宝支付

- 引入沙箱demo，
- 配置APPID，支付宝网关
- 每次支付会跳转设置的外网页面
- 支付宝异步通知
  - 支付成功后，会转到订单页面，需要更改订单信息。若在转发带订单页面时再更改，不安全。因为get请求可以获取全部信息。明文发送不安全。选择异步通知的方式
- 收单：在支付页面，不支付等待消息队列过期





# 10，秒杀

将相关商品在秒杀前，先加载到reids中进行预热

- ### **秒杀商品定时上架**

  - 秒杀商品上架是在凌晨将接下来三天内的秒杀活动获取加入redis进行预热
    - CRon表达式：实现定时任务
    - **Spring开启定时任务**
      - @enableScheduling 开启定时管理
      - @enableScheduled（cron=” * * * *”） 开启一个定时任务
        （定时任务不能以年为单位的）
    - **spring定时任务默认是阻塞的：即阻塞时，定时任务得不到执行。**
      - 解决办法：
        - **异步任务**：
          1. @enableAsync 开启异步任务功能
          2. @Async 给每个希望异步执行的方法标注注解
  - **上架功能实现：**
    - **先竞争分布式锁**，再执行上架功能：为避免分布式下相同的微服务运行在多台服务器上。需要加分布式锁（redisson实现），避免重复上架
    - 1，远程调用优惠微服务，获取三天内所有要秒杀的活动
      - 获取加下来三天的活动，以时间作为where条件，查询开始时间在三天内的活动
      - 查询每个秒杀活动，设计到的所有商品Id
    - 保存所有的秒杀活动信息  （保存在redis：List中，可以添加多个value）
      - 若判断是否已保存，则跳过执行
      - key：起始时间+结束时间，value：活动Id+商品SkuId（为避免多个秒杀活动有同一款商品导致覆盖，value添加上活动Id）
    - 保所所有要秒杀的商品信息
      - 遍历每个活动的每个商品，若已保存，则跳过（保存在redis：hash中）
        - 商品信息redisTo与product中的商品信息Entity不同，需要设置优惠价格，该商品的起始，结束时间。该活动的商品数量
        - 远程调用product微服务，获取sku基本信息。
        - 将活动的相关信息保存到该商品上。设置优惠价格，该商品的起始，结束信息。
        - 保存该商品，为避免多个活动有同一款商品，key添加上秒杀活动ID
        - **随机码**
          - 每种秒杀的商品都有一个随机码，购买该商品的请求需要携带随机码。
          - 未避免秒杀工具直接请求seckill？skuId=1。需要添加随机码。
          - 随机码在秒杀活动开始后暴露
          - 请求时携带随机码
            - **尽可能的保证秒杀是人点击页面实现的，而不是脚本预知了url来购买的**
        - 设置**redis信号量**：信号量为库存数。没有使用lua脚本，使用信号量的 tryAcquire方法来获取指定数量的信号量，若不能获取，则秒杀失败。否则成功。
          - 以库存作为信号量。
  
  该秒杀商品的保存，并未以活动作为分类，而是将商品作为一个类进行保存。
  
  1. 因为页面展示时。访问到该商品的详情页，也能显示秒杀活动。若以活动作为类进行保存，则无法实现该功能
  2. 页面展示秒杀活动时，仅展示在秒杀活动的商品，而并没有区分秒杀活动
  
  **==不要让数据库/数据中间件来做业务操作==**



- 获取秒杀商品信息：
  - 访问商城主页（获取所有在秒杀活动的信息）
    - 获取所有秒杀活动的key，遍历每一个秒杀活动，当前时间与活动的起始，结束时间比较。满足要求，则获取该活动涉及的所有商品key（（商品上架保存秒杀活动时已保存）），并在seckill:skus中获取商品详细信息
  - 访问详情页（判断该商品是否为秒杀商品，并显示详细信息）
    - 正则匹配所有的秒杀活动商品中：key是否以请求来的skuId结尾。是，则表明该商品未秒杀商品，并返回信息



- ### 秒杀商品购买

  - ## 高并发问题

    - **服务单一职责：**
      将每个功能作为一个微服务进行独立部署
    - **秒杀链接加密：**
      下单链接加上随机码，只有在秒杀活动开启后才能获取
    - **库存预热：**
      提前加入到redis中。信号量控制请求进来的秒杀请求
    - **动静分离，**
      Nginx实现动静分离，静态页面的获取直接在Nginx中获取，不会落到后端服务器上。动态请求来到后端服务器
    - **恶意请求拦截：**
      识别非法攻击请求并进行拦截，网关层面
    - **流量错峰：**
      购买秒杀商品，需要加入购物车才能购买，避免了直接购买而导致的高并发请求。加入购物车，用户的操作的快慢不一致，可以实现流量错峰。
    - **限流&熔断&降级**
    - **队列削峰**

  - **秒杀商品购买流程**

    1. 立即抢购商品，发送请求，该商品随机码，秒杀商品号（redis的key），数量
    2. 秒杀微服务：
       1. 获取当前秒杀商品的详细信息
       2. 校验合法性（时间合法性，随机码一致性，购物数量是否合理）**恶意请求拦截，秒杀链接加密：**
       3. 该用户是否购买过该秒杀商品，redis保存临时信息。设置过期时间，过期时间为秒杀活动结束时间
       4. 生成订单号，对信号量进行扣除（信号量为该秒杀商品的总数），没有信号量则无法进行购买
       5. 生成MQ通知订单服务生成订单。**队列削峰**
       6. **订单微服务生成订单后，转发到订单请求结果页面**
          1. 若抢购成功，显示生成订单号和和5秒后跳转支付请求，也可以立即支付链接。到支付页面。（**流量错峰：**）

    漏洞：若我秒杀到商品后，没支付，只能锁定库存，但不能恢复信号量。

    调用MQ进行削峰
    
    创建订单成功后，有直接去支付按钮，请求中携带这订单号。

# 11，Sentinel高并发解决熔断，降级等功能

- 熔断：某个服务发生故障，导致不可用。下次调用该服务，则直接返回不可用结果。

- 降级：高并发时，由于系统运行高并发，手动关闭一些非核心业务。来使得核心业务顺利执行

- Sentinel：

  - 对该服务的资源进行保护。资源可以是方法，代码。。。
  - 定义资源
  - 定义规则

- 整合Sentinel

  - 引入sentinel的starter包
  - 下载控制台，配置信息。
  - 在控制台调整参数。（这些参数默认保存在内存中，即监控的微服务重启，则配置丢失）

- 引入actuator和sentinel，properties配置。写配置类：实现自定义流控响应（即控制流量后，显示的限流信息，可以配置404等）

  ```properties
  #sentinel配置
  spring.cloud.sentinel.transport.dashboard=localhost:8333
  spring.cloud.sentinel.transport.port=8719
  management.endpoint.web.exposure.include=*
  ```

- 流控模式：

  - 直接：只限制当前请求，即请求该地址，则进行限制
  - 关联：A与B进行关联，A影响B 。对A的流控，也会影响B
  - 链路：指定入口，即通过入口最终到当前请求，则流控，若没有经过入口，则不流控

- 熔断降级：

  - 调用方熔断保护

    ```Java
    @FeignClient(value = "mall-seckill",fallback = SeckillFeignServiceFallBack.class)
    ```

    - 在调用该方法后，若feign调用不成功，会调用fallback指定的方法。并且一段时间内不会再调用feign调用该方法。而直接fallback

  - 降级策略：

    - 调用方手动指定远程调用服务的降级策略。
      - 若多次请求时间过长，则在接下来的一段时间内使用fallback方法。（即请求过慢，可以将远程服务进行降级处理，触发熔断回调方法。实质上是可以用的，仅仅是慢一些）
    - 提供方：执行降级策略。提供方在运行，但不执行业务逻辑。返回的是默认的熔断数据（限流的数据）

  - 熔断主要是在调用方控制，熔断主要是防止提供方宕机

  - 降级是在提供方控制。降级则是提供方为了解压，给调用方提供了一些解单的数据。

- **自定义受保护资源**

  1. 通过try  catch方式

     ```
      try (Entry entry = SphU.entry("自定义名称")) {
      	受保护资源
      } catch (BlockException e) {
     	log.error("资源被限流,{}",e.getMessage());
     }
     ```

  2. 通过注解：保护方法

     ```
     @SentinelResource(value = "getCurrentSeckillSkusResourses",blockHandler = "blockHandler",fallback = )
     ```

     blockHandler函数在原方法被限流/降级/系统保护的时候调用，而fallback函数会针对所有类型的异常。（fallback：注解修饰的方法为发生了异常时调用）

- **网关流控**

  - 对网关进行流控，即对整个微服务进行限制。不必进入目标微服务进行流控判断，降低微服务的消耗
  - 自定义流控回调：SentinelGatewayConfig

- 服务链路追踪系统

  - 



